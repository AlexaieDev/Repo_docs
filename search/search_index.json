{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Centro de Documentaci\u00f3n Bienvenido al centro de documentaci\u00f3n consolidada de todos los proyectos. Este sitio centraliza la informaci\u00f3n t\u00e9cnica, gu\u00edas y referencias de nuestros sistemas. \u00bfQu\u00e9 encontrar\u00e1s aqu\u00ed? Esta documentaci\u00f3n est\u00e1 dise\u00f1ada para desarrolladores, equipos t\u00e9cnicos y colaboradores que necesiten: Documentaci\u00f3n t\u00e9cnica completa de cada proyecto Gu\u00edas de inicio r\u00e1pido para empezar a trabajar r\u00e1pidamente Referencias de API detalladas y ejemplos de c\u00f3digo Mejores pr\u00e1cticas y patrones de desarrollo Tutoriales paso a paso para tareas comunes Proyectos Documentados Actualmente mantenemos documentaci\u00f3n para m\u00faltiples proyectos en diferentes etapas de desarrollo: Proyecto 1 - Sistema de Gesti\u00f3n Sistema de gesti\u00f3n empresarial con arquitectura de microservicios. - Estado: Producci\u00f3n - Stack: Python, FastAPI, PostgreSQL Proyecto 2 - Aplicaci\u00f3n E-Commerce Aplicaci\u00f3n m\u00f3vil multiplataforma para comercio electr\u00f3nico. - Estado: Beta - Stack: React Native, Node.js, MongoDB Proyecto 3 - API de Integraciones API REST para integraciones con servicios externos. - Estado: Desarrollo - Stack: Go, Docker, Redis Navegaci\u00f3n R\u00e1pida Ver todos los proyectos \u2192 Tutorial de MkDocs - Aprende sobre la plataforma de documentaci\u00f3n Buscar - Utiliza la barra de b\u00fasqueda en la parte superior para encontrar informaci\u00f3n espec\u00edfica Mantenimiento Esta documentaci\u00f3n se actualiza autom\u00e1ticamente mediante GitHub Actions cada vez que se hace push al repositorio. \u00daltima actualizaci\u00f3n: Autom\u00e1tica con cada despliegue","title":"Inicio"},{"location":"#centro-de-documentacion","text":"Bienvenido al centro de documentaci\u00f3n consolidada de todos los proyectos. Este sitio centraliza la informaci\u00f3n t\u00e9cnica, gu\u00edas y referencias de nuestros sistemas.","title":"Centro de Documentaci\u00f3n"},{"location":"#que-encontraras-aqui","text":"Esta documentaci\u00f3n est\u00e1 dise\u00f1ada para desarrolladores, equipos t\u00e9cnicos y colaboradores que necesiten: Documentaci\u00f3n t\u00e9cnica completa de cada proyecto Gu\u00edas de inicio r\u00e1pido para empezar a trabajar r\u00e1pidamente Referencias de API detalladas y ejemplos de c\u00f3digo Mejores pr\u00e1cticas y patrones de desarrollo Tutoriales paso a paso para tareas comunes","title":"\u00bfQu\u00e9 encontrar\u00e1s aqu\u00ed?"},{"location":"#proyectos-documentados","text":"Actualmente mantenemos documentaci\u00f3n para m\u00faltiples proyectos en diferentes etapas de desarrollo:","title":"Proyectos Documentados"},{"location":"#proyecto-1-sistema-de-gestion","text":"Sistema de gesti\u00f3n empresarial con arquitectura de microservicios. - Estado: Producci\u00f3n - Stack: Python, FastAPI, PostgreSQL","title":"Proyecto 1 - Sistema de Gesti\u00f3n"},{"location":"#proyecto-2-aplicacion-e-commerce","text":"Aplicaci\u00f3n m\u00f3vil multiplataforma para comercio electr\u00f3nico. - Estado: Beta - Stack: React Native, Node.js, MongoDB","title":"Proyecto 2 - Aplicaci\u00f3n E-Commerce"},{"location":"#proyecto-3-api-de-integraciones","text":"API REST para integraciones con servicios externos. - Estado: Desarrollo - Stack: Go, Docker, Redis","title":"Proyecto 3 - API de Integraciones"},{"location":"#navegacion-rapida","text":"Ver todos los proyectos \u2192 Tutorial de MkDocs - Aprende sobre la plataforma de documentaci\u00f3n Buscar - Utiliza la barra de b\u00fasqueda en la parte superior para encontrar informaci\u00f3n espec\u00edfica","title":"Navegaci\u00f3n R\u00e1pida"},{"location":"#mantenimiento","text":"Esta documentaci\u00f3n se actualiza autom\u00e1ticamente mediante GitHub Actions cada vez que se hace push al repositorio. \u00daltima actualizaci\u00f3n: Autom\u00e1tica con cada despliegue","title":"Mantenimiento"},{"location":"about-mkdocs/","text":"About MkDocs What is MkDocs? The description on the MkDocs site is: Project documentation with Markdown. MkDocs is a Python tool that generates a static site based on content written in Markdown. If you are new to markdown, see the Getting Started page on the Markdown Guide website. Resources mkdocs.org homepage mkdocs/mkdocs MkDocs Wiki - covering themes, plugins, recipes and more. Release notes for MkDocs. Reasons to use MkDocs Create an elegant, modern docs site for your project. Create a static site and serve from GitHub Pages easily. Low-code solution No need to write HTML or learn templating syntax needed Use your existing markdown files as content. Configure with a simple YAML file. Customizable. Add custom HTML if you want. Plugins available. Flexible theme choices. Includes search by default. Broken links to files (including from your navbar) will be detected at build time and shown as warnings. Do I need to know Python? MkDocs is built in Python (like Sphinx), but you don't have to write Python code. If you set up a Deploy flow right (using GitHub Actions), you don't even have to set it up locally, though then you can't preview.","title":"Acerca de MkDocs"},{"location":"about-mkdocs/#about-mkdocs","text":"","title":"About MkDocs"},{"location":"about-mkdocs/#what-is-mkdocs","text":"The description on the MkDocs site is: Project documentation with Markdown. MkDocs is a Python tool that generates a static site based on content written in Markdown. If you are new to markdown, see the Getting Started page on the Markdown Guide website.","title":"What is MkDocs?"},{"location":"about-mkdocs/#resources","text":"mkdocs.org homepage mkdocs/mkdocs MkDocs Wiki - covering themes, plugins, recipes and more. Release notes for MkDocs.","title":"Resources"},{"location":"about-mkdocs/#reasons-to-use-mkdocs","text":"Create an elegant, modern docs site for your project. Create a static site and serve from GitHub Pages easily. Low-code solution No need to write HTML or learn templating syntax needed Use your existing markdown files as content. Configure with a simple YAML file. Customizable. Add custom HTML if you want. Plugins available. Flexible theme choices. Includes search by default. Broken links to files (including from your navbar) will be detected at build time and shown as warnings.","title":"Reasons to use MkDocs"},{"location":"about-mkdocs/#do-i-need-to-know-python","text":"MkDocs is built in Python (like Sphinx), but you don't have to write Python code. If you set up a Deploy flow right (using GitHub Actions), you don't even have to set it up locally, though then you can't preview.","title":"Do I need to know Python?"},{"location":"proyectos/","text":"\ud83d\udcda Documentaci\u00f3n de Proyectos Bienvenido al centro de documentaci\u00f3n consolidada. Aqu\u00ed encontrar\u00e1s la documentaci\u00f3n completa de todos los proyectos. \ud83d\ude80 Proyectos Disponibles Proyecto 1 Sistema de gesti\u00f3n empresarial con arquitectura microservicios. - Estado: Producci\u00f3n - Tecnolog\u00edas: Python, FastAPI, PostgreSQL - Ver Documentaci\u00f3n \u2192 Proyecto 2 Aplicaci\u00f3n m\u00f3vil multiplataforma para e-commerce. - Estado: Beta - Tecnolog\u00edas: React Native, Node.js, MongoDB - Ver Documentaci\u00f3n \u2192 Proyecto 3 API REST para integraciones con servicios externos. - Estado: Desarrollo - Tecnolog\u00edas: Go, Docker, Redis - Ver Documentaci\u00f3n \u2192 \ud83d\udccb Estructura de la Documentaci\u00f3n Cada proyecto sigue la misma estructura: - Getting Started - Gu\u00eda de inicio r\u00e1pido - API Reference - Documentaci\u00f3n de APIs - Guides - Gu\u00edas detalladas y tutoriales - Examples - Ejemplos de c\u00f3digo y casos de uso \ud83d\udd0d B\u00fasqueda R\u00e1pida Utiliza la barra de b\u00fasqueda superior para encontrar informaci\u00f3n espec\u00edfica en cualquier proyecto.","title":"\ud83d\udcda Documentaci\u00f3n de Proyectos"},{"location":"proyectos/#documentacion-de-proyectos","text":"Bienvenido al centro de documentaci\u00f3n consolidada. Aqu\u00ed encontrar\u00e1s la documentaci\u00f3n completa de todos los proyectos.","title":"\ud83d\udcda Documentaci\u00f3n de Proyectos"},{"location":"proyectos/#proyectos-disponibles","text":"","title":"\ud83d\ude80 Proyectos Disponibles"},{"location":"proyectos/#proyecto-1","text":"Sistema de gesti\u00f3n empresarial con arquitectura microservicios. - Estado: Producci\u00f3n - Tecnolog\u00edas: Python, FastAPI, PostgreSQL - Ver Documentaci\u00f3n \u2192","title":"Proyecto 1"},{"location":"proyectos/#proyecto-2","text":"Aplicaci\u00f3n m\u00f3vil multiplataforma para e-commerce. - Estado: Beta - Tecnolog\u00edas: React Native, Node.js, MongoDB - Ver Documentaci\u00f3n \u2192","title":"Proyecto 2"},{"location":"proyectos/#proyecto-3","text":"API REST para integraciones con servicios externos. - Estado: Desarrollo - Tecnolog\u00edas: Go, Docker, Redis - Ver Documentaci\u00f3n \u2192","title":"Proyecto 3"},{"location":"proyectos/#estructura-de-la-documentacion","text":"Cada proyecto sigue la misma estructura: - Getting Started - Gu\u00eda de inicio r\u00e1pido - API Reference - Documentaci\u00f3n de APIs - Guides - Gu\u00edas detalladas y tutoriales - Examples - Ejemplos de c\u00f3digo y casos de uso","title":"\ud83d\udccb Estructura de la Documentaci\u00f3n"},{"location":"proyectos/#busqueda-rapida","text":"Utiliza la barra de b\u00fasqueda superior para encontrar informaci\u00f3n espec\u00edfica en cualquier proyecto.","title":"\ud83d\udd0d B\u00fasqueda R\u00e1pida"},{"location":"proyectos/proyecto-1/","text":"Proyecto 1: Sistema de Gesti\u00f3n Empresarial \ud83d\udcd6 Descripci\u00f3n General Sistema modular de gesti\u00f3n empresarial basado en microservicios, dise\u00f1ado para escalar seg\u00fan las necesidades del negocio. \u26a1 Caracter\u00edsticas Principales Arquitectura de Microservicios - Servicios independientes y escalables API RESTful - Interfaz unificada para todas las operaciones Dashboard Administrativo - Panel de control en tiempo real Gesti\u00f3n de Usuarios - Sistema robusto de roles y permisos Reportes Automatizados - Generaci\u00f3n de informes personalizables \ud83c\udfd7\ufe0f Arquitectura \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Load Balancer (Nginx) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u25bc \u25bc \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 API \u2502 \u2502 Auth \u2502 \u2502 Admin \u2502 \u2502 Gateway \u2502 \u2502 Service \u2502 \u2502 UI \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Message Queue \u2502 \u2502 (RabbitMQ) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u25bc \u25bc \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Users \u2502 \u2502 Reports \u2502 \u2502 Files \u2502 \u2502 Service \u2502 \u2502 Service \u2502 \u2502 Service \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 PostgreSQL DB \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \ud83d\udcda Secciones de Documentaci\u00f3n \ud83d\ude80 Getting Started - Instalaci\u00f3n y configuraci\u00f3n inicial \ud83d\udce1 API Reference - Documentaci\u00f3n completa de la API \ud83d\udcd6 Guides - Gu\u00edas detalladas y mejores pr\u00e1cticas \ud83d\udca1 Examples - Ejemplos de c\u00f3digo y casos de uso \ud83d\udd17 Enlaces \u00datiles GitHub Repository Issue Tracker Changelog \ud83d\udcca Estado del Proyecto Versi\u00f3n Actual: 2.3.1 \u00daltima Actualizaci\u00f3n: Octubre 2024 Estado: \ud83d\udfe2 Producci\u00f3n","title":"Proyecto 1: Sistema de Gesti\u00f3n Empresarial"},{"location":"proyectos/proyecto-1/#proyecto-1-sistema-de-gestion-empresarial","text":"","title":"Proyecto 1: Sistema de Gesti\u00f3n Empresarial"},{"location":"proyectos/proyecto-1/#descripcion-general","text":"Sistema modular de gesti\u00f3n empresarial basado en microservicios, dise\u00f1ado para escalar seg\u00fan las necesidades del negocio.","title":"\ud83d\udcd6 Descripci\u00f3n General"},{"location":"proyectos/proyecto-1/#caracteristicas-principales","text":"Arquitectura de Microservicios - Servicios independientes y escalables API RESTful - Interfaz unificada para todas las operaciones Dashboard Administrativo - Panel de control en tiempo real Gesti\u00f3n de Usuarios - Sistema robusto de roles y permisos Reportes Automatizados - Generaci\u00f3n de informes personalizables","title":"\u26a1 Caracter\u00edsticas Principales"},{"location":"proyectos/proyecto-1/#arquitectura","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Load Balancer (Nginx) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u25bc \u25bc \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 API \u2502 \u2502 Auth \u2502 \u2502 Admin \u2502 \u2502 Gateway \u2502 \u2502 Service \u2502 \u2502 UI \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Message Queue \u2502 \u2502 (RabbitMQ) \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u25bc \u25bc \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Users \u2502 \u2502 Reports \u2502 \u2502 Files \u2502 \u2502 Service \u2502 \u2502 Service \u2502 \u2502 Service \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u25bc \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 PostgreSQL DB \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"\ud83c\udfd7\ufe0f Arquitectura"},{"location":"proyectos/proyecto-1/#secciones-de-documentacion","text":"\ud83d\ude80 Getting Started - Instalaci\u00f3n y configuraci\u00f3n inicial \ud83d\udce1 API Reference - Documentaci\u00f3n completa de la API \ud83d\udcd6 Guides - Gu\u00edas detalladas y mejores pr\u00e1cticas \ud83d\udca1 Examples - Ejemplos de c\u00f3digo y casos de uso","title":"\ud83d\udcda Secciones de Documentaci\u00f3n"},{"location":"proyectos/proyecto-1/#enlaces-utiles","text":"GitHub Repository Issue Tracker Changelog","title":"\ud83d\udd17 Enlaces \u00datiles"},{"location":"proyectos/proyecto-1/#estado-del-proyecto","text":"Versi\u00f3n Actual: 2.3.1 \u00daltima Actualizaci\u00f3n: Octubre 2024 Estado: \ud83d\udfe2 Producci\u00f3n","title":"\ud83d\udcca Estado del Proyecto"},{"location":"proyectos/proyecto-1/api/","text":"\ud83d\udce1 API Reference - Proyecto 1 Endpoints Disponibles Autenticaci\u00f3n POST /api/auth/login Autentica un usuario y devuelve un token JWT. Request: { \"email\": \"usuario@ejemplo.com\", \"password\": \"contrase\u00f1a123\" } Response: { \"token\": \"eyJhbGciOiJIUzI1NiIs...\", \"user\": { \"id\": \"123\", \"email\": \"usuario@ejemplo.com\", \"name\": \"Usuario Ejemplo\" } } Usuarios GET /api/users Obtiene lista de usuarios (requiere autenticaci\u00f3n admin). GET /api/users/{id} Obtiene informaci\u00f3n de un usuario espec\u00edfico. POST /api/users Crea un nuevo usuario. PUT /api/users/{id} Actualiza informaci\u00f3n de usuario. C\u00f3digos de Estado 200 - Operaci\u00f3n exitosa 201 - Recurso creado 400 - Petici\u00f3n inv\u00e1lida 401 - No autorizado 403 - Prohibido 404 - No encontrado 500 - Error del servidor","title":"\ud83d\udce1 API Reference - Proyecto 1"},{"location":"proyectos/proyecto-1/api/#api-reference-proyecto-1","text":"","title":"\ud83d\udce1 API Reference - Proyecto 1"},{"location":"proyectos/proyecto-1/api/#endpoints-disponibles","text":"","title":"Endpoints Disponibles"},{"location":"proyectos/proyecto-1/api/#autenticacion","text":"","title":"Autenticaci\u00f3n"},{"location":"proyectos/proyecto-1/api/#post-apiauthlogin","text":"Autentica un usuario y devuelve un token JWT. Request: { \"email\": \"usuario@ejemplo.com\", \"password\": \"contrase\u00f1a123\" } Response: { \"token\": \"eyJhbGciOiJIUzI1NiIs...\", \"user\": { \"id\": \"123\", \"email\": \"usuario@ejemplo.com\", \"name\": \"Usuario Ejemplo\" } }","title":"POST /api/auth/login"},{"location":"proyectos/proyecto-1/api/#usuarios","text":"","title":"Usuarios"},{"location":"proyectos/proyecto-1/api/#get-apiusers","text":"Obtiene lista de usuarios (requiere autenticaci\u00f3n admin).","title":"GET /api/users"},{"location":"proyectos/proyecto-1/api/#get-apiusersid","text":"Obtiene informaci\u00f3n de un usuario espec\u00edfico.","title":"GET /api/users/{id}"},{"location":"proyectos/proyecto-1/api/#post-apiusers","text":"Crea un nuevo usuario.","title":"POST /api/users"},{"location":"proyectos/proyecto-1/api/#put-apiusersid","text":"Actualiza informaci\u00f3n de usuario.","title":"PUT /api/users/{id}"},{"location":"proyectos/proyecto-1/api/#codigos-de-estado","text":"200 - Operaci\u00f3n exitosa 201 - Recurso creado 400 - Petici\u00f3n inv\u00e1lida 401 - No autorizado 403 - Prohibido 404 - No encontrado 500 - Error del servidor","title":"C\u00f3digos de Estado"},{"location":"proyectos/proyecto-1/examples/","text":"Examples - Proyecto 1","title":"Examples - Proyecto 1"},{"location":"proyectos/proyecto-1/examples/#examples-proyecto-1","text":"","title":"Examples - Proyecto 1"},{"location":"proyectos/proyecto-1/getting-started/","text":"\ud83d\ude80 Getting Started - Proyecto 1 Requisitos Previos Python 3.8+ PostgreSQL 12+ Docker y Docker Compose Redis 6+ Instalaci\u00f3n R\u00e1pida 1. Clonar el Repositorio git clone https://github.com/tu-usuario/proyecto-1.git cd proyecto-1 2. Configurar Variables de Entorno cp .env.example .env # Editar .env con tus configuraciones 3. Iniciar con Docker Compose docker-compose up -d 4. Ejecutar Migraciones docker-compose exec api python manage.py migrate 5. Crear Usuario Administrador docker-compose exec api python manage.py createsuperuser Verificar Instalaci\u00f3n Accede a: - API: http://localhost:8000 - Admin UI: http://localhost:3000 - Documentaci\u00f3n API: http://localhost:8000/docs Pr\u00f3ximos Pasos Consulta la API Reference para detalles de endpoints Revisa las Gu\u00edas para configuraci\u00f3n avanzada Explora los Ejemplos para casos de uso comunes","title":"\ud83d\ude80 Getting Started - Proyecto 1"},{"location":"proyectos/proyecto-1/getting-started/#getting-started-proyecto-1","text":"","title":"\ud83d\ude80 Getting Started - Proyecto 1"},{"location":"proyectos/proyecto-1/getting-started/#requisitos-previos","text":"Python 3.8+ PostgreSQL 12+ Docker y Docker Compose Redis 6+","title":"Requisitos Previos"},{"location":"proyectos/proyecto-1/getting-started/#instalacion-rapida","text":"","title":"Instalaci\u00f3n R\u00e1pida"},{"location":"proyectos/proyecto-1/getting-started/#1-clonar-el-repositorio","text":"git clone https://github.com/tu-usuario/proyecto-1.git cd proyecto-1","title":"1. Clonar el Repositorio"},{"location":"proyectos/proyecto-1/getting-started/#2-configurar-variables-de-entorno","text":"cp .env.example .env # Editar .env con tus configuraciones","title":"2. Configurar Variables de Entorno"},{"location":"proyectos/proyecto-1/getting-started/#3-iniciar-con-docker-compose","text":"docker-compose up -d","title":"3. Iniciar con Docker Compose"},{"location":"proyectos/proyecto-1/getting-started/#4-ejecutar-migraciones","text":"docker-compose exec api python manage.py migrate","title":"4. Ejecutar Migraciones"},{"location":"proyectos/proyecto-1/getting-started/#5-crear-usuario-administrador","text":"docker-compose exec api python manage.py createsuperuser","title":"5. Crear Usuario Administrador"},{"location":"proyectos/proyecto-1/getting-started/#verificar-instalacion","text":"Accede a: - API: http://localhost:8000 - Admin UI: http://localhost:3000 - Documentaci\u00f3n API: http://localhost:8000/docs","title":"Verificar Instalaci\u00f3n"},{"location":"proyectos/proyecto-1/getting-started/#proximos-pasos","text":"Consulta la API Reference para detalles de endpoints Revisa las Gu\u00edas para configuraci\u00f3n avanzada Explora los Ejemplos para casos de uso comunes","title":"Pr\u00f3ximos Pasos"},{"location":"proyectos/proyecto-1/guides/","text":"Guides - Proyecto 1","title":"Guides - Proyecto 1"},{"location":"proyectos/proyecto-1/guides/#guides-proyecto-1","text":"","title":"Guides - Proyecto 1"},{"location":"proyectos/proyecto-2/","text":"Proyecto 2: Aplicaci\u00f3n M\u00f3vil E-commerce \ud83d\udcd6 Descripci\u00f3n General Aplicaci\u00f3n m\u00f3vil multiplataforma para comercio electr\u00f3nico con soporte offline y sincronizaci\u00f3n en tiempo real. \u26a1 Caracter\u00edsticas Principales Multiplataforma - iOS y Android desde un \u00fanico c\u00f3digo base Modo Offline - Funcionalidad completa sin conexi\u00f3n Push Notifications - Notificaciones personalizadas Pagos Integrados - Stripe, PayPal, Apple Pay, Google Pay Geolocalizaci\u00f3n - Tiendas cercanas y env\u00edos \ud83d\udcf1 Pantallas Principales Cat\u00e1logo de productos Carrito de compras Perfil de usuario Historial de pedidos Favoritos Chat de soporte \ud83d\udcda Documentaci\u00f3n \ud83d\ude80 Getting Started \ud83d\udce1 API Reference \ud83d\udcd6 Guides \ud83d\udca1 Examples \ud83d\udd17 Enlaces GitHub Repository App Store Google Play","title":"Proyecto 2: Aplicaci\u00f3n M\u00f3vil E-commerce"},{"location":"proyectos/proyecto-2/#proyecto-2-aplicacion-movil-e-commerce","text":"","title":"Proyecto 2: Aplicaci\u00f3n M\u00f3vil E-commerce"},{"location":"proyectos/proyecto-2/#descripcion-general","text":"Aplicaci\u00f3n m\u00f3vil multiplataforma para comercio electr\u00f3nico con soporte offline y sincronizaci\u00f3n en tiempo real.","title":"\ud83d\udcd6 Descripci\u00f3n General"},{"location":"proyectos/proyecto-2/#caracteristicas-principales","text":"Multiplataforma - iOS y Android desde un \u00fanico c\u00f3digo base Modo Offline - Funcionalidad completa sin conexi\u00f3n Push Notifications - Notificaciones personalizadas Pagos Integrados - Stripe, PayPal, Apple Pay, Google Pay Geolocalizaci\u00f3n - Tiendas cercanas y env\u00edos","title":"\u26a1 Caracter\u00edsticas Principales"},{"location":"proyectos/proyecto-2/#pantallas-principales","text":"Cat\u00e1logo de productos Carrito de compras Perfil de usuario Historial de pedidos Favoritos Chat de soporte","title":"\ud83d\udcf1 Pantallas Principales"},{"location":"proyectos/proyecto-2/#documentacion","text":"\ud83d\ude80 Getting Started \ud83d\udce1 API Reference \ud83d\udcd6 Guides \ud83d\udca1 Examples","title":"\ud83d\udcda Documentaci\u00f3n"},{"location":"proyectos/proyecto-2/#enlaces","text":"GitHub Repository App Store Google Play","title":"\ud83d\udd17 Enlaces"},{"location":"proyectos/proyecto-2/api/","text":"API Reference - Proyecto 2","title":"API Reference - Proyecto 2"},{"location":"proyectos/proyecto-2/api/#api-reference-proyecto-2","text":"","title":"API Reference - Proyecto 2"},{"location":"proyectos/proyecto-2/examples/","text":"Examples - Proyecto 2","title":"Examples - Proyecto 2"},{"location":"proyectos/proyecto-2/examples/#examples-proyecto-2","text":"","title":"Examples - Proyecto 2"},{"location":"proyectos/proyecto-2/getting-started/","text":"Getting Started - Proyecto 2","title":"Getting Started - Proyecto 2"},{"location":"proyectos/proyecto-2/getting-started/#getting-started-proyecto-2","text":"","title":"Getting Started - Proyecto 2"},{"location":"proyectos/proyecto-2/guides/","text":"Guides - Proyecto 2","title":"Guides - Proyecto 2"},{"location":"proyectos/proyecto-2/guides/#guides-proyecto-2","text":"","title":"Guides - Proyecto 2"},{"location":"proyectos/proyecto-3/","text":"Proyecto 3: API REST Integraciones","title":"Proyecto 3: API REST Integraciones"},{"location":"proyectos/proyecto-3/#proyecto-3-api-rest-integraciones","text":"","title":"Proyecto 3: API REST Integraciones"},{"location":"proyectos/proyecto-3/api/","text":"API Reference - Proyecto 3","title":"API Reference - Proyecto 3"},{"location":"proyectos/proyecto-3/api/#api-reference-proyecto-3","text":"","title":"API Reference - Proyecto 3"},{"location":"proyectos/proyecto-3/examples/","text":"Examples - Proyecto 3","title":"Examples - Proyecto 3"},{"location":"proyectos/proyecto-3/examples/#examples-proyecto-3","text":"","title":"Examples - Proyecto 3"},{"location":"proyectos/proyecto-3/getting-started/","text":"Getting Started - Proyecto 3","title":"Getting Started - Proyecto 3"},{"location":"proyectos/proyecto-3/getting-started/#getting-started-proyecto-3","text":"","title":"Getting Started - Proyecto 3"},{"location":"proyectos/proyecto-3/guides/","text":"Guides - Proyecto 3","title":"Guides - Proyecto 3"},{"location":"proyectos/proyecto-3/guides/#guides-proyecto-3","text":"","title":"Guides - Proyecto 3"},{"location":"tutorial/advanced/","text":"Advanced Beyond the basic configuration and content Once you've got the Set up Project section, you can customize further using this guide. Or skip this and go to Usage . Navbar nesting You can add an additional level to your navbar like this: nav: - Home: index.md - About: about.md - Foo: - Overview: foo/index.md - Bar: foo/bar.md The value can either be a string (as in the first case) or a map (as in the last case). This seems to be a YAML limitation but see also issue #1139 . Add config options See Configuration page on MkDocs site for options. Separate docs directory approach You can also structure your project to have the set up above nested inside a docs directory. This is useful you have a few other directories and you want to keep the project root clean. docs/ docs/ index.md theme/ main.html nav.html toc.html mkdocs.yml An example of this is the Poetry repo. That project is also how I got into MkDocs in the first place. Embedding To embed a gist, just copy and paste the embed script URL which is provided on a gist. e.g. <script src=\"https://gist.github.com/MichaelCurrin/57caae30bd7b0991098e9804a9494c23.js\"></script>","title":"Advanced"},{"location":"tutorial/advanced/#advanced","text":"Beyond the basic configuration and content Once you've got the Set up Project section, you can customize further using this guide. Or skip this and go to Usage .","title":"Advanced"},{"location":"tutorial/advanced/#navbar-nesting","text":"You can add an additional level to your navbar like this: nav: - Home: index.md - About: about.md - Foo: - Overview: foo/index.md - Bar: foo/bar.md The value can either be a string (as in the first case) or a map (as in the last case). This seems to be a YAML limitation but see also issue #1139 .","title":"Navbar nesting"},{"location":"tutorial/advanced/#add-config-options","text":"See Configuration page on MkDocs site for options.","title":"Add config options"},{"location":"tutorial/advanced/#separate-docs-directory-approach","text":"You can also structure your project to have the set up above nested inside a docs directory. This is useful you have a few other directories and you want to keep the project root clean. docs/ docs/ index.md theme/ main.html nav.html toc.html mkdocs.yml An example of this is the Poetry repo. That project is also how I got into MkDocs in the first place.","title":"Separate docs directory approach"},{"location":"tutorial/advanced/#embedding","text":"To embed a gist, just copy and paste the embed script URL which is provided on a gist. e.g. <script src=\"https://gist.github.com/MichaelCurrin/57caae30bd7b0991098e9804a9494c23.js\"></script>","title":"Embedding"},{"location":"tutorial/deploy/","text":"Deploy Build and deploy to a remote public site See Deploying Your Docs on the Mkdocs site for more details. GitHub Pages How to deploy your docs site to GitHub Pages. Follow one of the approaches below: Run deploy command - Run a MkDocs CLI command locally to deploy. Deploy with GitHub Actions - Use the project's CI workflow in the cloud to build and deploy to GH Pages on commits pushed to master. Then go to your repo's Settings and Pages then enable GitHub Pages on the gh-pages branch's root. Note this is for a Project Page on a subpath, you will have to make adjustments to the command below if you want an Organization or User Page on the root path. Run deploy command Run a MkDocs CLI command locally to deploy MkDocs needs to know where to publish commits on GitHub - so make sure you are working with a repo that you cloned, or that you initialize the local repo and add a remote repo. Run this command locally: $ make d That will use Makefile to run the following: $ mkdocs gh-deploy --strict --force That will do the following: Clean and build to site directory. Force push to gh-pages branch, overwriting any changes which were pushed from another build. Then go to your repo on GitHub, look at the Environment tab. When it is done building, click View deployment to see your site. e.g. michaelcurrin.github.io/mkdocs-quickstart/ See deploy options in the help: $ mkdocs gh-deploy --help Deploy with GitHub Actions Set up continuous deployment config to enable deploys on a change to files on GitHub When you make changes to your docs config or the docs directory, especially editing on GitHub directly, it's often useful to have the docs site build and deploy automatically in a remote environment. This is provided for free by GitHub. See the docs.yml workflow provided with this project. You don't have to change anything there. The token will be generated for you by GitHub Actions.","title":"Deploy"},{"location":"tutorial/deploy/#deploy","text":"Build and deploy to a remote public site See Deploying Your Docs on the Mkdocs site for more details.","title":"Deploy"},{"location":"tutorial/deploy/#github-pages","text":"How to deploy your docs site to GitHub Pages. Follow one of the approaches below: Run deploy command - Run a MkDocs CLI command locally to deploy. Deploy with GitHub Actions - Use the project's CI workflow in the cloud to build and deploy to GH Pages on commits pushed to master. Then go to your repo's Settings and Pages then enable GitHub Pages on the gh-pages branch's root. Note this is for a Project Page on a subpath, you will have to make adjustments to the command below if you want an Organization or User Page on the root path.","title":"GitHub Pages"},{"location":"tutorial/deploy/#run-deploy-command","text":"Run a MkDocs CLI command locally to deploy MkDocs needs to know where to publish commits on GitHub - so make sure you are working with a repo that you cloned, or that you initialize the local repo and add a remote repo. Run this command locally: $ make d That will use Makefile to run the following: $ mkdocs gh-deploy --strict --force That will do the following: Clean and build to site directory. Force push to gh-pages branch, overwriting any changes which were pushed from another build. Then go to your repo on GitHub, look at the Environment tab. When it is done building, click View deployment to see your site. e.g. michaelcurrin.github.io/mkdocs-quickstart/ See deploy options in the help: $ mkdocs gh-deploy --help","title":"Run deploy command"},{"location":"tutorial/deploy/#deploy-with-github-actions","text":"Set up continuous deployment config to enable deploys on a change to files on GitHub When you make changes to your docs config or the docs directory, especially editing on GitHub directly, it's often useful to have the docs site build and deploy automatically in a remote environment. This is provided for free by GitHub. See the docs.yml workflow provided with this project. You don't have to change anything there. The token will be generated for you by GitHub Actions.","title":"Deploy with GitHub Actions"},{"location":"tutorial/installation/","text":"Installation How to install MkDocs locally. Requirements Python 3 Make - standard on macOS and Linux but can be installed on Windows too. Install system dependencies Set up a new repo Follow the Tutorial page to set up a project from scratch. Or click this create your own copy of the repo. Then clone your repo. e.g. $ git clone git@github.com:MichaelCurrin/mkdocs-quickstart.git $ cd mkdocs-quickstart Install project dependencies Install MkDocs locally For more info, see the Installation page on the MkDocs site. Install in a virtual environment Create a virtual environment at the project root - this is used to isolate project packages from the global packages. $ python3 -m venv venv Activate the environment. $ source venv/bin/activate Install mkdocs - this is covered in the project requirements file. $ cd docs $ make install Note - mkdocs 1.2 causes a break on force pushes, so this is excluded in the requirements. See issue #2447 . Install globally If you prefer to install MkDocs once and reuse it across projects, then you can install it globally instead. MkDocs is available using package managers like apt-get , homebrew and yum . Or you can install like this: $ python3 -m pip install mkdocs If you get prompted for sudo use, then cancel and run again with -U flag for user-level install.","title":"Installation"},{"location":"tutorial/installation/#installation","text":"How to install MkDocs locally.","title":"Installation"},{"location":"tutorial/installation/#requirements","text":"Python 3 Make - standard on macOS and Linux but can be installed on Windows too.","title":"Requirements"},{"location":"tutorial/installation/#install-system-dependencies","text":"","title":"Install system dependencies"},{"location":"tutorial/installation/#set-up-a-new-repo","text":"Follow the Tutorial page to set up a project from scratch. Or click this create your own copy of the repo. Then clone your repo. e.g. $ git clone git@github.com:MichaelCurrin/mkdocs-quickstart.git $ cd mkdocs-quickstart","title":"Set up a new repo"},{"location":"tutorial/installation/#install-project-dependencies","text":"Install MkDocs locally For more info, see the Installation page on the MkDocs site.","title":"Install project dependencies"},{"location":"tutorial/installation/#install-in-a-virtual-environment","text":"Create a virtual environment at the project root - this is used to isolate project packages from the global packages. $ python3 -m venv venv Activate the environment. $ source venv/bin/activate Install mkdocs - this is covered in the project requirements file. $ cd docs $ make install Note - mkdocs 1.2 causes a break on force pushes, so this is excluded in the requirements. See issue #2447 .","title":"Install in a virtual environment"},{"location":"tutorial/installation/#install-globally","text":"If you prefer to install MkDocs once and reuse it across projects, then you can install it globally instead. MkDocs is available using package managers like apt-get , homebrew and yum . Or you can install like this: $ python3 -m pip install mkdocs If you get prompted for sudo use, then cancel and run again with -U flag for user-level install.","title":"Install globally"},{"location":"tutorial/setup-project/","text":"Set up project How to create a MkDocs site from scratch This is a summary of the tutorial on mkdocs.org . How to use this guide Use one of the approaches below: Create a quickstart project with the new command covered in Create a starter site . Follow the extended guide to create a Set up docs site by hand. Basic structure This is the simplest MkDocs site you can make: docs/ index.md - Homepage in the docs directory (by default). mkdocs.yml Config at the root - control appearance and navigation of your site. See this project's docs/mkdocs.yml file on GitHub. Notes on fields for the config: site_name - title of your site. site_description - used as a description for SEO and you could use it somewhere in your template. site_url - now a required field when running a deploy. Include the subpath on the domain. If your site is not ready to be hosted, set this field to an empty string. repo_url - for Edit on GitHub button. See docs . edit_uri - defaults to edit/master/docs/ , which includes docs directory of markdown files inside your repo root. But, if the site's root is in an outer docs directory, then you need to also add that, so paths do not break. e.g. edit/master/docs/docs . See docs Requirements file A requirements file is optional but it can make it easier to manage dependencies. If you choose not use the file, make sure pip install mkdocs and pip install THEME lines are your instructions. If you want to add, then include requirements.txt at the root. If your project is already a Python project, you might prefer to add mkdocs in requirements-dev.txt or at docs/requirements.txt to keep it isolated.This file should have mkdocs in it and also any themes if needed. Create a starter site Run this command to create a starter site. This make the steps below go quicker. cd my-project mkdocs new PATH The result will be same as the Basic structure defined above and will include minimal text content generated by the MkDocs CLI. This text is defined in the project's new.py module. Set up a docs site Tip: Optionally use the new command covered above to set up the config and index page first and then continue . Create doc pages. Create a docs directory. Create index.md as your homepage. Create other markdown pages (optional). Use placeholder content if you want to move on and then come back to expand them. If you have any existing markdown docs, these will work too. Set up config. Create mkdocs.yml at the project root. Set up a navbar there. Choose a theme. Create a favicon (optional). It will be picked up at this path: docs/img/favicon.ico . Add to your .gitignore . Add build directory. This will prevent it from being versioned on master branch. Add virtual environment, if using one. You project should now look this this: docs/ index.md More pages... mkdocs.yml .gitignore venv requirements.txt - optional Sample content Ignore file .gitignore site/ venv Navbar mkdocs.yml nav: - Home: index.md - About: about.md Themes Builtin Use a builtin theme that comes with MkDocs. The default. theme: mkdocs Using ReadTheDocs theme and alternative config syntax. theme: name: readthedocs Find more supported themes . If it doesn't immediately, you'll have to use pip to install it and add to a requirements.txt file. ReadTheDocs Dropdown theme See below using mkdocs-rtd-dropdown . requirements.txt : mkdocs-rtd-dropdown mkdocs.yml : theme: name: 'rtd-dropdown' Material for MkdDocs theme See the MkDocs for Material homepage. See the Set up page for config options. requirements.txt : mkdocs-material-extensions>=1.0 mkdocs.yml : theme: name: 'material'","title":"Set up project"},{"location":"tutorial/setup-project/#set-up-project","text":"How to create a MkDocs site from scratch This is a summary of the tutorial on mkdocs.org .","title":"Set up project"},{"location":"tutorial/setup-project/#how-to-use-this-guide","text":"Use one of the approaches below: Create a quickstart project with the new command covered in Create a starter site . Follow the extended guide to create a Set up docs site by hand.","title":"How to use this guide"},{"location":"tutorial/setup-project/#basic-structure","text":"This is the simplest MkDocs site you can make: docs/ index.md - Homepage in the docs directory (by default). mkdocs.yml Config at the root - control appearance and navigation of your site. See this project's docs/mkdocs.yml file on GitHub. Notes on fields for the config: site_name - title of your site. site_description - used as a description for SEO and you could use it somewhere in your template. site_url - now a required field when running a deploy. Include the subpath on the domain. If your site is not ready to be hosted, set this field to an empty string. repo_url - for Edit on GitHub button. See docs . edit_uri - defaults to edit/master/docs/ , which includes docs directory of markdown files inside your repo root. But, if the site's root is in an outer docs directory, then you need to also add that, so paths do not break. e.g. edit/master/docs/docs . See docs","title":"Basic structure"},{"location":"tutorial/setup-project/#requirements-file","text":"A requirements file is optional but it can make it easier to manage dependencies. If you choose not use the file, make sure pip install mkdocs and pip install THEME lines are your instructions. If you want to add, then include requirements.txt at the root. If your project is already a Python project, you might prefer to add mkdocs in requirements-dev.txt or at docs/requirements.txt to keep it isolated.This file should have mkdocs in it and also any themes if needed.","title":"Requirements file"},{"location":"tutorial/setup-project/#create-a-starter-site","text":"Run this command to create a starter site. This make the steps below go quicker. cd my-project mkdocs new PATH The result will be same as the Basic structure defined above and will include minimal text content generated by the MkDocs CLI. This text is defined in the project's new.py module.","title":"Create a starter site"},{"location":"tutorial/setup-project/#set-up-a-docs-site","text":"Tip: Optionally use the new command covered above to set up the config and index page first and then continue . Create doc pages. Create a docs directory. Create index.md as your homepage. Create other markdown pages (optional). Use placeholder content if you want to move on and then come back to expand them. If you have any existing markdown docs, these will work too. Set up config. Create mkdocs.yml at the project root. Set up a navbar there. Choose a theme. Create a favicon (optional). It will be picked up at this path: docs/img/favicon.ico . Add to your .gitignore . Add build directory. This will prevent it from being versioned on master branch. Add virtual environment, if using one. You project should now look this this: docs/ index.md More pages... mkdocs.yml .gitignore venv requirements.txt - optional","title":"Set up a docs site"},{"location":"tutorial/setup-project/#sample-content","text":"","title":"Sample content"},{"location":"tutorial/setup-project/#ignore-file","text":".gitignore site/ venv","title":"Ignore file"},{"location":"tutorial/setup-project/#navbar","text":"mkdocs.yml nav: - Home: index.md - About: about.md","title":"Navbar"},{"location":"tutorial/setup-project/#themes","text":"","title":"Themes"},{"location":"tutorial/setup-project/#builtin","text":"Use a builtin theme that comes with MkDocs. The default. theme: mkdocs Using ReadTheDocs theme and alternative config syntax. theme: name: readthedocs Find more supported themes . If it doesn't immediately, you'll have to use pip to install it and add to a requirements.txt file.","title":"Builtin"},{"location":"tutorial/setup-project/#readthedocs-dropdown-theme","text":"See below using mkdocs-rtd-dropdown . requirements.txt : mkdocs-rtd-dropdown mkdocs.yml : theme: name: 'rtd-dropdown'","title":"ReadTheDocs Dropdown theme"},{"location":"tutorial/setup-project/#material-for-mkddocs-theme","text":"See the MkDocs for Material homepage. See the Set up page for config options. requirements.txt : mkdocs-material-extensions>=1.0 mkdocs.yml : theme: name: 'material'","title":"Material for MkdDocs theme"},{"location":"tutorial/tldr/","text":"TL;DR A simplified version of the tutorial. Local setup Install pip install mkdocs Set up project mkdocs new . or Run mkdocs serve View on localhost:8000 Deploy to remote site Run deploy command locally Deploy to GitHub Pages mkdocs gh-deploy View published site on GitHub Pages at https://USERNAME.github.io/REPO-NAME/ Run continuous integration For CI/CD deploy, use GitHub Actions with an action such as Deploy MkDocs . Or use Netlify. This is not covered in this tutorial.","title":"TL;DR"},{"location":"tutorial/tldr/#tldr","text":"A simplified version of the tutorial.","title":"TL;DR"},{"location":"tutorial/tldr/#local-setup","text":"Install pip install mkdocs Set up project mkdocs new . or Run mkdocs serve View on localhost:8000","title":"Local setup"},{"location":"tutorial/tldr/#deploy-to-remote-site","text":"","title":"Deploy to remote site"},{"location":"tutorial/tldr/#run-deploy-command-locally","text":"Deploy to GitHub Pages mkdocs gh-deploy View published site on GitHub Pages at https://USERNAME.github.io/REPO-NAME/","title":"Run deploy command locally"},{"location":"tutorial/tldr/#run-continuous-integration","text":"For CI/CD deploy, use GitHub Actions with an action such as Deploy MkDocs . Or use Netlify. This is not covered in this tutorial.","title":"Run continuous integration"},{"location":"tutorial/usage/","text":"Usage Build and preview a site locally Make sure to run all commands from the docs directory, as that is where Makefile is. $ cd docs CLI help $ make help default: install all: install build h help: install: upgrade: s serve: b build: d deploy: Serve docs This will build the docs in memory (not to disk) and serve an auto-reloading server. $ make serve Then open in your browser: localhost:8000 Build docs Build docs site to site directory. This is useful for a CI flow. $ make build","title":"Usage"},{"location":"tutorial/usage/#usage","text":"Build and preview a site locally Make sure to run all commands from the docs directory, as that is where Makefile is. $ cd docs","title":"Usage"},{"location":"tutorial/usage/#cli-help","text":"$ make help default: install all: install build h help: install: upgrade: s serve: b build: d deploy:","title":"CLI help"},{"location":"tutorial/usage/#serve-docs","text":"This will build the docs in memory (not to disk) and serve an auto-reloading server. $ make serve Then open in your browser: localhost:8000","title":"Serve docs"},{"location":"tutorial/usage/#build-docs","text":"Build docs site to site directory. This is useful for a CI flow. $ make build","title":"Build docs"},{"location":"best-practices/","text":"Secure GitHub Repo Template A production-ready starting point with security-by-default for teams. What\u2019s included Standard repo layout (.github, workflows, CODEOWNERS, templates) CI: tests, lint, SAST (Semgrep), dependency audits, secret scanning (Gitleaks), optional container/IaC scan (Trivy) Code scanning (CodeQL) + SARIF upload Dependabot updates (npm, pip, GitHub Actions) Pre-commit hooks (detect-secrets, basic hygiene) Branch/merge conventions (documented in CONTRIBUTING.md) Security policy (SECURITY.md) and CODEOWNERS Replace @your-org/your-team and contact addresses with your own.","title":"Overview"},{"location":"best-practices/#secure-github-repo-template","text":"A production-ready starting point with security-by-default for teams.","title":"Secure GitHub Repo Template"},{"location":"best-practices/#whats-included","text":"Standard repo layout (.github, workflows, CODEOWNERS, templates) CI: tests, lint, SAST (Semgrep), dependency audits, secret scanning (Gitleaks), optional container/IaC scan (Trivy) Code scanning (CodeQL) + SARIF upload Dependabot updates (npm, pip, GitHub Actions) Pre-commit hooks (detect-secrets, basic hygiene) Branch/merge conventions (documented in CONTRIBUTING.md) Security policy (SECURITY.md) and CODEOWNERS Replace @your-org/your-team and contact addresses with your own.","title":"What\u2019s included"},{"location":"best-practices/CONTRIBUTING/","text":"Contributing & Secure Development Guidelines Branching model (trunk-based recommended) Default branch: main (protected). Short-lived feature branches from main : feat/<ticket>-short-desc fix/<ticket>-short-desc chore/<desc> , docs/<desc> , sec/<desc> for security hardening No direct commits to main . Always via PR with green CI and approvals. Merge method : prefer squash merge for clean history. Rebase locally if needed. Pull Requests Keep PRs small and focused. Include a clear description, risk assessment, and test evidence. Required : 1\u20132 approvals (incl. CODEOWNERS when touching owned paths). Resolve all comments and conversations before merge. CI must pass: tests, lint, SAST, secrets, deps. Keep branch up-to-date. Commit messages Follow Conventional Commits : e.g., feat(ui): add dark mode toggle , fix(api): handle 401 . Reference tickets (e.g., JIRA) in the footer. Secrets & credentials Never commit secrets. Use environment secrets or OIDC (see deploy-prod.yml example). Run pre-commit hooks to detect leaks before pushing. Dependency hygiene Keep dependencies minimal and pinned. Let Dependabot open PRs; review carefully. Avoid abandoned packages; prefer vendors with security track records. Secure coding checklist (quick) Validate all inputs; fail closed. Principle of least privilege (tokens, cloud roles, DB users). Store secrets in env or KMS; rotate regularly. Log security-relevant events (authz failures, admin actions). Avoid logging secrets. Review dangerous patterns (command exec, deserialization, SQL queries).","title":"Contributing"},{"location":"best-practices/CONTRIBUTING/#contributing-secure-development-guidelines","text":"","title":"Contributing &amp; Secure Development Guidelines"},{"location":"best-practices/CONTRIBUTING/#branching-model-trunk-based-recommended","text":"Default branch: main (protected). Short-lived feature branches from main : feat/<ticket>-short-desc fix/<ticket>-short-desc chore/<desc> , docs/<desc> , sec/<desc> for security hardening No direct commits to main . Always via PR with green CI and approvals. Merge method : prefer squash merge for clean history. Rebase locally if needed.","title":"Branching model (trunk-based recommended)"},{"location":"best-practices/CONTRIBUTING/#pull-requests","text":"Keep PRs small and focused. Include a clear description, risk assessment, and test evidence. Required : 1\u20132 approvals (incl. CODEOWNERS when touching owned paths). Resolve all comments and conversations before merge. CI must pass: tests, lint, SAST, secrets, deps. Keep branch up-to-date.","title":"Pull Requests"},{"location":"best-practices/CONTRIBUTING/#commit-messages","text":"Follow Conventional Commits : e.g., feat(ui): add dark mode toggle , fix(api): handle 401 . Reference tickets (e.g., JIRA) in the footer.","title":"Commit messages"},{"location":"best-practices/CONTRIBUTING/#secrets-credentials","text":"Never commit secrets. Use environment secrets or OIDC (see deploy-prod.yml example). Run pre-commit hooks to detect leaks before pushing.","title":"Secrets &amp; credentials"},{"location":"best-practices/CONTRIBUTING/#dependency-hygiene","text":"Keep dependencies minimal and pinned. Let Dependabot open PRs; review carefully. Avoid abandoned packages; prefer vendors with security track records.","title":"Dependency hygiene"},{"location":"best-practices/CONTRIBUTING/#secure-coding-checklist-quick","text":"Validate all inputs; fail closed. Principle of least privilege (tokens, cloud roles, DB users). Store secrets in env or KMS; rotate regularly. Log security-relevant events (authz failures, admin actions). Avoid logging secrets. Review dangerous patterns (command exec, deserialization, SQL queries).","title":"Secure coding checklist (quick)"},{"location":"best-practices/SECURITY/","text":"Security Policy Reporting a Vulnerability If you believe you\u2019ve found a security issue, do not open a public issue. Email security@yourcompany.com or use GitHub Security Advisories to privately report it. We aim to acknowledge within 2 business days and provide a remediation plan as soon as possible. Supported Versions We support the latest main branch and the most recent stable release tags. Hardening Protected branches with required reviews and status checks. Secret scanning & push protection enabled. Code scanning (CodeQL) and SAST in CI. Short\u2011lived cloud creds via OIDC for deployments.","title":"Security"},{"location":"best-practices/SECURITY/#security-policy","text":"","title":"Security Policy"},{"location":"best-practices/SECURITY/#reporting-a-vulnerability","text":"If you believe you\u2019ve found a security issue, do not open a public issue. Email security@yourcompany.com or use GitHub Security Advisories to privately report it. We aim to acknowledge within 2 business days and provide a remediation plan as soon as possible.","title":"Reporting a Vulnerability"},{"location":"best-practices/SECURITY/#supported-versions","text":"We support the latest main branch and the most recent stable release tags.","title":"Supported Versions"},{"location":"best-practices/SECURITY/#hardening","text":"Protected branches with required reviews and status checks. Secret scanning & push protection enabled. Code scanning (CodeQL) and SAST in CI. Short\u2011lived cloud creds via OIDC for deployments.","title":"Hardening"},{"location":"open-agentic-framework/","text":"Open Agentic Framework A sample framework implementation for creating and orchestrating AI agents, featuring multi-provider LLM support, intelligent memory management, and advanced workflow capabilities. Features AI Agent Management - Create agents with specific roles, goals, and capabilities Multi-Provider LLM Support - Ollama, OpenAI, OpenRouter with automatic fallback Extensible Tool System - Built-in tools with plugin architecture for custom integrations Advanced Workflow Orchestration - Chain agents and tools with intelligent variable resolution Smart Memory Management - Automatic memory limits, cleanup, and context filtering Model Warmup System - Pre-load models for instant response times Task Scheduling - Automated execution of agents and workflows Website Monitoring - Real-world example with email alerting capabilities Production Ready - Docker deployment with comprehensive monitoring Interactive API Documentation - Complete Swagger UI with live testing Web UI - Modern web interface for easy management and monitoring Quick Start Prerequisites Docker and Docker Compose 4GB+ available RAM Internet connection for downloading models 1. Clone and Deploy # Clone the repository git clone https://github.com/oscarvalenzuelab/open_agentic_framework.git cd open_agentic_framework # Start the framework docker-compose up -d # Wait for models to download (5-10 minutes) docker-compose logs -f model-downloader 2. Access the Framework & Documentation Web UI : http://localhost:8000/ui Interactive API Documentation : http://localhost:8000/docs Alternative Docs (ReDoc) : http://localhost:8000/redoc Health Check : http://localhost:8000/health Provider Status : http://localhost:8000/providers Available Models : http://localhost:8000/models Memory Statistics : http://localhost:8000/memory/stats Tip : The Swagger documentation at /docs provides a complete interactive interface to explore and test all API endpoints with live examples! 3. Create Your First Agent curl -X POST \"http://localhost:8000/agents\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"website_guardian\", \"role\": \"Website Monitoring Specialist\", \"goals\": \"Monitor websites and send alerts when issues are detected\", \"backstory\": \"You are an experienced system administrator responsible for ensuring high availability.\", \"tools\": [\"website_monitor\", \"email_sender\"], \"ollama_model\": \"granite3.2:2b\", \"enabled\": true }' 4. Execute Your First Task curl -X POST \"http://localhost:8000/agents/website_guardian/execute\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"task\": \"Check if https://google.com is online and report the status\", \"context\": {} }' Multi-Provider LLM Support The framework supports multiple LLM providers with automatic fallback and intelligent routing: Supported Providers Ollama - Local models (default) OpenAI - GPT models via API OpenRouter - Access to 100+ models Environment Configuration # Core LLM Configuration DEFAULT_LLM_PROVIDER=ollama # Primary provider LLM_FALLBACK_ENABLED=true # Enable automatic fallback LLM_FALLBACK_ORDER=ollama,openai,openrouter # Fallback priority order # Ollama Provider (Default) OLLAMA_ENABLED=true OLLAMA_URL=http://localhost:11434 OLLAMA_DEFAULT_MODEL=granite3.2:2b # OpenAI Provider OPENAI_ENABLED=false # Set to true to enable OPENAI_API_KEY=your-openai-api-key OPENAI_DEFAULT_MODEL=gpt-3.5-turbo OPENAI_ORGANIZATION=your-org-id # Optional # OpenRouter Provider OPENROUTER_ENABLED=false # Set to true to enable OPENROUTER_API_KEY=your-openrouter-api-key OPENROUTER_DEFAULT_MODEL=openai/gpt-3.5-turbo Dynamic Provider Management # Configure providers without restart curl -X POST \"http://localhost:8000/providers/openai/configure\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"enabled\": true, \"api_key\": \"your-new-api-key\", \"default_model\": \"gpt-4\" }' # Check all provider status curl http://localhost:8000/providers # Test specific model curl -X POST \"http://localhost:8000/models/test/gpt-3.5-turbo\" Model Warmup System Advanced model pre-loading for instant response times: # Model warmup configuration MODEL_WARMUP_TIMEOUT=60 # Warmup timeout (seconds) MAX_CONCURRENT_WARMUPS=2 # Concurrent warmup operations AUTO_WARMUP_ON_STARTUP=true # Auto-warm agent models WARMUP_INTERVAL_HOURS=6 # Re-warm interval MAX_IDLE_HOURS=24 # Remove unused models after Features: - Instant Responses - Pre-loaded models respond immediately - Usage Tracking - Monitors which models are actively used - Automatic Cleanup - Removes unused models to save memory - Smart Refresh - Re-warms models periodically Core Concepts Understanding the framework's key components: Agent An intelligent entity with a specific role, goals, and capabilities. Agents can use tools to accomplish tasks and maintain conversation memory. { \"name\": \"website_guardian\", \"role\": \"Website Monitoring Specialist\", \"goals\": \"Monitor websites and send alerts when issues detected\", \"backstory\": \"Experienced system administrator with 10+ years experience\", \"tools\": [\"website_monitor\", \"email_sender\"], \"ollama_model\": \"granite3.2:2b\", \"tool_configs\": { \"email_sender\": { \"smtp_host\": \"smtp.gmail.com\", \"smtp_port\": 587, \"smtp_username\": \"alerts@company.com\", \"smtp_password\": \"app-password\" } } } Task A specific instruction or request given to an agent. Tasks are processed by agents using their available tools and knowledge. # Example task \"Check if https://google.com is online and send an email alert if it's down\" Tool A specific capability or function that agents can use to interact with external systems, APIs, or perform specific operations. Built-in Tools: - website_monitor - Check website availability and response time - email_sender - Send emails via SMTP - http_client - Make HTTP requests to APIs Workflow A sequence of steps that can include both agent tasks and tool executions, with advanced variable passing between steps, input validation , and output filtering . { \"name\": \"website_health_check\", \"description\": \"Comprehensive website monitoring with input validation and output filtering\", \"input_schema\": { \"type\": \"object\", \"properties\": { \"target_url\": { \"type\": \"string\", \"description\": \"URL to monitor\" }, \"alert_email\": { \"type\": \"string\", \"description\": \"Email for alerts\" }, \"timeout\": { \"type\": \"integer\", \"description\": \"Timeout in seconds\", \"default\": 10 } }, \"required\": [\"target_url\", \"alert_email\"] }, \"output_spec\": { \"extractions\": [ { \"name\": \"status_summary\", \"type\": \"path\", \"query\": \"website_status.status\", \"default\": \"unknown\", \"format\": \"text\" }, { \"name\": \"response_time\", \"type\": \"path\", \"query\": \"website_status.response_time_ms\", \"default\": \"0\", \"format\": \"number\" } ] }, \"steps\": [ { \"type\": \"tool\", \"name\": \"website_monitor\", \"parameters\": {\"url\": \"{{target_url}}\", \"timeout\": \"{{timeout}}\"}, \"context_key\": \"website_status\" }, { \"type\": \"agent\", \"name\": \"website_guardian\", \"task\": \"Analyze status: {{website_status.response_time}}ms response from {{website_status.url}} and send alerts if needed\", \"context_key\": \"analysis_result\" } ] } Memory Conversation history and context maintained for each agent, with intelligent context filtering and automatic cleanup (default: 5 entries per agent). Scheduled Task Automated execution of agents or workflows at specified times or intervals. { \"task_type\": \"workflow\", \"workflow_name\": \"website_health_check\", \"scheduled_time\": \"2024-01-15T10:00:00Z\" } Creating Advanced Workflows Workflows support sophisticated variable substitution and nested object access: Variable Substitution System Use {{variable}} syntax to pass data between workflow steps: { \"name\": \"data_processing_pipeline\", \"steps\": [ { \"type\": \"tool\", \"name\": \"http_client\", \"parameters\": { \"url\": \"https://api.example.com/data/{{dataset_id}}\", \"headers\": {\"Authorization\": \"Bearer {{api_token}}\"} }, \"context_key\": \"api_response\" }, { \"type\": \"agent\", \"name\": \"data_analyst\", \"task\": \"Analyze this API response: {{api_response.data}} with status {{api_response.status}} for dataset {{dataset_id}}\", \"context_key\": \"analysis\" } ] } Nested Object Access Access nested properties from previous workflow steps: { \"task\": \"The API returned status {{api_response.status}} with {{api_response.data.total_records}} records. Send summary to {{user.email}}\" } Workflow Output Filtering Control what data is returned from workflow execution using the output_spec field. This allows you to extract specific fields from the workflow context instead of returning all data. Basic Output Filtering { \"name\": \"license_assessment_workflow\", \"output_spec\": { \"extractions\": [ { \"name\": \"risk_assessment\", \"type\": \"path\", \"query\": \"risk_assessment\", \"default\": \"\", \"format\": \"text\" } ] } } Result: Only the risk_assessment data is returned in the output field, not the full workflow context. Advanced Output Filtering Extract multiple specific fields with different extraction types: { \"name\": \"comprehensive_monitoring\", \"output_spec\": { \"extractions\": [ { \"name\": \"overall_risk\", \"type\": \"path\", \"query\": \"risk_assessment.OVERALL RISK LEVEL\", \"default\": \"UNKNOWN\", \"format\": \"text\" }, { \"name\": \"security_score\", \"type\": \"path\", \"query\": \"risk_assessment.SECURITY ASSESSMENT.ClearlyDefined Score\", \"default\": \"0\", \"format\": \"number\" }, { \"name\": \"license_breakdown\", \"type\": \"path\", \"query\": \"risk_assessment.LICENSE ANALYSIS.License Breakdown\", \"default\": \"{}\", \"format\": \"text\" } ] } } Extraction Types path - Extract data using dot notation (e.g., \"risk_assessment.OVERALL RISK LEVEL\" ) regex - Extract using regular expressions literal - Return a literal value find - Find data in arrays using criteria join_field - Extract array and join field values with separator Format Options text - Return as-is (preserves JSON objects/arrays) number - Convert to number boolean - Convert to boolean Input Validation Use input_schema to validate workflow inputs: { \"name\": \"validated_workflow\", \"input_schema\": { \"type\": \"object\", \"properties\": { \"package_name\": { \"type\": \"string\", \"description\": \"Package name to analyze\" }, \"analysis_depth\": { \"type\": \"string\", \"enum\": [\"basic\", \"comprehensive\"], \"default\": \"basic\" } }, \"required\": [\"package_name\"] } } Benefits: - Clean Output - Only relevant data is returned - Reduced Payload - Smaller response sizes - Better Integration - Easier to consume in other systems - Input Validation - Ensures required parameters are provided - Type Safety - Validates input types and formats Tool Configuration per Agent Configure tools differently for each agent to customize their behavior: Email Sender Configuration curl -X POST \"http://localhost:8000/agents\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"notification_agent\", \"role\": \"Notification Specialist\", \"goals\": \"Send professional email notifications and alerts\", \"backstory\": \"You are an experienced communication specialist who sends clear, actionable notifications.\", \"tools\": [\"email_sender\", \"webhook_client\"], \"ollama_model\": \"granite3.2:2b\", \"enabled\": true, \"tool_configs\": { \"email_sender\": { \"smtp_host\": \"smtp.gmail.com\", \"smtp_port\": 587, \"smtp_username\": \"alerts@yourcompany.com\", \"smtp_password\": \"your-app-password\", \"from_email\": \"AI Assistant <alerts@yourcompany.com>\", \"default_template\": \"professional\" }, \"webhook_client\": { \"default_timeout\": 30, \"retry_attempts\": 3 } } }' Website Monitor Configuration curl -X POST \"http://localhost:8000/agents\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"monitoring_agent\", \"role\": \"System Monitoring Specialist\", \"goals\": \"Monitor system health and performance\", \"backstory\": \"You are a vigilant system administrator who monitors infrastructure and reports issues.\", \"tools\": [\"website_monitor\", \"http_client\"], \"ollama_model\": \"deepseek-r1:1.5b\", \"enabled\": true, \"tool_configs\": { \"website_monitor\": { \"default_timeout\": 15, \"retry_attempts\": 2, \"expected_status_codes\": [200, 301, 302] }, \"http_client\": { \"default_timeout\": 30, \"max_redirects\": 5, \"verify_ssl\": true } } }' Benefits of Tool Configuration: - Customized Behavior - Each agent can have different tool settings - Environment-Specific - Configure for development, staging, or production - Security - Set different credentials per agent - Performance - Optimize timeouts and retry settings per use case Enhanced Memory Management Advanced memory features with intelligent cleanup: Memory Statistics & Cleanup # Get detailed memory statistics curl http://localhost:8000/memory/stats # Example response: { \"total_memory_entries\": 45, \"agents_with_memory\": 3, \"memory_per_agent\": { \"website_guardian\": 12, \"data_analyst\": 8, \"license_assessor\": 25 }, \"oldest_entry\": \"2024-06-09T10:00:00Z\", \"newest_entry\": \"2024-06-10T14:30:00Z\" } # Intelligent cleanup (keeps last N entries per agent) curl -X POST \"http://localhost:8000/memory/cleanup\" # Clear all memory (nuclear option) curl -X DELETE \"http://localhost:8000/memory/clear-all\" # Clear specific agent memory curl -X DELETE \"http://localhost:8000/agents/website_guardian/memory\" Memory Configuration # Memory Management Settings MAX_AGENT_MEMORY_ENTRIES=5 # Max memory per agent CLEAR_MEMORY_ON_STARTUP=false # Clear memory on restart MEMORY_CLEANUP_INTERVAL=3600 # Cleanup interval (seconds) MEMORY_RETENTION_DAYS=7 # Days to keep old entries API Documentation Interactive Swagger Documentation Access the complete API documentation with interactive testing capabilities: http://localhost:8000/docs The Swagger interface provides: - Complete endpoint documentation - Live API Testing - Test endpoints directly from the browser - Request/response schemas with examples - Authentication options - Code Generation - Generate client code in multiple languages - Schema Explorer - Browse all data models and their properties Alternative Documentation Formats ReDoc : http://localhost:8000/redoc (Clean, responsive documentation) OpenAPI JSON : http://localhost:8000/openapi.json (Raw OpenAPI specification) Key API Sections Providers ( /providers ) - Multi-provider LLM management Models ( /models ) - Model discovery and testing Agents ( /agents ) - Create and manage AI agents Tools ( /tools ) - Execute and manage tools Workflows ( /workflows ) - Create and execute workflows Memory ( /memory ) - Advanced memory management Schedule ( /schedule ) - Schedule automated tasks System ( /health , /config ) - System monitoring and configuration Complete Website Monitoring Example Click to expand complete monitoring system setup # 1. Create monitoring agent with email configuration curl -X POST \"http://localhost:8000/agents\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"website_guardian\", \"role\": \"Website Monitoring Guardian\", \"goals\": \"Ensure critical websites are always online and notify immediately when issues are detected\", \"backstory\": \"You are a vigilant system monitor with years of experience in maintaining high-availability systems. You check websites systematically and provide clear, actionable status reports.\", \"tools\": [\"website_monitor\", \"email_sender\"], \"ollama_model\": \"deepseek-r1:1.5b\", \"enabled\": true, \"tool_configs\": { \"email_sender\": { \"smtp_host\": \"smtp.gmail.com\", \"smtp_port\": 587, \"smtp_username\": \"alerts@yourcompany.com\", \"smtp_password\": \"your-app-password\", \"from_email\": \"Website Guardian <alerts@yourcompany.com>\" } } }' # 2. Create monitoring workflow with intelligent analysis curl -X POST \"http://localhost:8000/workflows\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"website_health_check\", \"description\": \"Comprehensive website monitoring with intelligent alerts\", \"input_schema\": { \"type\": \"object\", \"properties\": { \"target_url\": { \"type\": \"string\", \"description\": \"URL to monitor\" }, \"alert_email\": { \"type\": \"string\", \"description\": \"Email for alerts\" }, \"timeout\": { \"type\": \"integer\", \"description\": \"Timeout in seconds\", \"default\": 10 } }, \"required\": [\"target_url\", \"alert_email\"] }, \"output_spec\": { \"extractions\": [ { \"name\": \"status\", \"type\": \"path\", \"query\": \"website_status.status\", \"default\": \"unknown\", \"format\": \"text\" }, { \"name\": \"response_time\", \"type\": \"path\", \"query\": \"website_status.response_time_ms\", \"default\": \"0\", \"format\": \"number\" }, { \"name\": \"analysis_summary\", \"type\": \"path\", \"query\": \"alert_result\", \"default\": \"\", \"format\": \"text\" } ] }, \"steps\": [ { \"type\": \"tool\", \"name\": \"website_monitor\", \"parameters\": { \"url\": \"{{target_url}}\", \"timeout\": \"{{timeout}}\", \"expected_status\": 200 }, \"context_key\": \"website_status\" }, { \"type\": \"agent\", \"name\": \"website_guardian\", \"task\": \"Analyze the website monitoring result: {{website_status}}. Check response time (should be <2000ms), status code, and any errors. If there are issues, send an email alert to {{alert_email}} with detailed analysis.\", \"context_key\": \"alert_result\" } ], \"enabled\": true }' # 3. Execute monitoring workflow curl -X POST \"http://localhost:8000/workflows/website_health_check/execute\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"context\": { \"target_url\": \"https://yourwebsite.com\", \"alert_email\": \"admin@yourcompany.com\" } }' # 4. Schedule regular monitoring (every 5 minutes) curl -X POST \"http://localhost:8000/schedule\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"task_type\": \"workflow\", \"workflow_name\": \"website_health_check\", \"scheduled_time\": \"2024-01-15T10:00:00Z\", \"context\": { \"recurring\": \"every_5_minutes\", \"target_url\": \"https://yourwebsite.com\", \"alert_email\": \"admin@yourcompany.com\" } }' Web UI The Open Agentic Framework includes a modern web interface that provides an intuitive way to manage your AI agents, workflows, and system configuration. Accessing the Web UI Once the framework is running, access the web interface at: http://localhost:8000/ui Contributing We welcome contributions! Please see our Contributing Guidelines for details. Development Process Fork the repository Create a feature branch ( git checkout -b feature/amazing-feature ) Commit your changes ( git commit -m 'Add amazing feature' ) Push to the branch ( git push origin feature/amazing-feature ) Open a Pull Request License This project is licensed under the MIT License - see the LICENSE file for details. Acknowledgments FastAPI for the excellent web framework Ollama for local LLM capabilities OpenAI for pioneering AI APIs SQLAlchemy for robust database management Pydantic for data validation","title":"Overview"},{"location":"open-agentic-framework/#open-agentic-framework","text":"A sample framework implementation for creating and orchestrating AI agents, featuring multi-provider LLM support, intelligent memory management, and advanced workflow capabilities.","title":"Open Agentic Framework"},{"location":"open-agentic-framework/#features","text":"AI Agent Management - Create agents with specific roles, goals, and capabilities Multi-Provider LLM Support - Ollama, OpenAI, OpenRouter with automatic fallback Extensible Tool System - Built-in tools with plugin architecture for custom integrations Advanced Workflow Orchestration - Chain agents and tools with intelligent variable resolution Smart Memory Management - Automatic memory limits, cleanup, and context filtering Model Warmup System - Pre-load models for instant response times Task Scheduling - Automated execution of agents and workflows Website Monitoring - Real-world example with email alerting capabilities Production Ready - Docker deployment with comprehensive monitoring Interactive API Documentation - Complete Swagger UI with live testing Web UI - Modern web interface for easy management and monitoring","title":"Features"},{"location":"open-agentic-framework/#quick-start","text":"","title":"Quick Start"},{"location":"open-agentic-framework/#prerequisites","text":"Docker and Docker Compose 4GB+ available RAM Internet connection for downloading models","title":"Prerequisites"},{"location":"open-agentic-framework/#1-clone-and-deploy","text":"# Clone the repository git clone https://github.com/oscarvalenzuelab/open_agentic_framework.git cd open_agentic_framework # Start the framework docker-compose up -d # Wait for models to download (5-10 minutes) docker-compose logs -f model-downloader","title":"1. Clone and Deploy"},{"location":"open-agentic-framework/#2-access-the-framework-documentation","text":"Web UI : http://localhost:8000/ui Interactive API Documentation : http://localhost:8000/docs Alternative Docs (ReDoc) : http://localhost:8000/redoc Health Check : http://localhost:8000/health Provider Status : http://localhost:8000/providers Available Models : http://localhost:8000/models Memory Statistics : http://localhost:8000/memory/stats Tip : The Swagger documentation at /docs provides a complete interactive interface to explore and test all API endpoints with live examples!","title":"2. Access the Framework &amp; Documentation"},{"location":"open-agentic-framework/#3-create-your-first-agent","text":"curl -X POST \"http://localhost:8000/agents\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"website_guardian\", \"role\": \"Website Monitoring Specialist\", \"goals\": \"Monitor websites and send alerts when issues are detected\", \"backstory\": \"You are an experienced system administrator responsible for ensuring high availability.\", \"tools\": [\"website_monitor\", \"email_sender\"], \"ollama_model\": \"granite3.2:2b\", \"enabled\": true }'","title":"3. Create Your First Agent"},{"location":"open-agentic-framework/#4-execute-your-first-task","text":"curl -X POST \"http://localhost:8000/agents/website_guardian/execute\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"task\": \"Check if https://google.com is online and report the status\", \"context\": {} }'","title":"4. Execute Your First Task"},{"location":"open-agentic-framework/#multi-provider-llm-support","text":"The framework supports multiple LLM providers with automatic fallback and intelligent routing:","title":"Multi-Provider LLM Support"},{"location":"open-agentic-framework/#supported-providers","text":"Ollama - Local models (default) OpenAI - GPT models via API OpenRouter - Access to 100+ models","title":"Supported Providers"},{"location":"open-agentic-framework/#environment-configuration","text":"# Core LLM Configuration DEFAULT_LLM_PROVIDER=ollama # Primary provider LLM_FALLBACK_ENABLED=true # Enable automatic fallback LLM_FALLBACK_ORDER=ollama,openai,openrouter # Fallback priority order # Ollama Provider (Default) OLLAMA_ENABLED=true OLLAMA_URL=http://localhost:11434 OLLAMA_DEFAULT_MODEL=granite3.2:2b # OpenAI Provider OPENAI_ENABLED=false # Set to true to enable OPENAI_API_KEY=your-openai-api-key OPENAI_DEFAULT_MODEL=gpt-3.5-turbo OPENAI_ORGANIZATION=your-org-id # Optional # OpenRouter Provider OPENROUTER_ENABLED=false # Set to true to enable OPENROUTER_API_KEY=your-openrouter-api-key OPENROUTER_DEFAULT_MODEL=openai/gpt-3.5-turbo","title":"Environment Configuration"},{"location":"open-agentic-framework/#dynamic-provider-management","text":"# Configure providers without restart curl -X POST \"http://localhost:8000/providers/openai/configure\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"enabled\": true, \"api_key\": \"your-new-api-key\", \"default_model\": \"gpt-4\" }' # Check all provider status curl http://localhost:8000/providers # Test specific model curl -X POST \"http://localhost:8000/models/test/gpt-3.5-turbo\"","title":"Dynamic Provider Management"},{"location":"open-agentic-framework/#model-warmup-system","text":"Advanced model pre-loading for instant response times: # Model warmup configuration MODEL_WARMUP_TIMEOUT=60 # Warmup timeout (seconds) MAX_CONCURRENT_WARMUPS=2 # Concurrent warmup operations AUTO_WARMUP_ON_STARTUP=true # Auto-warm agent models WARMUP_INTERVAL_HOURS=6 # Re-warm interval MAX_IDLE_HOURS=24 # Remove unused models after Features: - Instant Responses - Pre-loaded models respond immediately - Usage Tracking - Monitors which models are actively used - Automatic Cleanup - Removes unused models to save memory - Smart Refresh - Re-warms models periodically","title":"Model Warmup System"},{"location":"open-agentic-framework/#core-concepts","text":"Understanding the framework's key components:","title":"Core Concepts"},{"location":"open-agentic-framework/#agent","text":"An intelligent entity with a specific role, goals, and capabilities. Agents can use tools to accomplish tasks and maintain conversation memory. { \"name\": \"website_guardian\", \"role\": \"Website Monitoring Specialist\", \"goals\": \"Monitor websites and send alerts when issues detected\", \"backstory\": \"Experienced system administrator with 10+ years experience\", \"tools\": [\"website_monitor\", \"email_sender\"], \"ollama_model\": \"granite3.2:2b\", \"tool_configs\": { \"email_sender\": { \"smtp_host\": \"smtp.gmail.com\", \"smtp_port\": 587, \"smtp_username\": \"alerts@company.com\", \"smtp_password\": \"app-password\" } } }","title":"Agent"},{"location":"open-agentic-framework/#task","text":"A specific instruction or request given to an agent. Tasks are processed by agents using their available tools and knowledge. # Example task \"Check if https://google.com is online and send an email alert if it's down\"","title":"Task"},{"location":"open-agentic-framework/#tool","text":"A specific capability or function that agents can use to interact with external systems, APIs, or perform specific operations. Built-in Tools: - website_monitor - Check website availability and response time - email_sender - Send emails via SMTP - http_client - Make HTTP requests to APIs","title":"Tool"},{"location":"open-agentic-framework/#workflow","text":"A sequence of steps that can include both agent tasks and tool executions, with advanced variable passing between steps, input validation , and output filtering . { \"name\": \"website_health_check\", \"description\": \"Comprehensive website monitoring with input validation and output filtering\", \"input_schema\": { \"type\": \"object\", \"properties\": { \"target_url\": { \"type\": \"string\", \"description\": \"URL to monitor\" }, \"alert_email\": { \"type\": \"string\", \"description\": \"Email for alerts\" }, \"timeout\": { \"type\": \"integer\", \"description\": \"Timeout in seconds\", \"default\": 10 } }, \"required\": [\"target_url\", \"alert_email\"] }, \"output_spec\": { \"extractions\": [ { \"name\": \"status_summary\", \"type\": \"path\", \"query\": \"website_status.status\", \"default\": \"unknown\", \"format\": \"text\" }, { \"name\": \"response_time\", \"type\": \"path\", \"query\": \"website_status.response_time_ms\", \"default\": \"0\", \"format\": \"number\" } ] }, \"steps\": [ { \"type\": \"tool\", \"name\": \"website_monitor\", \"parameters\": {\"url\": \"{{target_url}}\", \"timeout\": \"{{timeout}}\"}, \"context_key\": \"website_status\" }, { \"type\": \"agent\", \"name\": \"website_guardian\", \"task\": \"Analyze status: {{website_status.response_time}}ms response from {{website_status.url}} and send alerts if needed\", \"context_key\": \"analysis_result\" } ] }","title":"Workflow"},{"location":"open-agentic-framework/#memory","text":"Conversation history and context maintained for each agent, with intelligent context filtering and automatic cleanup (default: 5 entries per agent).","title":"Memory"},{"location":"open-agentic-framework/#scheduled-task","text":"Automated execution of agents or workflows at specified times or intervals. { \"task_type\": \"workflow\", \"workflow_name\": \"website_health_check\", \"scheduled_time\": \"2024-01-15T10:00:00Z\" }","title":"Scheduled Task"},{"location":"open-agentic-framework/#creating-advanced-workflows","text":"Workflows support sophisticated variable substitution and nested object access:","title":"Creating Advanced Workflows"},{"location":"open-agentic-framework/#variable-substitution-system","text":"Use {{variable}} syntax to pass data between workflow steps: { \"name\": \"data_processing_pipeline\", \"steps\": [ { \"type\": \"tool\", \"name\": \"http_client\", \"parameters\": { \"url\": \"https://api.example.com/data/{{dataset_id}}\", \"headers\": {\"Authorization\": \"Bearer {{api_token}}\"} }, \"context_key\": \"api_response\" }, { \"type\": \"agent\", \"name\": \"data_analyst\", \"task\": \"Analyze this API response: {{api_response.data}} with status {{api_response.status}} for dataset {{dataset_id}}\", \"context_key\": \"analysis\" } ] }","title":"Variable Substitution System"},{"location":"open-agentic-framework/#nested-object-access","text":"Access nested properties from previous workflow steps: { \"task\": \"The API returned status {{api_response.status}} with {{api_response.data.total_records}} records. Send summary to {{user.email}}\" }","title":"Nested Object Access"},{"location":"open-agentic-framework/#workflow-output-filtering","text":"Control what data is returned from workflow execution using the output_spec field. This allows you to extract specific fields from the workflow context instead of returning all data.","title":"Workflow Output Filtering"},{"location":"open-agentic-framework/#basic-output-filtering","text":"{ \"name\": \"license_assessment_workflow\", \"output_spec\": { \"extractions\": [ { \"name\": \"risk_assessment\", \"type\": \"path\", \"query\": \"risk_assessment\", \"default\": \"\", \"format\": \"text\" } ] } } Result: Only the risk_assessment data is returned in the output field, not the full workflow context.","title":"Basic Output Filtering"},{"location":"open-agentic-framework/#advanced-output-filtering","text":"Extract multiple specific fields with different extraction types: { \"name\": \"comprehensive_monitoring\", \"output_spec\": { \"extractions\": [ { \"name\": \"overall_risk\", \"type\": \"path\", \"query\": \"risk_assessment.OVERALL RISK LEVEL\", \"default\": \"UNKNOWN\", \"format\": \"text\" }, { \"name\": \"security_score\", \"type\": \"path\", \"query\": \"risk_assessment.SECURITY ASSESSMENT.ClearlyDefined Score\", \"default\": \"0\", \"format\": \"number\" }, { \"name\": \"license_breakdown\", \"type\": \"path\", \"query\": \"risk_assessment.LICENSE ANALYSIS.License Breakdown\", \"default\": \"{}\", \"format\": \"text\" } ] } }","title":"Advanced Output Filtering"},{"location":"open-agentic-framework/#extraction-types","text":"path - Extract data using dot notation (e.g., \"risk_assessment.OVERALL RISK LEVEL\" ) regex - Extract using regular expressions literal - Return a literal value find - Find data in arrays using criteria join_field - Extract array and join field values with separator","title":"Extraction Types"},{"location":"open-agentic-framework/#format-options","text":"text - Return as-is (preserves JSON objects/arrays) number - Convert to number boolean - Convert to boolean","title":"Format Options"},{"location":"open-agentic-framework/#input-validation","text":"Use input_schema to validate workflow inputs: { \"name\": \"validated_workflow\", \"input_schema\": { \"type\": \"object\", \"properties\": { \"package_name\": { \"type\": \"string\", \"description\": \"Package name to analyze\" }, \"analysis_depth\": { \"type\": \"string\", \"enum\": [\"basic\", \"comprehensive\"], \"default\": \"basic\" } }, \"required\": [\"package_name\"] } } Benefits: - Clean Output - Only relevant data is returned - Reduced Payload - Smaller response sizes - Better Integration - Easier to consume in other systems - Input Validation - Ensures required parameters are provided - Type Safety - Validates input types and formats","title":"Input Validation"},{"location":"open-agentic-framework/#tool-configuration-per-agent","text":"Configure tools differently for each agent to customize their behavior:","title":"Tool Configuration per Agent"},{"location":"open-agentic-framework/#email-sender-configuration","text":"curl -X POST \"http://localhost:8000/agents\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"notification_agent\", \"role\": \"Notification Specialist\", \"goals\": \"Send professional email notifications and alerts\", \"backstory\": \"You are an experienced communication specialist who sends clear, actionable notifications.\", \"tools\": [\"email_sender\", \"webhook_client\"], \"ollama_model\": \"granite3.2:2b\", \"enabled\": true, \"tool_configs\": { \"email_sender\": { \"smtp_host\": \"smtp.gmail.com\", \"smtp_port\": 587, \"smtp_username\": \"alerts@yourcompany.com\", \"smtp_password\": \"your-app-password\", \"from_email\": \"AI Assistant <alerts@yourcompany.com>\", \"default_template\": \"professional\" }, \"webhook_client\": { \"default_timeout\": 30, \"retry_attempts\": 3 } } }'","title":"Email Sender Configuration"},{"location":"open-agentic-framework/#website-monitor-configuration","text":"curl -X POST \"http://localhost:8000/agents\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"monitoring_agent\", \"role\": \"System Monitoring Specialist\", \"goals\": \"Monitor system health and performance\", \"backstory\": \"You are a vigilant system administrator who monitors infrastructure and reports issues.\", \"tools\": [\"website_monitor\", \"http_client\"], \"ollama_model\": \"deepseek-r1:1.5b\", \"enabled\": true, \"tool_configs\": { \"website_monitor\": { \"default_timeout\": 15, \"retry_attempts\": 2, \"expected_status_codes\": [200, 301, 302] }, \"http_client\": { \"default_timeout\": 30, \"max_redirects\": 5, \"verify_ssl\": true } } }' Benefits of Tool Configuration: - Customized Behavior - Each agent can have different tool settings - Environment-Specific - Configure for development, staging, or production - Security - Set different credentials per agent - Performance - Optimize timeouts and retry settings per use case","title":"Website Monitor Configuration"},{"location":"open-agentic-framework/#enhanced-memory-management","text":"Advanced memory features with intelligent cleanup:","title":"Enhanced Memory Management"},{"location":"open-agentic-framework/#memory-statistics-cleanup","text":"# Get detailed memory statistics curl http://localhost:8000/memory/stats # Example response: { \"total_memory_entries\": 45, \"agents_with_memory\": 3, \"memory_per_agent\": { \"website_guardian\": 12, \"data_analyst\": 8, \"license_assessor\": 25 }, \"oldest_entry\": \"2024-06-09T10:00:00Z\", \"newest_entry\": \"2024-06-10T14:30:00Z\" } # Intelligent cleanup (keeps last N entries per agent) curl -X POST \"http://localhost:8000/memory/cleanup\" # Clear all memory (nuclear option) curl -X DELETE \"http://localhost:8000/memory/clear-all\" # Clear specific agent memory curl -X DELETE \"http://localhost:8000/agents/website_guardian/memory\"","title":"Memory Statistics &amp; Cleanup"},{"location":"open-agentic-framework/#memory-configuration","text":"# Memory Management Settings MAX_AGENT_MEMORY_ENTRIES=5 # Max memory per agent CLEAR_MEMORY_ON_STARTUP=false # Clear memory on restart MEMORY_CLEANUP_INTERVAL=3600 # Cleanup interval (seconds) MEMORY_RETENTION_DAYS=7 # Days to keep old entries","title":"Memory Configuration"},{"location":"open-agentic-framework/#api-documentation","text":"","title":"API Documentation"},{"location":"open-agentic-framework/#interactive-swagger-documentation","text":"Access the complete API documentation with interactive testing capabilities: http://localhost:8000/docs The Swagger interface provides: - Complete endpoint documentation - Live API Testing - Test endpoints directly from the browser - Request/response schemas with examples - Authentication options - Code Generation - Generate client code in multiple languages - Schema Explorer - Browse all data models and their properties","title":"Interactive Swagger Documentation"},{"location":"open-agentic-framework/#alternative-documentation-formats","text":"ReDoc : http://localhost:8000/redoc (Clean, responsive documentation) OpenAPI JSON : http://localhost:8000/openapi.json (Raw OpenAPI specification)","title":"Alternative Documentation Formats"},{"location":"open-agentic-framework/#key-api-sections","text":"Providers ( /providers ) - Multi-provider LLM management Models ( /models ) - Model discovery and testing Agents ( /agents ) - Create and manage AI agents Tools ( /tools ) - Execute and manage tools Workflows ( /workflows ) - Create and execute workflows Memory ( /memory ) - Advanced memory management Schedule ( /schedule ) - Schedule automated tasks System ( /health , /config ) - System monitoring and configuration","title":"Key API Sections"},{"location":"open-agentic-framework/#complete-website-monitoring-example","text":"Click to expand complete monitoring system setup # 1. Create monitoring agent with email configuration curl -X POST \"http://localhost:8000/agents\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"website_guardian\", \"role\": \"Website Monitoring Guardian\", \"goals\": \"Ensure critical websites are always online and notify immediately when issues are detected\", \"backstory\": \"You are a vigilant system monitor with years of experience in maintaining high-availability systems. You check websites systematically and provide clear, actionable status reports.\", \"tools\": [\"website_monitor\", \"email_sender\"], \"ollama_model\": \"deepseek-r1:1.5b\", \"enabled\": true, \"tool_configs\": { \"email_sender\": { \"smtp_host\": \"smtp.gmail.com\", \"smtp_port\": 587, \"smtp_username\": \"alerts@yourcompany.com\", \"smtp_password\": \"your-app-password\", \"from_email\": \"Website Guardian <alerts@yourcompany.com>\" } } }' # 2. Create monitoring workflow with intelligent analysis curl -X POST \"http://localhost:8000/workflows\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"name\": \"website_health_check\", \"description\": \"Comprehensive website monitoring with intelligent alerts\", \"input_schema\": { \"type\": \"object\", \"properties\": { \"target_url\": { \"type\": \"string\", \"description\": \"URL to monitor\" }, \"alert_email\": { \"type\": \"string\", \"description\": \"Email for alerts\" }, \"timeout\": { \"type\": \"integer\", \"description\": \"Timeout in seconds\", \"default\": 10 } }, \"required\": [\"target_url\", \"alert_email\"] }, \"output_spec\": { \"extractions\": [ { \"name\": \"status\", \"type\": \"path\", \"query\": \"website_status.status\", \"default\": \"unknown\", \"format\": \"text\" }, { \"name\": \"response_time\", \"type\": \"path\", \"query\": \"website_status.response_time_ms\", \"default\": \"0\", \"format\": \"number\" }, { \"name\": \"analysis_summary\", \"type\": \"path\", \"query\": \"alert_result\", \"default\": \"\", \"format\": \"text\" } ] }, \"steps\": [ { \"type\": \"tool\", \"name\": \"website_monitor\", \"parameters\": { \"url\": \"{{target_url}}\", \"timeout\": \"{{timeout}}\", \"expected_status\": 200 }, \"context_key\": \"website_status\" }, { \"type\": \"agent\", \"name\": \"website_guardian\", \"task\": \"Analyze the website monitoring result: {{website_status}}. Check response time (should be <2000ms), status code, and any errors. If there are issues, send an email alert to {{alert_email}} with detailed analysis.\", \"context_key\": \"alert_result\" } ], \"enabled\": true }' # 3. Execute monitoring workflow curl -X POST \"http://localhost:8000/workflows/website_health_check/execute\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"context\": { \"target_url\": \"https://yourwebsite.com\", \"alert_email\": \"admin@yourcompany.com\" } }' # 4. Schedule regular monitoring (every 5 minutes) curl -X POST \"http://localhost:8000/schedule\" \\ -H \"Content-Type: application/json\" \\ -d '{ \"task_type\": \"workflow\", \"workflow_name\": \"website_health_check\", \"scheduled_time\": \"2024-01-15T10:00:00Z\", \"context\": { \"recurring\": \"every_5_minutes\", \"target_url\": \"https://yourwebsite.com\", \"alert_email\": \"admin@yourcompany.com\" } }'","title":"Complete Website Monitoring Example"},{"location":"open-agentic-framework/#web-ui","text":"The Open Agentic Framework includes a modern web interface that provides an intuitive way to manage your AI agents, workflows, and system configuration.","title":"Web UI"},{"location":"open-agentic-framework/#accessing-the-web-ui","text":"Once the framework is running, access the web interface at: http://localhost:8000/ui","title":"Accessing the Web UI"},{"location":"open-agentic-framework/#contributing","text":"We welcome contributions! Please see our Contributing Guidelines for details.","title":"Contributing"},{"location":"open-agentic-framework/#development-process","text":"Fork the repository Create a feature branch ( git checkout -b feature/amazing-feature ) Commit your changes ( git commit -m 'Add amazing feature' ) Push to the branch ( git push origin feature/amazing-feature ) Open a Pull Request","title":"Development Process"},{"location":"open-agentic-framework/#license","text":"This project is licensed under the MIT License - see the LICENSE file for details.","title":"License"},{"location":"open-agentic-framework/#acknowledgments","text":"FastAPI for the excellent web framework Ollama for local LLM capabilities OpenAI for pioneering AI APIs SQLAlchemy for robust database management Pydantic for data validation","title":"Acknowledgments"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/","text":"\ud83e\udd1d Code of Conduct Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards \u2705 Examples of behavior that contributes to a positive environment Be Respectful - Using welcoming and inclusive language - Being respectful of differing viewpoints and experiences - Gracefully accepting constructive criticism - Focusing on what is best for the community - Showing empathy towards other community members Be Collaborative - Helping newcomers get started and learn - Sharing knowledge and resources openly - Giving credit where credit is due - Working together to solve problems - Supporting other contributors' efforts Be Professional - Keeping discussions focused and on-topic - Providing constructive feedback on ideas and code - Acknowledging mistakes and learning from them - Being patient with questions and different skill levels - Maintaining professional communication in all interactions Be Inclusive - Welcoming people from all backgrounds and experience levels - Using inclusive language and avoiding assumptions - Making space for different perspectives and approaches - Encouraging participation from underrepresented groups - Being mindful of accessibility needs \u274c Examples of unacceptable behavior Harassment and Discrimination - The use of sexualized language or imagery, and sexual attention or advances of any kind - Trolling, insulting or derogatory comments, and personal or political attacks - Public or private harassment - Publishing others' private information without explicit permission - Discriminatory jokes, language, or imagery Disruptive Behavior - Deliberate intimidation, stalking, or following - Sustained disruption of discussions, issues, or pull requests - Spamming or flooding communication channels - Off-topic discussions that derail productive conversation - Repeatedly ignoring community guidelines after warnings Unprofessional Conduct - Other conduct which could reasonably be considered inappropriate in a professional setting - Advocating for or encouraging any of the above behaviors - Making false or misleading statements about the project or other contributors - Attempting to circumvent moderation decisions - Engaging in bad faith arguments or discussions Project-Specific Guidelines Technical Discussions Constructive Code Review - Focus on the code, not the person who wrote it - Explain the reasoning behind your suggestions - Acknowledge good solutions and creative approaches - Provide specific, actionable feedback - Be patient with contributors who are learning Issue and Pull Request Etiquette - Search existing issues before creating new ones - Provide clear, reproducible examples for bug reports - Stay on topic and avoid scope creep in discussions - Be responsive to feedback and questions - Follow up on your contributions Knowledge Sharing - Share resources and learning materials freely - Help document solutions to common problems - Mentor newcomers and answer questions patiently - Acknowledge when you don't know something - Credit others for their ideas and contributions Community Participation Inclusive Participation - Welcome questions from people at all skill levels - Avoid gatekeeping or elitist attitudes - Use clear, jargon-free language when possible - Provide context for technical discussions - Encourage diverse perspectives and approaches Collaborative Problem Solving - Assume positive intent in communications - Ask clarifying questions rather than making assumptions - Offer help and resources when you can - Celebrate others' successes and contributions - Learn from mistakes and help others do the same Enforcement Responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include: Using an official project email address Posting via an official social media account Acting as an appointed representative at an online or offline event Contributing to the project repositories Participating in project discussions, issues, and pull requests Representing the project in external forums or conferences Reporting Guidelines How to Report If you experience or witness unacceptable behavior, or have any other concerns, please report it by contacting the project team at: Email : conduct@openagenticframework.com GitHub : Create a private issue using the \"Report Code of Conduct Violation\" template Direct Contact : Reach out to any project maintainer directly What to Include When reporting, please include: Your contact information (so we can follow up) Names of individuals involved (including witnesses) Description of what happened (be as specific as possible) When and where it occurred Any additional context that would be helpful Any supporting evidence (screenshots, links, etc.) Privacy and Confidentiality All reports will be handled with discretion and confidentiality. We respect the privacy of all parties involved and will only share information on a need-to-know basis for the purpose of investigating and resolving the issue. Enforcement Process Investigation Acknowledgment : We will acknowledge receipt of your report within 24 hours Initial Review : The moderation team will review the report and gather any additional information needed Investigation : We will investigate the incident, which may include speaking with involved parties and witnesses Decision : The team will determine what action, if any, is needed Possible Actions Depending on the severity and nature of the violation, consequences may include: Warning - A private, written warning from community leaders - Clarification of why the behavior was inappropriate - Request for an apology or behavior change Temporary Restriction - Temporary ban from commenting on issues and pull requests - Temporary ban from community spaces (Discord, forums, etc.) - Restriction from certain project activities Permanent Ban - Permanent removal from all community spaces - Permanent ban from contributing to the project - Public announcement of the ban (in severe cases) Appeals Process If you believe you have been wrongfully accused or disagree with a moderation decision: Contact the moderation team within 30 days of the decision Provide additional context or evidence for your appeal The team will review your appeal and respond within 7 days Final decisions will be communicated clearly with reasoning Community Leadership Project Maintainers Project maintainers are responsible for: - Setting and enforcing community standards - Responding to Code of Conduct violations - Making final decisions on enforcement actions - Supporting community members and contributors - Continuously improving community processes Community Moderators Community moderators help by: - Monitoring discussions and interactions - Providing guidance on community standards - Supporting new contributors and community members - Escalating serious violations to project maintainers - Helping maintain a positive community atmosphere Attribution and Inspiration This Code of Conduct is adapted from: - The Contributor Covenant , version 2.1 - The Django Code of Conduct - The Rust Code of Conduct - The GitHub Community Guidelines Living Document This Code of Conduct is a living document that may be updated from time to time to better serve our community. We welcome feedback and suggestions for improvement. Recent Updates v1.0 (2024-06-05): Initial version based on Contributor Covenant 2.1 Added project-specific guidelines for technical discussions Included detailed reporting and enforcement procedures Added appeals process and community leadership structure Commitment to Improvement We are committed to: - Regular review of our Code of Conduct and its effectiveness - Community feedback on how we can improve our standards and processes - Transparency in our enforcement decisions (while respecting privacy) - Education and resources to help community members understand expectations - Continuous learning about best practices for inclusive communities Getting Help Questions About the Code of Conduct If you have questions about this Code of Conduct or need clarification on any aspect: - Contact maintainers directly - Email us at conduct@openagenticframework.com Resources for Creating Inclusive Spaces Inclusive Language Guidelines Building Welcoming Communities GitHub's Guide to Building Communities Contributor Covenant Resources Emergency Contacts In cases of immediate safety concerns or urgent violations: - Security Contact : security@openagenticframework.com Thank You Thank you for helping make the Open Agentic Framework community a welcoming, inclusive, and productive space for everyone. By participating in our community, you're helping build the future of AI automation while creating an environment where all contributors can thrive. Together, we can build not just better software, but a better community. \ud83d\ude80 Remember : This Code of Conduct applies to all interactions within our community, whether online or offline, formal or informal. We're all responsible for maintaining a positive and inclusive environment.","title":"\ud83e\udd1d Code of Conduct"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#code-of-conduct","text":"","title":"\ud83e\udd1d Code of Conduct"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#our-standards","text":"","title":"Our Standards"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#examples-of-behavior-that-contributes-to-a-positive-environment","text":"Be Respectful - Using welcoming and inclusive language - Being respectful of differing viewpoints and experiences - Gracefully accepting constructive criticism - Focusing on what is best for the community - Showing empathy towards other community members Be Collaborative - Helping newcomers get started and learn - Sharing knowledge and resources openly - Giving credit where credit is due - Working together to solve problems - Supporting other contributors' efforts Be Professional - Keeping discussions focused and on-topic - Providing constructive feedback on ideas and code - Acknowledging mistakes and learning from them - Being patient with questions and different skill levels - Maintaining professional communication in all interactions Be Inclusive - Welcoming people from all backgrounds and experience levels - Using inclusive language and avoiding assumptions - Making space for different perspectives and approaches - Encouraging participation from underrepresented groups - Being mindful of accessibility needs","title":"\u2705 Examples of behavior that contributes to a positive environment"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#examples-of-unacceptable-behavior","text":"Harassment and Discrimination - The use of sexualized language or imagery, and sexual attention or advances of any kind - Trolling, insulting or derogatory comments, and personal or political attacks - Public or private harassment - Publishing others' private information without explicit permission - Discriminatory jokes, language, or imagery Disruptive Behavior - Deliberate intimidation, stalking, or following - Sustained disruption of discussions, issues, or pull requests - Spamming or flooding communication channels - Off-topic discussions that derail productive conversation - Repeatedly ignoring community guidelines after warnings Unprofessional Conduct - Other conduct which could reasonably be considered inappropriate in a professional setting - Advocating for or encouraging any of the above behaviors - Making false or misleading statements about the project or other contributors - Attempting to circumvent moderation decisions - Engaging in bad faith arguments or discussions","title":"\u274c Examples of unacceptable behavior"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#project-specific-guidelines","text":"","title":"Project-Specific Guidelines"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#technical-discussions","text":"Constructive Code Review - Focus on the code, not the person who wrote it - Explain the reasoning behind your suggestions - Acknowledge good solutions and creative approaches - Provide specific, actionable feedback - Be patient with contributors who are learning Issue and Pull Request Etiquette - Search existing issues before creating new ones - Provide clear, reproducible examples for bug reports - Stay on topic and avoid scope creep in discussions - Be responsive to feedback and questions - Follow up on your contributions Knowledge Sharing - Share resources and learning materials freely - Help document solutions to common problems - Mentor newcomers and answer questions patiently - Acknowledge when you don't know something - Credit others for their ideas and contributions","title":"Technical Discussions"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#community-participation","text":"Inclusive Participation - Welcome questions from people at all skill levels - Avoid gatekeeping or elitist attitudes - Use clear, jargon-free language when possible - Provide context for technical discussions - Encourage diverse perspectives and approaches Collaborative Problem Solving - Assume positive intent in communications - Ask clarifying questions rather than making assumptions - Offer help and resources when you can - Celebrate others' successes and contributions - Learn from mistakes and help others do the same","title":"Community Participation"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include: Using an official project email address Posting via an official social media account Acting as an appointed representative at an online or offline event Contributing to the project repositories Participating in project discussions, issues, and pull requests Representing the project in external forums or conferences","title":"Scope"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#reporting-guidelines","text":"","title":"Reporting Guidelines"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#how-to-report","text":"If you experience or witness unacceptable behavior, or have any other concerns, please report it by contacting the project team at: Email : conduct@openagenticframework.com GitHub : Create a private issue using the \"Report Code of Conduct Violation\" template Direct Contact : Reach out to any project maintainer directly","title":"How to Report"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#what-to-include","text":"When reporting, please include: Your contact information (so we can follow up) Names of individuals involved (including witnesses) Description of what happened (be as specific as possible) When and where it occurred Any additional context that would be helpful Any supporting evidence (screenshots, links, etc.)","title":"What to Include"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#privacy-and-confidentiality","text":"All reports will be handled with discretion and confidentiality. We respect the privacy of all parties involved and will only share information on a need-to-know basis for the purpose of investigating and resolving the issue.","title":"Privacy and Confidentiality"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#enforcement-process","text":"","title":"Enforcement Process"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#investigation","text":"Acknowledgment : We will acknowledge receipt of your report within 24 hours Initial Review : The moderation team will review the report and gather any additional information needed Investigation : We will investigate the incident, which may include speaking with involved parties and witnesses Decision : The team will determine what action, if any, is needed","title":"Investigation"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#possible-actions","text":"Depending on the severity and nature of the violation, consequences may include: Warning - A private, written warning from community leaders - Clarification of why the behavior was inappropriate - Request for an apology or behavior change Temporary Restriction - Temporary ban from commenting on issues and pull requests - Temporary ban from community spaces (Discord, forums, etc.) - Restriction from certain project activities Permanent Ban - Permanent removal from all community spaces - Permanent ban from contributing to the project - Public announcement of the ban (in severe cases)","title":"Possible Actions"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#appeals-process","text":"If you believe you have been wrongfully accused or disagree with a moderation decision: Contact the moderation team within 30 days of the decision Provide additional context or evidence for your appeal The team will review your appeal and respond within 7 days Final decisions will be communicated clearly with reasoning","title":"Appeals Process"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#community-leadership","text":"","title":"Community Leadership"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#project-maintainers","text":"Project maintainers are responsible for: - Setting and enforcing community standards - Responding to Code of Conduct violations - Making final decisions on enforcement actions - Supporting community members and contributors - Continuously improving community processes","title":"Project Maintainers"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#community-moderators","text":"Community moderators help by: - Monitoring discussions and interactions - Providing guidance on community standards - Supporting new contributors and community members - Escalating serious violations to project maintainers - Helping maintain a positive community atmosphere","title":"Community Moderators"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#attribution-and-inspiration","text":"This Code of Conduct is adapted from: - The Contributor Covenant , version 2.1 - The Django Code of Conduct - The Rust Code of Conduct - The GitHub Community Guidelines","title":"Attribution and Inspiration"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#living-document","text":"This Code of Conduct is a living document that may be updated from time to time to better serve our community. We welcome feedback and suggestions for improvement.","title":"Living Document"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#recent-updates","text":"v1.0 (2024-06-05): Initial version based on Contributor Covenant 2.1 Added project-specific guidelines for technical discussions Included detailed reporting and enforcement procedures Added appeals process and community leadership structure","title":"Recent Updates"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#commitment-to-improvement","text":"We are committed to: - Regular review of our Code of Conduct and its effectiveness - Community feedback on how we can improve our standards and processes - Transparency in our enforcement decisions (while respecting privacy) - Education and resources to help community members understand expectations - Continuous learning about best practices for inclusive communities","title":"Commitment to Improvement"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#getting-help","text":"","title":"Getting Help"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#questions-about-the-code-of-conduct","text":"If you have questions about this Code of Conduct or need clarification on any aspect: - Contact maintainers directly - Email us at conduct@openagenticframework.com","title":"Questions About the Code of Conduct"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#resources-for-creating-inclusive-spaces","text":"Inclusive Language Guidelines Building Welcoming Communities GitHub's Guide to Building Communities Contributor Covenant Resources","title":"Resources for Creating Inclusive Spaces"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#emergency-contacts","text":"In cases of immediate safety concerns or urgent violations: - Security Contact : security@openagenticframework.com","title":"Emergency Contacts"},{"location":"open-agentic-framework/CODE_OF_CONDUCT/#thank-you","text":"Thank you for helping make the Open Agentic Framework community a welcoming, inclusive, and productive space for everyone. By participating in our community, you're helping build the future of AI automation while creating an environment where all contributors can thrive. Together, we can build not just better software, but a better community. \ud83d\ude80 Remember : This Code of Conduct applies to all interactions within our community, whether online or offline, formal or informal. We're all responsible for maintaining a positive and inclusive environment.","title":"Thank You"},{"location":"open-agentic-framework/CONTRIBUTING/","text":"\ud83e\udd1d Contributing to Open Agentic Framework Thank you for your interest in contributing to the Open Agentic Framework! We welcome contributions from developers of all skill levels. This guide will help you get started. \ud83d\udccb Table of Contents Code of Conduct Getting Started Development Environment Contributing Process Contribution Types Development Guidelines Testing Documentation Community \ud83d\udcdc Code of Conduct We are committed to providing a welcoming and inclusive experience for everyone. By participating in this project, you agree to abide by our Code of Conduct . Our Standards Be respectful and considerate in your communication Be collaborative and help others learn and grow Be inclusive and welcome newcomers to the community Focus on what's best for the community and project Show empathy towards other community members \ud83d\ude80 Getting Started Ways to Contribute \ud83d\udc1b Report bugs and issues \ud83d\udca1 Suggest new features or improvements \ud83d\udcdd Improve documentation \ud83d\udd27 Submit code changes and bug fixes \ud83c\udfaf Create new tools and integrations \ud83e\uddea Write tests and improve coverage \ud83c\udf1f Share your use cases and success stories Before You Start Check existing issues to avoid duplicating work Read the documentation to understand the project structure Join our community discussions for questions and ideas Start small with your first contribution \ud83d\udee0 Development Environment Prerequisites Python 3.8+ Docker and Docker Compose Git Text editor or IDE (VS Code, PyCharm, etc.) 4GB+ RAM for running models locally Local Setup # 1. Fork the repository on GitHub # 2. Clone your fork locally git clone https://github.com/oscarvalenzuelab/open_agentic_framework.git cd open_agentic_framework # 3. Add upstream remote git remote add upstream https://github.com/oscarvalenzuelab/open_agentic_framework.git # 4. Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # 5. Install development dependencies pip install -r requirements-dev.txt # 6. Install pre-commit hooks pre-commit install # 7. Start the development environment docker-compose up -d # 8. Run tests to verify setup pytest tests/ -v Development Tools We use several tools to maintain code quality: Black - Code formatting isort - Import sorting flake8 - Linting mypy - Type checking pytest - Testing pre-commit - Git hooks # Format code black . isort . # Lint code flake8 . # Type checking mypy . # Run tests pytest tests/ -v --cov=. \ud83d\udd04 Contributing Process 1. Create an Issue (Recommended) Before starting work, create an issue to discuss your proposed changes: Bug reports : Use the bug report template Feature requests : Use the feature request template Questions : Start a discussion in GitHub Discussions 2. Fork and Branch # Create a new branch for your work git checkout -b feature/amazing-new-feature # Or for bug fixes git checkout -b fix/bug-description # Or for documentation git checkout -b docs/update-contributing-guide Branch Naming Convention feature/description - New features fix/description - Bug fixes docs/description - Documentation updates test/description - Test improvements refactor/description - Code refactoring chore/description - Maintenance tasks 3. Make Your Changes Follow our Development Guidelines while making changes. 4. Test Your Changes # Run the full test suite pytest tests/ -v # Run specific test files pytest tests/test_agents.py -v # Run with coverage pytest tests/ --cov=. --cov-report=html # Test your changes manually docker-compose up -d curl http://localhost:8000/health 5. Commit Your Changes We follow the Conventional Commits specification: # Examples of good commit messages git commit -m \"feat: add email notification tool\" git commit -m \"fix: resolve memory leak in agent execution\" git commit -m \"docs: update quick start guide with new examples\" git commit -m \"test: add unit tests for workflow manager\" git commit -m \"refactor: simplify tool registration process\" Commit Types feat: - New features fix: - Bug fixes docs: - Documentation changes test: - Adding or updating tests refactor: - Code refactoring perf: - Performance improvements style: - Code style changes (formatting, etc.) chore: - Maintenance tasks ci: - CI/CD changes 6. Push and Create Pull Request # Push your branch git push origin feature/amazing-new-feature # Create a pull request on GitHub # Use the pull request template and provide: # - Clear description of changes # - Link to related issues # - Screenshots if applicable # - Testing instructions 7. Code Review Process Automated checks run on every PR (tests, linting, type checking) Maintainer review for code quality and design Community feedback welcome on all PRs Iterative improvement based on feedback Final approval from project maintainers \ud83c\udfaf Contribution Types \ud83d\udc1b Bug Reports When reporting bugs, please include: **Bug Description** A clear description of what the bug is. **Steps to Reproduce** 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected Behavior** What you expected to happen. **Actual Behavior** What actually happened. **Environment** - OS: [e.g. Ubuntu 20.04] - Python version: [e.g. 3.9.5] - Docker version: [e.g. 20.10.8] - Framework version: [e.g. 1.1.0] **Additional Context** Logs, screenshots, or other helpful information. \ud83d\udca1 Feature Requests For new features, please provide: Use case - Why is this feature needed? Proposed solution - How should it work? Alternatives considered - What other approaches did you consider? Implementation ideas - Any thoughts on how to implement it? \ud83d\udd27 Code Contributions New Tools Creating a new tool is a great way to contribute! Tools extend agent capabilities: # Example: tools/my_awesome_tool.py from tools.base_tool import BaseTool from typing import Dict, Any class MyAwesomeTool(BaseTool): @property def name(self) -> str: return \"my_awesome_tool\" @property def description(self) -> str: return \"Does something awesome for agents\" @property def parameters(self) -> Dict[str, Any]: return { \"type\": \"object\", \"properties\": { \"input_text\": { \"type\": \"string\", \"description\": \"Text to process\" }, \"option\": { \"type\": \"string\", \"enum\": [\"fast\", \"thorough\"], \"default\": \"fast\" } }, \"required\": [\"input_text\"] } async def execute(self, parameters: Dict[str, Any]) -> Any: \"\"\"Execute the tool with given parameters\"\"\" input_text = parameters[\"input_text\"] option = parameters.get(\"option\", \"fast\") # Your tool logic here result = f\"Processed '{input_text}' with {option} mode\" return { \"result\": result, \"processed_length\": len(input_text), \"mode\": option } Tool Contribution Checklist: - [ ] Inherits from BaseTool - [ ] Has clear name , description , and parameters - [ ] Includes proper error handling - [ ] Has comprehensive tests - [ ] Includes documentation and examples - [ ] Follows security best practices Core Framework Improvements For core framework changes: Discuss first in an issue or discussion Maintain backward compatibility when possible Update documentation for any API changes Add comprehensive tests Consider performance impact \u2753 FAQ Q: I'm new to open source. How can I contribute? A: Start small! Look for issues labeled good first issue or help wanted . Documentation improvements and bug reports are great first contributions. Q: Can I add support for a new LLM provider? A: Absolutely! We welcome integrations with different LLM providers. Please create an issue first to discuss the implementation approach. Q: How do I create a custom tool? A: Check out the tool creation guide and look at existing tools in the tools/ directory for examples. Q: What if my PR gets rejected? A: Feedback is part of the process! We'll provide specific suggestions for improvement. Don't take it personally - we're all working together to make the project better. Q: Can I work on multiple issues at once? A: It's better to focus on one issue at a time, especially when starting out. This helps ensure quality and makes the review process smoother. \ud83d\ude4f Thank You Thank you for considering contributing to the Open Agentic Framework! Every contribution, no matter how small, helps make this project better for everyone.","title":"\ud83e\udd1d Contributing to Open Agentic Framework"},{"location":"open-agentic-framework/CONTRIBUTING/#contributing-to-open-agentic-framework","text":"Thank you for your interest in contributing to the Open Agentic Framework! We welcome contributions from developers of all skill levels. This guide will help you get started.","title":"\ud83e\udd1d Contributing to Open Agentic Framework"},{"location":"open-agentic-framework/CONTRIBUTING/#table-of-contents","text":"Code of Conduct Getting Started Development Environment Contributing Process Contribution Types Development Guidelines Testing Documentation Community","title":"\ud83d\udccb Table of Contents"},{"location":"open-agentic-framework/CONTRIBUTING/#code-of-conduct","text":"We are committed to providing a welcoming and inclusive experience for everyone. By participating in this project, you agree to abide by our Code of Conduct .","title":"\ud83d\udcdc Code of Conduct"},{"location":"open-agentic-framework/CONTRIBUTING/#our-standards","text":"Be respectful and considerate in your communication Be collaborative and help others learn and grow Be inclusive and welcome newcomers to the community Focus on what's best for the community and project Show empathy towards other community members","title":"Our Standards"},{"location":"open-agentic-framework/CONTRIBUTING/#getting-started","text":"","title":"\ud83d\ude80 Getting Started"},{"location":"open-agentic-framework/CONTRIBUTING/#ways-to-contribute","text":"\ud83d\udc1b Report bugs and issues \ud83d\udca1 Suggest new features or improvements \ud83d\udcdd Improve documentation \ud83d\udd27 Submit code changes and bug fixes \ud83c\udfaf Create new tools and integrations \ud83e\uddea Write tests and improve coverage \ud83c\udf1f Share your use cases and success stories","title":"Ways to Contribute"},{"location":"open-agentic-framework/CONTRIBUTING/#before-you-start","text":"Check existing issues to avoid duplicating work Read the documentation to understand the project structure Join our community discussions for questions and ideas Start small with your first contribution","title":"Before You Start"},{"location":"open-agentic-framework/CONTRIBUTING/#development-environment","text":"","title":"\ud83d\udee0 Development Environment"},{"location":"open-agentic-framework/CONTRIBUTING/#prerequisites","text":"Python 3.8+ Docker and Docker Compose Git Text editor or IDE (VS Code, PyCharm, etc.) 4GB+ RAM for running models locally","title":"Prerequisites"},{"location":"open-agentic-framework/CONTRIBUTING/#local-setup","text":"# 1. Fork the repository on GitHub # 2. Clone your fork locally git clone https://github.com/oscarvalenzuelab/open_agentic_framework.git cd open_agentic_framework # 3. Add upstream remote git remote add upstream https://github.com/oscarvalenzuelab/open_agentic_framework.git # 4. Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # 5. Install development dependencies pip install -r requirements-dev.txt # 6. Install pre-commit hooks pre-commit install # 7. Start the development environment docker-compose up -d # 8. Run tests to verify setup pytest tests/ -v","title":"Local Setup"},{"location":"open-agentic-framework/CONTRIBUTING/#development-tools","text":"We use several tools to maintain code quality: Black - Code formatting isort - Import sorting flake8 - Linting mypy - Type checking pytest - Testing pre-commit - Git hooks # Format code black . isort . # Lint code flake8 . # Type checking mypy . # Run tests pytest tests/ -v --cov=.","title":"Development Tools"},{"location":"open-agentic-framework/CONTRIBUTING/#contributing-process","text":"","title":"\ud83d\udd04 Contributing Process"},{"location":"open-agentic-framework/CONTRIBUTING/#1-create-an-issue-recommended","text":"Before starting work, create an issue to discuss your proposed changes: Bug reports : Use the bug report template Feature requests : Use the feature request template Questions : Start a discussion in GitHub Discussions","title":"1. Create an Issue (Recommended)"},{"location":"open-agentic-framework/CONTRIBUTING/#2-fork-and-branch","text":"# Create a new branch for your work git checkout -b feature/amazing-new-feature # Or for bug fixes git checkout -b fix/bug-description # Or for documentation git checkout -b docs/update-contributing-guide","title":"2. Fork and Branch"},{"location":"open-agentic-framework/CONTRIBUTING/#branch-naming-convention","text":"feature/description - New features fix/description - Bug fixes docs/description - Documentation updates test/description - Test improvements refactor/description - Code refactoring chore/description - Maintenance tasks","title":"Branch Naming Convention"},{"location":"open-agentic-framework/CONTRIBUTING/#3-make-your-changes","text":"Follow our Development Guidelines while making changes.","title":"3. Make Your Changes"},{"location":"open-agentic-framework/CONTRIBUTING/#4-test-your-changes","text":"# Run the full test suite pytest tests/ -v # Run specific test files pytest tests/test_agents.py -v # Run with coverage pytest tests/ --cov=. --cov-report=html # Test your changes manually docker-compose up -d curl http://localhost:8000/health","title":"4. Test Your Changes"},{"location":"open-agentic-framework/CONTRIBUTING/#5-commit-your-changes","text":"We follow the Conventional Commits specification: # Examples of good commit messages git commit -m \"feat: add email notification tool\" git commit -m \"fix: resolve memory leak in agent execution\" git commit -m \"docs: update quick start guide with new examples\" git commit -m \"test: add unit tests for workflow manager\" git commit -m \"refactor: simplify tool registration process\"","title":"5. Commit Your Changes"},{"location":"open-agentic-framework/CONTRIBUTING/#commit-types","text":"feat: - New features fix: - Bug fixes docs: - Documentation changes test: - Adding or updating tests refactor: - Code refactoring perf: - Performance improvements style: - Code style changes (formatting, etc.) chore: - Maintenance tasks ci: - CI/CD changes","title":"Commit Types"},{"location":"open-agentic-framework/CONTRIBUTING/#6-push-and-create-pull-request","text":"# Push your branch git push origin feature/amazing-new-feature # Create a pull request on GitHub # Use the pull request template and provide: # - Clear description of changes # - Link to related issues # - Screenshots if applicable # - Testing instructions","title":"6. Push and Create Pull Request"},{"location":"open-agentic-framework/CONTRIBUTING/#7-code-review-process","text":"Automated checks run on every PR (tests, linting, type checking) Maintainer review for code quality and design Community feedback welcome on all PRs Iterative improvement based on feedback Final approval from project maintainers","title":"7. Code Review Process"},{"location":"open-agentic-framework/CONTRIBUTING/#contribution-types","text":"","title":"\ud83c\udfaf Contribution Types"},{"location":"open-agentic-framework/CONTRIBUTING/#bug-reports","text":"When reporting bugs, please include: **Bug Description** A clear description of what the bug is. **Steps to Reproduce** 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected Behavior** What you expected to happen. **Actual Behavior** What actually happened. **Environment** - OS: [e.g. Ubuntu 20.04] - Python version: [e.g. 3.9.5] - Docker version: [e.g. 20.10.8] - Framework version: [e.g. 1.1.0] **Additional Context** Logs, screenshots, or other helpful information.","title":"\ud83d\udc1b Bug Reports"},{"location":"open-agentic-framework/CONTRIBUTING/#feature-requests","text":"For new features, please provide: Use case - Why is this feature needed? Proposed solution - How should it work? Alternatives considered - What other approaches did you consider? Implementation ideas - Any thoughts on how to implement it?","title":"\ud83d\udca1 Feature Requests"},{"location":"open-agentic-framework/CONTRIBUTING/#code-contributions","text":"","title":"\ud83d\udd27 Code Contributions"},{"location":"open-agentic-framework/CONTRIBUTING/#new-tools","text":"Creating a new tool is a great way to contribute! Tools extend agent capabilities: # Example: tools/my_awesome_tool.py from tools.base_tool import BaseTool from typing import Dict, Any class MyAwesomeTool(BaseTool): @property def name(self) -> str: return \"my_awesome_tool\" @property def description(self) -> str: return \"Does something awesome for agents\" @property def parameters(self) -> Dict[str, Any]: return { \"type\": \"object\", \"properties\": { \"input_text\": { \"type\": \"string\", \"description\": \"Text to process\" }, \"option\": { \"type\": \"string\", \"enum\": [\"fast\", \"thorough\"], \"default\": \"fast\" } }, \"required\": [\"input_text\"] } async def execute(self, parameters: Dict[str, Any]) -> Any: \"\"\"Execute the tool with given parameters\"\"\" input_text = parameters[\"input_text\"] option = parameters.get(\"option\", \"fast\") # Your tool logic here result = f\"Processed '{input_text}' with {option} mode\" return { \"result\": result, \"processed_length\": len(input_text), \"mode\": option } Tool Contribution Checklist: - [ ] Inherits from BaseTool - [ ] Has clear name , description , and parameters - [ ] Includes proper error handling - [ ] Has comprehensive tests - [ ] Includes documentation and examples - [ ] Follows security best practices","title":"New Tools"},{"location":"open-agentic-framework/CONTRIBUTING/#core-framework-improvements","text":"For core framework changes: Discuss first in an issue or discussion Maintain backward compatibility when possible Update documentation for any API changes Add comprehensive tests Consider performance impact","title":"Core Framework Improvements"},{"location":"open-agentic-framework/CONTRIBUTING/#faq","text":"","title":"\u2753 FAQ"},{"location":"open-agentic-framework/CONTRIBUTING/#q-im-new-to-open-source-how-can-i-contribute","text":"A: Start small! Look for issues labeled good first issue or help wanted . Documentation improvements and bug reports are great first contributions.","title":"Q: I'm new to open source. How can I contribute?"},{"location":"open-agentic-framework/CONTRIBUTING/#q-can-i-add-support-for-a-new-llm-provider","text":"A: Absolutely! We welcome integrations with different LLM providers. Please create an issue first to discuss the implementation approach.","title":"Q: Can I add support for a new LLM provider?"},{"location":"open-agentic-framework/CONTRIBUTING/#q-how-do-i-create-a-custom-tool","text":"A: Check out the tool creation guide and look at existing tools in the tools/ directory for examples.","title":"Q: How do I create a custom tool?"},{"location":"open-agentic-framework/CONTRIBUTING/#q-what-if-my-pr-gets-rejected","text":"A: Feedback is part of the process! We'll provide specific suggestions for improvement. Don't take it personally - we're all working together to make the project better.","title":"Q: What if my PR gets rejected?"},{"location":"open-agentic-framework/CONTRIBUTING/#q-can-i-work-on-multiple-issues-at-once","text":"A: It's better to focus on one issue at a time, especially when starting out. This helps ensure quality and makes the review process smoother.","title":"Q: Can I work on multiple issues at once?"},{"location":"open-agentic-framework/CONTRIBUTING/#thank-you","text":"Thank you for considering contributing to the Open Agentic Framework! Every contribution, no matter how small, helps make this project better for everyone.","title":"\ud83d\ude4f Thank You"},{"location":"sbom-analysis-agentic/","text":"Using AI Agents for Audit SBOMs for OSS Compliance This repository contains supporting materials from a talk on applying Agentic AI techniques to parse and analyze Software Bill of Materials (SBOMs). These materials are shared to illustrate concepts discussed during the presentation and are not intended for production use. What's Included sboms/ \u2013 Example SBOMs (in SPDX and CycloneDX formats) used in the demo slides/ \u2013 Slide deck from the talk, which includes commentary and opinions n8n_workflows/ \u2013 N8N workflow JSON files showing example automation flows Disclaimers This project is provided as a sample and learning resource. Please keep in mind: These materials are not production-ready. No warranties or guarantees are provided. Tools shown are just examples\u2014many other tools may be better suited for specific use cases. The slides contain personal views and do not represent Amazon or any employer. While I\u2019m open to discussions and idea-sharing, I cannot commit to supporting or maintaining these materials. Licensing To respect the nature of the materials: SBOM files and N8N workflow JSON files: Licensed under MIT No Attribution (MIT-0) You are free to use, copy, and adapt without attribution. Slides and written commentary: Licensed under Creative Commons Attribution-NoDerivatives 4.0 (CC BY-ND 4.0) You are welcome to quote or share with attribution but not to remix or alter.","title":"Overview"},{"location":"sbom-analysis-agentic/#using-ai-agents-for-audit-sboms-for-oss-compliance","text":"This repository contains supporting materials from a talk on applying Agentic AI techniques to parse and analyze Software Bill of Materials (SBOMs). These materials are shared to illustrate concepts discussed during the presentation and are not intended for production use.","title":"Using AI Agents for Audit SBOMs for OSS Compliance"},{"location":"sbom-analysis-agentic/#whats-included","text":"sboms/ \u2013 Example SBOMs (in SPDX and CycloneDX formats) used in the demo slides/ \u2013 Slide deck from the talk, which includes commentary and opinions n8n_workflows/ \u2013 N8N workflow JSON files showing example automation flows","title":"What's Included"},{"location":"sbom-analysis-agentic/#disclaimers","text":"This project is provided as a sample and learning resource. Please keep in mind: These materials are not production-ready. No warranties or guarantees are provided. Tools shown are just examples\u2014many other tools may be better suited for specific use cases. The slides contain personal views and do not represent Amazon or any employer. While I\u2019m open to discussions and idea-sharing, I cannot commit to supporting or maintaining these materials.","title":"Disclaimers"},{"location":"sbom-analysis-agentic/#licensing","text":"To respect the nature of the materials: SBOM files and N8N workflow JSON files: Licensed under MIT No Attribution (MIT-0) You are free to use, copy, and adapt without attribution. Slides and written commentary: Licensed under Creative Commons Attribution-NoDerivatives 4.0 (CC BY-ND 4.0) You are welcome to quote or share with attribution but not to remix or alter.","title":"Licensing"},{"location":"purl2src/","text":"PURL2SRC - Package URL to Source Download URLs Translate Package URLs (PURLs) into validated download URLs for source code artifacts across multiple package ecosystems. Provides a reliable three-tier resolution strategy with URL validation and batch processing capabilities for automated source code retrieval workflows. Features Multi-Ecosystem Support : NPM, PyPI, Cargo, NuGet, GitHub, Maven, RubyGems, Go, Conda, and more Smart Resolution Strategy : Three-level approach from direct URL construction to API queries and local fallback URL Validation : Verify download URLs are accessible before returning results SEMCL.ONE Integration : Seamlessly integrates with other ecosystem tools for comprehensive source analysis Installation pip install purl2src For development: git clone https://github.com/SemClone/purl2src.git cd purl2src pip install -e . Quick Start # Convert a single PURL to download URL purl2src \"pkg:npm/express@4.17.1\" # Batch process multiple PURLs with validation purl2src -f purls.txt --validate --output results.json Usage CLI Usage # Single PURL with default text output purl2src \"pkg:npm/express@4.17.1\" # Output: pkg:npm/express@4.17.1 -> https://registry.npmjs.org/express/-/express-4.17.1.tgz # JSON output format purl2src \"pkg:npm/express@4.17.1\" --format json # With URL validation purl2src \"pkg:pypi/requests@2.28.0\" --validate # Batch processing from file purl2src -f purls.txt --output results.json # CSV output format purl2src -f purls.txt --format csv --output results.csv Python API from purl2src import get_download_url # Get download URL for a PURL result = get_download_url(\"pkg:npm/express@4.17.1\") print(result.download_url) # https://registry.npmjs.org/express/-/express-4.17.1.tgz # With validation (recommended for production) result = get_download_url(\"pkg:pypi/requests@2.28.0\", validate=True) # Batch processing from purl2src import process_purls results = process_purls([\"pkg:npm/express@4.17.1\", \"pkg:pypi/requests@2.28.0\"]) Supported Ecosystems Ecosystem PURL Type Example NPM npm pkg:npm/@angular/core@12.0.0 PyPI pypi pkg:pypi/django@4.0.0 Cargo cargo pkg:cargo/serde@1.0.0 NuGet nuget pkg:nuget/Newtonsoft.Json@13.0.1 Maven maven pkg:maven/org.apache.commons/commons-lang3@3.12.0 RubyGems gem pkg:gem/rails@7.0.0 Go golang pkg:golang/github.com/gin-gonic/gin@v1.8.0 GitHub github pkg:github/facebook/react@v18.0.0 Conda conda pkg:conda/numpy@1.23.0?channel=conda-forge&subdir=linux-64&build=py39h1234567_0 Generic generic pkg:generic/package@1.0.0?download_url=https://example.com/file.tar.gz Examples NPM with Scoped Package purl2src \"pkg:npm/@angular/core@12.0.0\" # Output: https://registry.npmjs.org/@angular/core/-/core-12.0.0.tgz Maven with Classifier purl2src \"pkg:maven/org.apache.xmlgraphics/batik-anim@1.9.1?classifier=sources\" # Output: https://repo.maven.apache.org/maven2/org/apache/xmlgraphics/batik-anim/1.9.1/batik-anim-1.9.1-sources.jar Generic with Checksum Validation purl2src \"pkg:generic/mypackage@1.0.0?download_url=https://example.com/pkg.tar.gz&checksum=sha256:abcd1234...\" Integration with SEMCL.ONE PURL2SRC is a core component of the SEMCL.ONE ecosystem, enabling automated source code retrieval workflows: Works with src2purl for package identification and coordinate extraction Integrates with purl2notices for legal notice generation from source packages Supports upmex package metadata extraction workflows Complements osslili for comprehensive license analysis of downloaded sources Documentation User Guide - Comprehensive usage examples and configuration API Reference - Python API documentation and examples Examples - Common workflows and integration patterns Contributing We welcome contributions! Please see CONTRIBUTING.md for details on: - Code of conduct - Development setup - Submitting pull requests - Reporting issues Support For support and questions: - GitHub Issues - Bug reports and feature requests - Documentation - Complete project documentation - SEMCL.ONE Community - Ecosystem support and discussions License Apache License 2.0 - see LICENSE file for details. Authors See AUTHORS.md for a list of contributors. Part of the SEMCL.ONE ecosystem for comprehensive OSS compliance and code analysis.","title":"purl2src"},{"location":"purl2src/#purl2src-package-url-to-source-download-urls","text":"Translate Package URLs (PURLs) into validated download URLs for source code artifacts across multiple package ecosystems. Provides a reliable three-tier resolution strategy with URL validation and batch processing capabilities for automated source code retrieval workflows.","title":"PURL2SRC - Package URL to Source Download URLs"},{"location":"purl2src/#features","text":"Multi-Ecosystem Support : NPM, PyPI, Cargo, NuGet, GitHub, Maven, RubyGems, Go, Conda, and more Smart Resolution Strategy : Three-level approach from direct URL construction to API queries and local fallback URL Validation : Verify download URLs are accessible before returning results SEMCL.ONE Integration : Seamlessly integrates with other ecosystem tools for comprehensive source analysis","title":"Features"},{"location":"purl2src/#installation","text":"pip install purl2src For development: git clone https://github.com/SemClone/purl2src.git cd purl2src pip install -e .","title":"Installation"},{"location":"purl2src/#quick-start","text":"# Convert a single PURL to download URL purl2src \"pkg:npm/express@4.17.1\" # Batch process multiple PURLs with validation purl2src -f purls.txt --validate --output results.json","title":"Quick Start"},{"location":"purl2src/#usage","text":"","title":"Usage"},{"location":"purl2src/#cli-usage","text":"# Single PURL with default text output purl2src \"pkg:npm/express@4.17.1\" # Output: pkg:npm/express@4.17.1 -> https://registry.npmjs.org/express/-/express-4.17.1.tgz # JSON output format purl2src \"pkg:npm/express@4.17.1\" --format json # With URL validation purl2src \"pkg:pypi/requests@2.28.0\" --validate # Batch processing from file purl2src -f purls.txt --output results.json # CSV output format purl2src -f purls.txt --format csv --output results.csv","title":"CLI Usage"},{"location":"purl2src/#python-api","text":"from purl2src import get_download_url # Get download URL for a PURL result = get_download_url(\"pkg:npm/express@4.17.1\") print(result.download_url) # https://registry.npmjs.org/express/-/express-4.17.1.tgz # With validation (recommended for production) result = get_download_url(\"pkg:pypi/requests@2.28.0\", validate=True) # Batch processing from purl2src import process_purls results = process_purls([\"pkg:npm/express@4.17.1\", \"pkg:pypi/requests@2.28.0\"])","title":"Python API"},{"location":"purl2src/#supported-ecosystems","text":"Ecosystem PURL Type Example NPM npm pkg:npm/@angular/core@12.0.0 PyPI pypi pkg:pypi/django@4.0.0 Cargo cargo pkg:cargo/serde@1.0.0 NuGet nuget pkg:nuget/Newtonsoft.Json@13.0.1 Maven maven pkg:maven/org.apache.commons/commons-lang3@3.12.0 RubyGems gem pkg:gem/rails@7.0.0 Go golang pkg:golang/github.com/gin-gonic/gin@v1.8.0 GitHub github pkg:github/facebook/react@v18.0.0 Conda conda pkg:conda/numpy@1.23.0?channel=conda-forge&subdir=linux-64&build=py39h1234567_0 Generic generic pkg:generic/package@1.0.0?download_url=https://example.com/file.tar.gz","title":"Supported Ecosystems"},{"location":"purl2src/#examples","text":"","title":"Examples"},{"location":"purl2src/#npm-with-scoped-package","text":"purl2src \"pkg:npm/@angular/core@12.0.0\" # Output: https://registry.npmjs.org/@angular/core/-/core-12.0.0.tgz","title":"NPM with Scoped Package"},{"location":"purl2src/#maven-with-classifier","text":"purl2src \"pkg:maven/org.apache.xmlgraphics/batik-anim@1.9.1?classifier=sources\" # Output: https://repo.maven.apache.org/maven2/org/apache/xmlgraphics/batik-anim/1.9.1/batik-anim-1.9.1-sources.jar","title":"Maven with Classifier"},{"location":"purl2src/#generic-with-checksum-validation","text":"purl2src \"pkg:generic/mypackage@1.0.0?download_url=https://example.com/pkg.tar.gz&checksum=sha256:abcd1234...\"","title":"Generic with Checksum Validation"},{"location":"purl2src/#integration-with-semclone","text":"PURL2SRC is a core component of the SEMCL.ONE ecosystem, enabling automated source code retrieval workflows: Works with src2purl for package identification and coordinate extraction Integrates with purl2notices for legal notice generation from source packages Supports upmex package metadata extraction workflows Complements osslili for comprehensive license analysis of downloaded sources","title":"Integration with SEMCL.ONE"},{"location":"purl2src/#documentation","text":"User Guide - Comprehensive usage examples and configuration API Reference - Python API documentation and examples Examples - Common workflows and integration patterns","title":"Documentation"},{"location":"purl2src/#contributing","text":"We welcome contributions! Please see CONTRIBUTING.md for details on: - Code of conduct - Development setup - Submitting pull requests - Reporting issues","title":"Contributing"},{"location":"purl2src/#support","text":"For support and questions: - GitHub Issues - Bug reports and feature requests - Documentation - Complete project documentation - SEMCL.ONE Community - Ecosystem support and discussions","title":"Support"},{"location":"purl2src/#license","text":"Apache License 2.0 - see LICENSE file for details.","title":"License"},{"location":"purl2src/#authors","text":"See AUTHORS.md for a list of contributors. Part of the SEMCL.ONE ecosystem for comprehensive OSS compliance and code analysis.","title":"Authors"},{"location":"purl2src/AUTHORS/","text":"Authors Project Lead Oscar Valenzuela B. - Project creator and lead developer For a complete list of all contributors, please see the GitHub contributors page .","title":"Authors"},{"location":"purl2src/AUTHORS/#authors","text":"","title":"Authors"},{"location":"purl2src/AUTHORS/#project-lead","text":"Oscar Valenzuela B. - Project creator and lead developer For a complete list of all contributors, please see the GitHub contributors page .","title":"Project Lead"},{"location":"purl2src/CHANGELOG/","text":"Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [1.2.3] - 2025-10-27 Changed Project renamed from semantic-copycat-purl2src to purl2src Repository moved to https://github.com/SemClone/purl2src Updated all package references, URLs, and documentation to reflect new name Updated PyPI package name to purl2src [1.2.2] - 2025-10-22 Documentation Added link to LICENSE file in README.md General documentation improvements and cleanup Maintenance Added git commit message template (.gitmessage) Added git hook to prevent commits with prohibited terms Code cleanup and maintenance [1.2.1] - 2025-10-22 Security Updated urllib3 to v2.5.0 to address security vulnerability Fixed URL substring sanitization vulnerability in RubyGems handler that could potentially allow malicious URL injection [1.1.2] - 2025-01-06 Fixed Conda handler now correctly resolves download URLs for packages from the 'main' channel Main/defaults channels now use repo.anaconda.com/pkgs/main/ URL structure Community channels (conda-forge, bioconda) continue using anaconda.org URL structure Resolved issue where main channel packages were failing with \"Failed to resolve download URL\" error [0.1.1] - 2025-01-27 Changed Version is now dynamically loaded from pyproject.toml using importlib.metadata Removed hardcoded version from init .py to prevent version mismatches [0.1.0] - 2025-01-27 Added Initial release of purl2src Support for 10 package ecosystems: Maven (Java) NPM (JavaScript/TypeScript) PyPI (Python) RubyGems (Ruby) Cargo (Rust) NuGet (.NET) Golang (Go modules) Conda (Data Science/Python) GitHub (Source repositories) Generic (Direct URLs) Three-level resolution strategy: Direct URL construction from PURL components Registry API queries for download URLs Package manager CLI fallback with availability detection CLI tool purl2src with: Single PURL resolution Batch processing from files JSON, CSV, and text output formats Progress bar for batch operations URL validation options Automatic output format detection from file extension Comprehensive PURL parsing with support for: Namespaces (e.g., Maven group IDs, npm scopes) Versions with special characters Qualifiers (repository URLs, classifiers, etc.) Subpaths HTTP client with: Connection pooling Retry logic with exponential backoff Proper timeout handling User-Agent headers Package manager detection for fallback commands Proper handling of scoped NPM packages (@namespace/package) Fixed PURL parser regex to handle scoped NPM packages with @ symbol CLI progressbar compatibility issue Test assertion for PURLs with qualifiers Maven artifact naming for Apache Commons IO versions fallback_available flag to correctly reflect package manager installation status urllib3 OpenSSL warning on macOS by constraining to v1.x and adding warning suppression NPM fallback command encoding issue - removed URL encoding for npm commands Security All HTTP requests use HTTPS where available No credentials or sensitive data are stored or logged Secure command execution with proper escaping Changed License from MIT to Apache-2.0 Known Issues Maven fallback command doesn't directly return download URLs (downloads to local repository) Some ecosystem API endpoints may have rate limits","title":"Changelog"},{"location":"purl2src/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"purl2src/CHANGELOG/#123-2025-10-27","text":"","title":"[1.2.3] - 2025-10-27"},{"location":"purl2src/CHANGELOG/#changed","text":"Project renamed from semantic-copycat-purl2src to purl2src Repository moved to https://github.com/SemClone/purl2src Updated all package references, URLs, and documentation to reflect new name Updated PyPI package name to purl2src","title":"Changed"},{"location":"purl2src/CHANGELOG/#122-2025-10-22","text":"","title":"[1.2.2] - 2025-10-22"},{"location":"purl2src/CHANGELOG/#documentation","text":"Added link to LICENSE file in README.md General documentation improvements and cleanup","title":"Documentation"},{"location":"purl2src/CHANGELOG/#maintenance","text":"Added git commit message template (.gitmessage) Added git hook to prevent commits with prohibited terms Code cleanup and maintenance","title":"Maintenance"},{"location":"purl2src/CHANGELOG/#121-2025-10-22","text":"","title":"[1.2.1] - 2025-10-22"},{"location":"purl2src/CHANGELOG/#security","text":"Updated urllib3 to v2.5.0 to address security vulnerability Fixed URL substring sanitization vulnerability in RubyGems handler that could potentially allow malicious URL injection","title":"Security"},{"location":"purl2src/CHANGELOG/#112-2025-01-06","text":"","title":"[1.1.2] - 2025-01-06"},{"location":"purl2src/CHANGELOG/#fixed","text":"Conda handler now correctly resolves download URLs for packages from the 'main' channel Main/defaults channels now use repo.anaconda.com/pkgs/main/ URL structure Community channels (conda-forge, bioconda) continue using anaconda.org URL structure Resolved issue where main channel packages were failing with \"Failed to resolve download URL\" error","title":"Fixed"},{"location":"purl2src/CHANGELOG/#011-2025-01-27","text":"","title":"[0.1.1] - 2025-01-27"},{"location":"purl2src/CHANGELOG/#changed_1","text":"Version is now dynamically loaded from pyproject.toml using importlib.metadata Removed hardcoded version from init .py to prevent version mismatches","title":"Changed"},{"location":"purl2src/CHANGELOG/#010-2025-01-27","text":"","title":"[0.1.0] - 2025-01-27"},{"location":"purl2src/CHANGELOG/#added","text":"Initial release of purl2src Support for 10 package ecosystems: Maven (Java) NPM (JavaScript/TypeScript) PyPI (Python) RubyGems (Ruby) Cargo (Rust) NuGet (.NET) Golang (Go modules) Conda (Data Science/Python) GitHub (Source repositories) Generic (Direct URLs) Three-level resolution strategy: Direct URL construction from PURL components Registry API queries for download URLs Package manager CLI fallback with availability detection CLI tool purl2src with: Single PURL resolution Batch processing from files JSON, CSV, and text output formats Progress bar for batch operations URL validation options Automatic output format detection from file extension Comprehensive PURL parsing with support for: Namespaces (e.g., Maven group IDs, npm scopes) Versions with special characters Qualifiers (repository URLs, classifiers, etc.) Subpaths HTTP client with: Connection pooling Retry logic with exponential backoff Proper timeout handling User-Agent headers Package manager detection for fallback commands Proper handling of scoped NPM packages (@namespace/package)","title":"Added"},{"location":"purl2src/CHANGELOG/#fixed_1","text":"PURL parser regex to handle scoped NPM packages with @ symbol CLI progressbar compatibility issue Test assertion for PURLs with qualifiers Maven artifact naming for Apache Commons IO versions fallback_available flag to correctly reflect package manager installation status urllib3 OpenSSL warning on macOS by constraining to v1.x and adding warning suppression NPM fallback command encoding issue - removed URL encoding for npm commands","title":"Fixed"},{"location":"purl2src/CHANGELOG/#security_1","text":"All HTTP requests use HTTPS where available No credentials or sensitive data are stored or logged Secure command execution with proper escaping","title":"Security"},{"location":"purl2src/CHANGELOG/#changed_2","text":"License from MIT to Apache-2.0","title":"Changed"},{"location":"purl2src/CHANGELOG/#known-issues","text":"Maven fallback command doesn't directly return download URLs (downloads to local repository) Some ecosystem API endpoints may have rate limits","title":"Known Issues"},{"location":"purl2src/CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Contributor Covenant Code of Conduct"},{"location":"purl2src/CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"purl2src/CODE_OF_CONDUCT/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"purl2src/CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"purl2src/CODE_OF_CONDUCT/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"purl2src/CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"purl2src/CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"purl2src/CODE_OF_CONDUCT/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"purl2src/CODE_OF_CONDUCT/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"purl2src/CODE_OF_CONDUCT/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"purl2src/CODE_OF_CONDUCT/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"purl2src/CODE_OF_CONDUCT/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"purl2src/CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Attribution"},{"location":"purl2src/CONTRIBUTING/","text":"Contributing to purl2src First off, thank you for considering contributing to purl2src! It's people like you that make purl2src such a great tool. Code of Conduct This project and everyone participating in it is governed by the Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to conduct@semcl.one . How Can I Contribute? Reporting Bugs Before creating bug reports, please check existing issues as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one. How Do I Submit A Good Bug Report? Bugs are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem. If the problem wasn't triggered by a specific action , describe what you were doing before the problem happened and share more information using the guidelines below. Suggesting Enhancements Enhancement suggestions are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps . Include copy/pasteable snippets which you use in those examples. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users. List some other projects where this enhancement exists. Your First Code Contribution Unsure where to begin contributing? You can start by looking through these beginner and help-wanted issues: [Beginner issues][beginner] - issues which should only require a few lines of code, and a test or two. [Help wanted issues][help-wanted] - issues which should be a bit more involved than beginner issues. Pull Requests The process described here has several goals: Maintain code quality Fix problems that are important to users Engage the community in working toward the best possible product Enable a sustainable system for maintainers to review contributions Please follow these steps to have your contribution considered by the maintainers: Follow all instructions in the template Follow the styleguides After you submit your pull request, verify that all status checks are passing While the prerequisites above must be satisfied prior to having your pull request reviewed, the reviewer(s) may ask you to complete additional design work, tests, or other changes before your pull request can be ultimately accepted. Styleguides Git Commit Messages Use the present tense (\"Add feature\" not \"Added feature\") Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit the first line to 72 characters or less Reference issues and pull requests liberally after the first line When only changing documentation, include [ci skip] in the commit title Python Styleguide All Python code must adhere to PEP 8 . Use type hints where appropriate Include docstrings for all public functions, classes, and modules Prefer explicit over implicit Write tests for new functionality Documentation Styleguide Use Markdown . Reference functions and classes in backticks: `function_name()`. Include code examples where appropriate. Development Process Fork the repo and create your branch from main . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request! Development Setup # Clone your fork git clone https://github.com/your-username/purl2src.git cd purl2src # Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # Install dependencies pip install -e .[dev] # Run tests pytest # Run linting ruff check . black --check . Running Tests # Run all tests pytest # Run with coverage pytest --cov=purl2src # Run specific test file pytest tests/test_specific.py Community You can chat with the community on: - GitHub Discussions - Issues Recognition Contributors who have made significant contributions will be recognized in our AUTHORS file. Thank you for contributing!","title":"Contributing to purl2src"},{"location":"purl2src/CONTRIBUTING/#contributing-to-purl2src","text":"First off, thank you for considering contributing to purl2src! It's people like you that make purl2src such a great tool.","title":"Contributing to purl2src"},{"location":"purl2src/CONTRIBUTING/#code-of-conduct","text":"This project and everyone participating in it is governed by the Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to conduct@semcl.one .","title":"Code of Conduct"},{"location":"purl2src/CONTRIBUTING/#how-can-i-contribute","text":"","title":"How Can I Contribute?"},{"location":"purl2src/CONTRIBUTING/#reporting-bugs","text":"Before creating bug reports, please check existing issues as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one.","title":"Reporting Bugs"},{"location":"purl2src/CONTRIBUTING/#how-do-i-submit-a-good-bug-report","text":"Bugs are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem. If the problem wasn't triggered by a specific action , describe what you were doing before the problem happened and share more information using the guidelines below.","title":"How Do I Submit A Good Bug Report?"},{"location":"purl2src/CONTRIBUTING/#suggesting-enhancements","text":"Enhancement suggestions are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps . Include copy/pasteable snippets which you use in those examples. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users. List some other projects where this enhancement exists.","title":"Suggesting Enhancements"},{"location":"purl2src/CONTRIBUTING/#your-first-code-contribution","text":"Unsure where to begin contributing? You can start by looking through these beginner and help-wanted issues: [Beginner issues][beginner] - issues which should only require a few lines of code, and a test or two. [Help wanted issues][help-wanted] - issues which should be a bit more involved than beginner issues.","title":"Your First Code Contribution"},{"location":"purl2src/CONTRIBUTING/#pull-requests","text":"The process described here has several goals: Maintain code quality Fix problems that are important to users Engage the community in working toward the best possible product Enable a sustainable system for maintainers to review contributions Please follow these steps to have your contribution considered by the maintainers: Follow all instructions in the template Follow the styleguides After you submit your pull request, verify that all status checks are passing While the prerequisites above must be satisfied prior to having your pull request reviewed, the reviewer(s) may ask you to complete additional design work, tests, or other changes before your pull request can be ultimately accepted.","title":"Pull Requests"},{"location":"purl2src/CONTRIBUTING/#styleguides","text":"","title":"Styleguides"},{"location":"purl2src/CONTRIBUTING/#git-commit-messages","text":"Use the present tense (\"Add feature\" not \"Added feature\") Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit the first line to 72 characters or less Reference issues and pull requests liberally after the first line When only changing documentation, include [ci skip] in the commit title","title":"Git Commit Messages"},{"location":"purl2src/CONTRIBUTING/#python-styleguide","text":"All Python code must adhere to PEP 8 . Use type hints where appropriate Include docstrings for all public functions, classes, and modules Prefer explicit over implicit Write tests for new functionality","title":"Python Styleguide"},{"location":"purl2src/CONTRIBUTING/#documentation-styleguide","text":"Use Markdown . Reference functions and classes in backticks: `function_name()`. Include code examples where appropriate.","title":"Documentation Styleguide"},{"location":"purl2src/CONTRIBUTING/#development-process","text":"Fork the repo and create your branch from main . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request!","title":"Development Process"},{"location":"purl2src/CONTRIBUTING/#development-setup","text":"# Clone your fork git clone https://github.com/your-username/purl2src.git cd purl2src # Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # Install dependencies pip install -e .[dev] # Run tests pytest # Run linting ruff check . black --check .","title":"Development Setup"},{"location":"purl2src/CONTRIBUTING/#running-tests","text":"# Run all tests pytest # Run with coverage pytest --cov=purl2src # Run specific test file pytest tests/test_specific.py","title":"Running Tests"},{"location":"purl2src/CONTRIBUTING/#community","text":"You can chat with the community on: - GitHub Discussions - Issues","title":"Community"},{"location":"purl2src/CONTRIBUTING/#recognition","text":"Contributors who have made significant contributions will be recognized in our AUTHORS file. Thank you for contributing!","title":"Recognition"},{"location":"purl2src/SECURITY/","text":"Security Policy Supported Versions We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release Reporting a Vulnerability Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. Preferred Languages We prefer all communications to be in English. Policy We follow the principle of Coordinated Vulnerability Disclosure.","title":"Security Policy"},{"location":"purl2src/SECURITY/#security-policy","text":"","title":"Security Policy"},{"location":"purl2src/SECURITY/#supported-versions","text":"We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release","title":"Supported Versions"},{"location":"purl2src/SECURITY/#reporting-a-vulnerability","text":"Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly.","title":"Reporting a Vulnerability"},{"location":"purl2src/SECURITY/#preferred-languages","text":"We prefer all communications to be in English.","title":"Preferred Languages"},{"location":"purl2src/SECURITY/#policy","text":"We follow the principle of Coordinated Vulnerability Disclosure.","title":"Policy"},{"location":"purl2src/SUPPORT/","text":"Support How to Get Help Thank you for using this project! Here are the best ways to get help: Documentation Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available) Getting Answers Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly Reporting Issues If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue Feature Requests We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project Security Issues For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines. Community Guidelines Please review our Code of Conduct before participating in discussions. Response Times This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours Additional Resources Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Support"},{"location":"purl2src/SUPPORT/#support","text":"","title":"Support"},{"location":"purl2src/SUPPORT/#how-to-get-help","text":"Thank you for using this project! Here are the best ways to get help:","title":"How to Get Help"},{"location":"purl2src/SUPPORT/#documentation","text":"Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available)","title":"Documentation"},{"location":"purl2src/SUPPORT/#getting-answers","text":"Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly","title":"Getting Answers"},{"location":"purl2src/SUPPORT/#reporting-issues","text":"If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue","title":"Reporting Issues"},{"location":"purl2src/SUPPORT/#feature-requests","text":"We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project","title":"Feature Requests"},{"location":"purl2src/SUPPORT/#security-issues","text":"For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines.","title":"Security Issues"},{"location":"purl2src/SUPPORT/#community-guidelines","text":"Please review our Code of Conduct before participating in discussions.","title":"Community Guidelines"},{"location":"purl2src/SUPPORT/#response-times","text":"This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours","title":"Response Times"},{"location":"purl2src/SUPPORT/#additional-resources","text":"Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Additional Resources"},{"location":"osslili/","text":"OSS License & Copyright Detector (osslili) A high-performance tool for identifying licenses and copyright information in local source code. Produces detailed evidence of where licenses are detected with support for all 700+ SPDX license identifiers, enabling comprehensive compliance documentation for the SEMCL.ONE ecosystem. Features Three-Tier License Detection : Dice-S\u00f8rensen similarity, TLSH fuzzy hashing, and regex pattern matching Evidence-Based Output : Exact file paths, confidence scores, and detection methods 700+ SPDX Licenses : Comprehensive support for all SPDX license identifiers SEMCL.ONE Integration : Works seamlessly with purl2notices, ospac, and other ecosystem tools How It Works Three-Tier License Detection System The tool uses a sophisticated multi-tier approach for maximum accuracy: Tier 1: Dice-S\u00f8rensen Similarity with TLSH Confirmation Compares license text using Dice-S\u00f8rensen coefficient (97% threshold) Confirms matches using TLSH fuzzy hashing to prevent false positives Achieves 97-100% accuracy on standard SPDX licenses Tier 2: TLSH Fuzzy Hash Matching Uses Trend Micro Locality Sensitive Hashing for variant detection Catches license variants like MIT-0, BSD-2-Clause vs BSD-3-Clause Pre-computed hashes for all 700+ SPDX licenses Tier 3: Pattern Recognition Regex-based detection for license references and identifiers Extracts from comments, headers, and documentation Additional Detection Methods Package Metadata Scanning : Detects licenses from package.json, composer.json, pyproject.toml, etc. Copyright Extraction : Advanced pattern matching with validation and deduplication SPDX Identifier Detection : Finds SPDX-License-Identifier tags in source files Installation pip install osslili For development: git clone https://github.com/SemClone/osslili.git cd osslili pip install -e . Quick Start # Scan current directory for licenses osslili . # Generate SBOM with license evidence osslili ./my-project -f cyclonedx-json -o sbom.json Usage CLI Usage # Scan a directory and see evidence (default format) osslili /path/to/project # Generate different output formats osslili ./my-project -f kissbom -o kissbom.json osslili ./my-project -f cyclonedx-json -o sbom.json osslili ./my-project -f cyclonedx-xml -o sbom.xml # Scan with parallel processing (4 threads) osslili ./my-project --threads 4 # Scan with limited depth (only 2 levels deep) osslili ./my-project --max-depth 2 # Extract and scan archives osslili package.tar.gz --max-extraction-depth 2 # Use caching for faster repeated scans osslili ./my-project --cache-dir ~/.cache/osslili # Check version osslili --version # Save results to file osslili ./my-project -o license-evidence.json # With custom configuration and verbose output osslili ./src --config config.yaml --verbose # Debug mode for detailed logging osslili ./project --debug Example Output { \"scan_results\": [{ \"path\": \"./project\", \"license_evidence\": [ { \"file\": \"/path/to/project/LICENSE\", \"detected_license\": \"Apache-2.0\", \"confidence\": 0.988, \"detection_method\": \"dice-sorensen\", \"category\": \"declared\", \"match_type\": \"text_similarity\", \"description\": \"Text matches Apache-2.0 license (98.8% similarity)\" }, { \"file\": \"/path/to/project/package.json\", \"detected_license\": \"Apache-2.0\", \"confidence\": 1.0, \"detection_method\": \"tag\", \"category\": \"declared\", \"match_type\": \"spdx_identifier\", \"description\": \"SPDX-License-Identifier: Apache-2.0 found\" } ], \"copyright_evidence\": [ { \"file\": \"/path/to/project/src/main.py\", \"holder\": \"Example Corp\", \"years\": [2023, 2024], \"statement\": \"Copyright 2023-2024 Example Corp\" } ] }], \"summary\": { \"total_files_scanned\": 42, \"declared_licenses\": {\"Apache-2.0\": 2}, \"detected_licenses\": {}, \"referenced_licenses\": {}, \"copyright_holders\": [\"Example Corp\"] } } Library Usage from osslili import LicenseCopyrightDetector # Initialize detector detector = LicenseCopyrightDetector() # Process a local directory result = detector.process_local_path(\"/path/to/source\") # Process a single file result = detector.process_local_path(\"/path/to/LICENSE\") # Generate different output formats evidence = detector.generate_evidence([result]) kissbom = detector.generate_kissbom([result]) cyclonedx = detector.generate_cyclonedx([result], format_type=\"json\") cyclonedx_xml = detector.generate_cyclonedx([result], format_type=\"xml\") # Access results directly for license in result.licenses: print(f\"License: {license.spdx_id} ({license.confidence:.0%} confidence)\") print(f\" Category: {license.category}\") # declared, detected, or referenced for copyright in result.copyrights: print(f\"Copyright: \u00a9 {copyright.holder}\") Output Format The tool outputs JSON evidence showing: - File path : Where the license was found - Detected license : The SPDX identifier of the license - Confidence : How confident the detection is (0.0 to 1.0) - Match type : How the license was detected (license_text, spdx_identifier, license_reference, text_similarity) - Description : Human-readable description of what was found Integration with SEMCL.ONE OSS License & Copyright Detector is a core component of the SEMCL.ONE ecosystem: Works with purl2notices for comprehensive legal notice generation Integrates with ospac for policy-based compliance evaluation Supports ossnotices for simplified attribution documentation Complements upmex for package metadata extraction workflows Configuration Create a config.yaml file: similarity_threshold: 0.97 max_recursion_depth: 10 max_extraction_depth: 10 thread_count: 4 cache_dir: \"~/.cache/osslili\" custom_aliases: \"Apache 2\": \"Apache-2.0\" \"MIT License\": \"MIT\" Documentation User Guide - Comprehensive usage examples and configuration API Reference - Python API documentation and examples SPDX Updates - How to update SPDX license data Performance Benchmarks - Comparison with other tools Contributing We welcome contributions! Please see CONTRIBUTING.md for details on: - Code of conduct - Development setup - Submitting pull requests - Reporting issues Support For support and questions: - GitHub Issues - Bug reports and feature requests - Documentation - Complete project documentation - SEMCL.ONE Community - Ecosystem support and discussions License Apache License 2.0 - see LICENSE file for details. Authors See AUTHORS.md for a list of contributors. Part of the SEMCL.ONE ecosystem for comprehensive OSS compliance and code analysis.","title":"osslili"},{"location":"osslili/#oss-license-copyright-detector-osslili","text":"A high-performance tool for identifying licenses and copyright information in local source code. Produces detailed evidence of where licenses are detected with support for all 700+ SPDX license identifiers, enabling comprehensive compliance documentation for the SEMCL.ONE ecosystem.","title":"OSS License &amp; Copyright Detector (osslili)"},{"location":"osslili/#features","text":"Three-Tier License Detection : Dice-S\u00f8rensen similarity, TLSH fuzzy hashing, and regex pattern matching Evidence-Based Output : Exact file paths, confidence scores, and detection methods 700+ SPDX Licenses : Comprehensive support for all SPDX license identifiers SEMCL.ONE Integration : Works seamlessly with purl2notices, ospac, and other ecosystem tools","title":"Features"},{"location":"osslili/#how-it-works","text":"","title":"How It Works"},{"location":"osslili/#three-tier-license-detection-system","text":"The tool uses a sophisticated multi-tier approach for maximum accuracy: Tier 1: Dice-S\u00f8rensen Similarity with TLSH Confirmation Compares license text using Dice-S\u00f8rensen coefficient (97% threshold) Confirms matches using TLSH fuzzy hashing to prevent false positives Achieves 97-100% accuracy on standard SPDX licenses Tier 2: TLSH Fuzzy Hash Matching Uses Trend Micro Locality Sensitive Hashing for variant detection Catches license variants like MIT-0, BSD-2-Clause vs BSD-3-Clause Pre-computed hashes for all 700+ SPDX licenses Tier 3: Pattern Recognition Regex-based detection for license references and identifiers Extracts from comments, headers, and documentation","title":"Three-Tier License Detection System"},{"location":"osslili/#additional-detection-methods","text":"Package Metadata Scanning : Detects licenses from package.json, composer.json, pyproject.toml, etc. Copyright Extraction : Advanced pattern matching with validation and deduplication SPDX Identifier Detection : Finds SPDX-License-Identifier tags in source files","title":"Additional Detection Methods"},{"location":"osslili/#installation","text":"pip install osslili For development: git clone https://github.com/SemClone/osslili.git cd osslili pip install -e .","title":"Installation"},{"location":"osslili/#quick-start","text":"# Scan current directory for licenses osslili . # Generate SBOM with license evidence osslili ./my-project -f cyclonedx-json -o sbom.json","title":"Quick Start"},{"location":"osslili/#usage","text":"","title":"Usage"},{"location":"osslili/#cli-usage","text":"# Scan a directory and see evidence (default format) osslili /path/to/project # Generate different output formats osslili ./my-project -f kissbom -o kissbom.json osslili ./my-project -f cyclonedx-json -o sbom.json osslili ./my-project -f cyclonedx-xml -o sbom.xml # Scan with parallel processing (4 threads) osslili ./my-project --threads 4 # Scan with limited depth (only 2 levels deep) osslili ./my-project --max-depth 2 # Extract and scan archives osslili package.tar.gz --max-extraction-depth 2 # Use caching for faster repeated scans osslili ./my-project --cache-dir ~/.cache/osslili # Check version osslili --version # Save results to file osslili ./my-project -o license-evidence.json # With custom configuration and verbose output osslili ./src --config config.yaml --verbose # Debug mode for detailed logging osslili ./project --debug","title":"CLI Usage"},{"location":"osslili/#example-output","text":"{ \"scan_results\": [{ \"path\": \"./project\", \"license_evidence\": [ { \"file\": \"/path/to/project/LICENSE\", \"detected_license\": \"Apache-2.0\", \"confidence\": 0.988, \"detection_method\": \"dice-sorensen\", \"category\": \"declared\", \"match_type\": \"text_similarity\", \"description\": \"Text matches Apache-2.0 license (98.8% similarity)\" }, { \"file\": \"/path/to/project/package.json\", \"detected_license\": \"Apache-2.0\", \"confidence\": 1.0, \"detection_method\": \"tag\", \"category\": \"declared\", \"match_type\": \"spdx_identifier\", \"description\": \"SPDX-License-Identifier: Apache-2.0 found\" } ], \"copyright_evidence\": [ { \"file\": \"/path/to/project/src/main.py\", \"holder\": \"Example Corp\", \"years\": [2023, 2024], \"statement\": \"Copyright 2023-2024 Example Corp\" } ] }], \"summary\": { \"total_files_scanned\": 42, \"declared_licenses\": {\"Apache-2.0\": 2}, \"detected_licenses\": {}, \"referenced_licenses\": {}, \"copyright_holders\": [\"Example Corp\"] } }","title":"Example Output"},{"location":"osslili/#library-usage","text":"from osslili import LicenseCopyrightDetector # Initialize detector detector = LicenseCopyrightDetector() # Process a local directory result = detector.process_local_path(\"/path/to/source\") # Process a single file result = detector.process_local_path(\"/path/to/LICENSE\") # Generate different output formats evidence = detector.generate_evidence([result]) kissbom = detector.generate_kissbom([result]) cyclonedx = detector.generate_cyclonedx([result], format_type=\"json\") cyclonedx_xml = detector.generate_cyclonedx([result], format_type=\"xml\") # Access results directly for license in result.licenses: print(f\"License: {license.spdx_id} ({license.confidence:.0%} confidence)\") print(f\" Category: {license.category}\") # declared, detected, or referenced for copyright in result.copyrights: print(f\"Copyright: \u00a9 {copyright.holder}\")","title":"Library Usage"},{"location":"osslili/#output-format","text":"The tool outputs JSON evidence showing: - File path : Where the license was found - Detected license : The SPDX identifier of the license - Confidence : How confident the detection is (0.0 to 1.0) - Match type : How the license was detected (license_text, spdx_identifier, license_reference, text_similarity) - Description : Human-readable description of what was found","title":"Output Format"},{"location":"osslili/#integration-with-semclone","text":"OSS License & Copyright Detector is a core component of the SEMCL.ONE ecosystem: Works with purl2notices for comprehensive legal notice generation Integrates with ospac for policy-based compliance evaluation Supports ossnotices for simplified attribution documentation Complements upmex for package metadata extraction workflows","title":"Integration with SEMCL.ONE"},{"location":"osslili/#configuration","text":"Create a config.yaml file: similarity_threshold: 0.97 max_recursion_depth: 10 max_extraction_depth: 10 thread_count: 4 cache_dir: \"~/.cache/osslili\" custom_aliases: \"Apache 2\": \"Apache-2.0\" \"MIT License\": \"MIT\"","title":"Configuration"},{"location":"osslili/#documentation","text":"User Guide - Comprehensive usage examples and configuration API Reference - Python API documentation and examples SPDX Updates - How to update SPDX license data Performance Benchmarks - Comparison with other tools","title":"Documentation"},{"location":"osslili/#contributing","text":"We welcome contributions! Please see CONTRIBUTING.md for details on: - Code of conduct - Development setup - Submitting pull requests - Reporting issues","title":"Contributing"},{"location":"osslili/#support","text":"For support and questions: - GitHub Issues - Bug reports and feature requests - Documentation - Complete project documentation - SEMCL.ONE Community - Ecosystem support and discussions","title":"Support"},{"location":"osslili/#license","text":"Apache License 2.0 - see LICENSE file for details.","title":"License"},{"location":"osslili/#authors","text":"See AUTHORS.md for a list of contributors. Part of the SEMCL.ONE ecosystem for comprehensive OSS compliance and code analysis.","title":"Authors"},{"location":"osslili/AUTHORS/","text":"Authors Project Lead Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Authors"},{"location":"osslili/AUTHORS/#authors","text":"","title":"Authors"},{"location":"osslili/AUTHORS/#project-lead","text":"Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Project Lead"},{"location":"osslili/CHANGELOG/","text":"Changelog All notable changes to osslili will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [Unreleased] [1.5.7] - 2025-10-30 Changed Performance Optimization : Updated default values for better performance Reduced default max recursion depth from 10 to 4 for faster directory scans Set explicit thread count default to 4 in CLI (previously inherited from Config) Aligned CLI and Config model defaults for consistency Technical CLI Defaults : Added explicit default values in CLI options for better visibility Configuration : Synchronized default values between CLI and Config model [1.5.6] - 2025-10-27 Changed Project Rename : Renamed project from semantic-copycat-oslili to osslili Updated package name and imports throughout codebase Changed CLI command from oslili to osslili Updated repository URL to https://github.com/SemClone/osslili Renamed main Python package directory from semantic_copycat_oslili to osslili Updated all documentation, configuration files, and scripts Simplified project description to \"Open Source License Identification Library\" Technical Package Structure : Completely reorganized package structure for the new name Import Compatibility : All import statements updated to use new package name Documentation : Updated all references across README, docs, and examples [1.5.5] - 2025-10-24 Fixed False Positive Copyright Detection : Eliminated false positive copyright holder detections Fixed overly broad regex patterns that captured programming language constructs Added filtering for Fortran data types (integer*1, character) being detected as copyright holders Enhanced filtering for Python code fragments (is not None, or sig_pattern, is np, is not np) Improved regex patterns to stop at programming keywords (is, or, and) Added exact match filtering for known false positive patterns Better handling of contributor phrases like \"and individual contributors\" Improved Copyright Extraction Accuracy : More precise copyright holder identification with significantly fewer false positives Code Pattern Detection : Enhanced recognition of programming language constructs to prevent them from being interpreted as copyright information [1.5.4] - 2025-10-24 Fixed False Positive License Detection : Significantly reduced false positive license detections Fixed overly broad keyword patterns for Python-2.0, ISC, and Perl licenses Enhanced context validation to require license-specific contexts for matches Added filtering for generic programming language names being detected as licenses Improved ISC license pattern specificity to require actual ISC license text Strengthened validation to prevent common programming terms from being flagged as licenses Improved License Detection Accuracy : More precise detection with fewer false positives while maintaining legitimate detection coverage Context Checking : Enhanced validation that license keywords appear in actual license contexts rather than general code comments [1.5.3] - 2025-10-21 Added Evidence Detail Levels : New --evidence-detail CLI option with 4 levels for controlling output verbosity minimal : Just license counts (compact 1KB output) summary : Adds detection method breakdown (1KB output) detailed : Includes sample evidence (72KB output) - default full : Complete evidence (several MB output) License Normalizer Utility : New utility class for consistent license ID normalization Regex Pattern Matcher : Optimized regex matching with lookup tables for better performance Fixed Critical Deduplication Bug : Fixed license detection deduplication that was discarding 99% of detections Changed deduplication key from (license_id, confidence) to (license_id, confidence, source_file) Increases detection coverage from ~1% to 99%+ of expected files File Readability Detection : Enhanced detection for better source file coverage Added more permissive encoding detection (UTF-8, Latin-1, cp1252, ISO-8859-1) Improved binary file detection with magic number signatures Better handling of files with mixed encodings Improved License Detection Coverage : Reduced false negatives while maintaining low false positive rate Reduced license text indicator threshold from 3 to 1 for better coverage Added validation filtering to reduce false positives Enhanced match type categorization (license_file, spdx_identifier, package_metadata, etc.) Performance Optimizations : Maintained ~117 files/second processing speed Memory-efficient streaming processing for large files Optimized regex pattern matching with lookup tables Parallel processing improvements Changed Evidence Formatter : Enhanced with detail level filtering and better match type descriptions License Detector : Improved categorization logic and false positive filtering [1.5.1] - 2025-10-17 Fixed Copyright Detection : Fixed overly aggressive filtering of copyright holders (issue #32) Copyright holders containing words like \"Test\", \"Demo\", etc. are now correctly detected when part of legitimate names \"Test Corporation\", \"TestCo Inc\", and similar names are now properly recognized Only standalone test/demo placeholders are filtered out (e.g., just \"test\" or \"demo\") Maintains filtering of actual placeholder text while allowing real organizations with these words [1.5.0] - 2025-10-15 Added Enhanced License Detection Accuracy : Significantly improved license detection with multi-pattern support (PR #30, issue #29) Multi-line pattern detection for licenses split across lines Fuzzy matching for common typos (e.g., \"Lisense\" to \"License\") Version suffix handling (GPLv2+ to GPL-2.0-or-later) License keyword detection with 47 comprehensive patterns Support for detecting licenses in all file types Comprehensive Benchmark : Added detailed comparison with ScanCode Toolkit Performance comparison showing 1.8x-30x faster execution Detection accuracy analysis with feature comparison matrix Use case recommendations for both tools Improved 4-Tier License Detection : All detection methods now engage for maximum accuracy Hash matching for exact license files Dice-S\u00f8rensen similarity for text similarity TLSH fuzzy hashing for variant detection Enhanced regex patterns for edge cases Edge Case Handling : Fixed detection for numerous previously failing cases Python Software Foundation License full phrase GNU Lesser General Public License v2.1 Generic GPL references with context-aware version detection MIT licenses in copyright lines Apache License with newlines in header Pattern Library : Integrated patterns from scancode-licensedb Added 47+ license patterns for comprehensive coverage Improved detection for permissive, copyleft, and proprietary licenses Better handling of license variations and aliases Fixed License Normalization : Improved SPDX ID normalization GNU-GPL-v2 to GPL-2.0 GPLv2+ to GPL-2.0-or-later Better handling of version suffixes and variations False Negative Reduction : Reduced false negative rate from 46.7% to near 0% Previously undetected licenses now properly identified Improved coverage across different file types and formats Performance Copyright Extraction : 26x more comprehensive than comparable tools Speed : Maintained 1.8x-30x faster performance while improving accuracy Scalability : Successfully tested on large codebases (FFmpeg-8.0) [1.4.1] - 2025-10-12 Fixed pyproject.toml PEP 639 File Reference : Fixed license detection from license = {file = \"LICENSE\"} format Changed from non-existent _detect_license_from_text() to proper _detect_from_full_text() method Now correctly reads and detects licenses from referenced files in pyproject.toml Properly sets category as DECLARED for licenses from metadata file references Added debug logging when referenced license file doesn't exist Removed Notices Output Format : Removed human-readable notices format to focus on scanning and verification Removed notices_formatter.py module Removed generate_notices() method from LicenseCopyrightDetector Removed notices option from CLI output formats Updated documentation to remove references to notices format This simplifies the codebase and clarifies the tool's primary purpose as a scanner/verifier [1.4.0] - 2025-10-12 Added Source Header License Detection in Metadata Files : Extract SPDX tags and license references from comments/headers Detects licenses in XML comments (pom.xml) Detects licenses in Python comments (setup.py, setup.cfg) Detects licenses in TOML comments (Cargo.toml) Detects licenses in Ruby comments (*.gemspec) New _extract_header_licenses() method for comprehensive header scanning Enhanced Package Metadata Support : Added extraction methods for additional formats Full support for package.json (Node.js) with SPDX expressions and arrays Full support for composer.json (PHP) with comment cleaning Improved extraction from all major package formats Fast-path Metadata API : New extract_package_metadata() method for metadata-only extraction Skips full text analysis for faster processing Supports all major package metadata formats Returns licenses from both structured metadata and source headers Improved Intelligent License Deduplication : Smart handling when same license found in multiple locations Prefers metadata version over header version as more authoritative Prevents duplicate licenses in results Tracks licenses by (spdx_id, match_type) for accurate deduplication Python Classifier Extraction : Fixed to handle both quoted and unquoted formats Works with setup.py quoted classifiers Works with setup.cfg unquoted classifiers Properly extracts OSI Approved licenses from trove classifiers File Pattern Matching : Enhanced to handle temporary files and various naming conventions Supports files ending with metadata names (e.g., temp_xyz.package.json) Better handling of edge cases in file detection Gemspec and Cargo.toml Processing : Added duplicate prevention Tracks found licenses to avoid duplicates Handles both single and array license declarations Fixed Duplicate License Detection : Resolved issues with licenses appearing multiple times Fixed gemspec pattern matching causing duplicates Fixed Cargo.toml SPDX expression parsing duplicates Improved overall deduplication logic [1.3.6] - 2025-09-06 Added Tier 0 Exact Hash Matching : Added SHA-256 and MD5 hash matching as the first detection tier Pre-computed hashes for all 699 SPDX licenses Support for license variants and aliases 100% confidence for exact matches New DetectionMethod.HASH enum value Hash Inventory System : Comprehensive hash inventory for license matching Standard SPDX license hashes Common variants (e.g., gradle-wrapper Apache-2.0) Hash lookup tables for fast matching Support for hash collisions (e.g., GPL versions) Improved Detection Tier Reorganization : Four-tier system: Hash \u2192 Dice-S\u00f8rensen \u2192 TLSH \u2192 Regex Exact hash matching runs first for perfect matches Dice-S\u00f8rensen no longer requires TLSH confirmation for >95% confidence Better performance and accuracy Apache-2.0 vs Pixar Disambiguation : Special handling for Modified Apache 2.0 License Prefers Apache-2.0 over Pixar when Dice-S\u00f8rensen scores are within 1% Fixes issue #16 where Apache-2.0 was incorrectly detected as Pixar Handles gradle-wrapper.jar Apache license variant correctly Fixed TLSH Hash Collision : Resolved Apache-2.0 being misidentified as Pixar license TLSH hashes were too similar (distance 8-24) Now handled by preferring base license over modified versions Exact hash matching bypasses fuzzy matching issues License Loading : Fixed get_all_license_ids() to properly handle dictionary format [1.3.5] - 2025-09-03 Added Expanded License File Detection : Added comprehensive license file patterns GPL variants ( *GPL* ) Copyleft files ( *COPYLEFT* ) EULA files ( *EULA* ) Commercial license files ( *COMMERCIAL* ) Agreement files ( *AGREEMENT* ) Bundle license files ( *BUNDLE* ) Third-party license files ( *THIRD-PARTY* , *THIRD_PARTY* ) Legal documents ( LEGAL* ) Improved License Detection Coverage : Extended fallback keyword detection to include: gpl, copyleft, eula, commercial, agreement, bundle, third-party, third_party Pattern Flexibility : All patterns now support characters before/after keywords (., -, _, etc.) [1.3.4] - 2025-09-02 Added Enhanced Archive Support : Added support for additional archive formats: Java archives (.jar, .war, .ear) .NET packages (.nupkg) Ruby gems (.gem) with nested archive extraction Rust crates (.crate) Improved Copyright Detection Completeness : Removed artificial 20-file limit for source file scanning Now scans ALL source files (.c, .h, .py, .js, .java, .cpp, .go, .rs, .ts, .tsx, .jsx) Improves detection from ~12 to 700+ copyright statements on large codebases Maintains 94% accuracy with comprehensive false positive filtering File Scanner Reliability : Fixed SafeFileScanner visited_inodes persistence bug Eliminates false \"symlink loop\" warnings on subsequent scans Enables proper scanning of multiple file extensions Fixed Single File Detection : Enhanced handling of directly-passed files as potential license content MIT License Detection : Improved regex patterns for partial MIT license text recognition Archive Extraction : Better support for nested archive formats and Ruby gem structure Repository Cleanup : Removed test-packages/ directory and added to .gitignore to keep repository clean [1.3.3] - 2025-08-30 Improved Confidence Scoring : Enhanced regex-based license detection with context-aware confidence scoring License files: 100% confidence for exact matches Full license headers in source files: 90% confidence License references: 30-50% confidence based on pattern matches Better distinction between comprehensive headers vs. brief references Categorization Logic : Improved license categorization to distinguish between full license headers and simple references Pattern Matching : Enhanced regex detection to track exact number of patterns matched for more accurate confidence scoring Technical Changes Added _adjust_regex_confidence method for intelligent confidence adjustment Enhanced pattern matching to differentiate license headers from references Improved license categorization logic for better accuracy assessment [1.3.2] - 2025-08-30 Fixed CLI Options : Fixed decorator ordering to enable -f output format option Documentation : Updated README with complete feature list and examples Changed Version Option : Moved to proper position in CLI decorator chain [1.3.1] - 2025-08-30 Added Archive Extraction : Restored archive extraction capability with configurable --max-extraction-depth option for nested archives Cache Functionality : Added caching support with --cache-dir option to speed up repeated scans Version Command : Added --version option to display the tool version Output Formats : Restored support for multiple output formats: kissbom : Simple JSON format with packages and licenses cyclonedx-json : CycloneDX SBOM in JSON format cyclonedx-xml : CycloneDX SBOM in XML format notices : Human-readable legal notices with license texts Changed Directory Traversal : Restored --max-depth option with enhanced symlink loop protection using inode tracking Safe File Scanner : Implemented SafeFileScanner class for secure directory traversal with depth limiting Fixed Missing Features : Restored several features that were accidentally removed in previous refactoring Documentation : Updated all documentation to reflect current functionality Code Quality : Removed unused get_license_aliases method and other dead code [1.2.9] - 2025-08-30 Added License Hierarchy System : Categorizes licenses as 'declared', 'detected', or 'referenced' for better understanding of license provenance Enhanced Output Format : Summary now shows declared_licenses, detected_licenses, and referenced_licenses separately Copyright Holders List : Summary includes unique list of copyright holders Match Type Field : Each license detection includes match_type (e.g., license_file, spdx_identifier, text_similarity) Changed Class Renamed : Main class renamed from LegalAttributionGenerator to LicenseCopyrightDetector to better reflect its functionality (BREAKING CHANGE) Model Renamed : AttributionResult renamed to DetectionResult to better reflect its purpose (BREAKING CHANGE) Fixed Copyright False Positives : Improved filtering to exclude placeholders like \"YYYY Name\", \"TODO\", and code fragments Invalid Copyright Holders : Added detection for fragments like \"in result\", \"lines that vary\", \"detector\", \"generator\" Placeholder Detection : Better filtering of template placeholders in copyright statements Removed Dead Code : Removed unused max_extraction_depth configuration option Unused Import : Removed unused fuzz_process import from license_detector.py Misleading Function Name : Renamed _process_extracted_package() to _process_local_path() Test Files : Removed development test files from repository Build Directory : Cleaned up build artifacts Duplicate Method : Consolidated duplicate _is_license_file implementations [1.2.8] - 2025-08-29 Fixed License Expression Parsing : Fixed incorrect splitting of \"or later\" suffix (e.g., \"LGPL 3 or later\" now correctly parsed as single license) False Positive Detection : Added filtering for TODO, FIXME, XXX, and placeholder text that were incorrectly detected as licenses MIT License Detection : Added quick pattern matching for MIT licenses before TLSH to prevent misidentification as JSON Test File Scanning : Fixed overly aggressive filtering that skipped all files with \"test_\" prefix, now only skips specific test patterns Improved Detection Accuracy : Significantly reduced false positives in license identification Expression Handling : Better handling of license suffixes like \"or later\", \"or-later\", \"+\" [1.2.7] - 2025-08-29 Added Dynamic License Normalization : Uses 1841+ name mappings from bundled SPDX data instead of hardcoding Properties for SPDX Data : Added aliases and name_mappings properties to SPDXLicenseData class Comprehensive Normalization : Support for 99.1% of SPDX licenses (694/700) with intelligent normalization Better Version Handling : GPL/LGPL/AGPL versions properly normalized (e.g., GPL-3 \u2192 GPL-3.0) Common Aliases : Added fallback aliases for \"New BSD\", \"Simplified BSD\", \"CC0\", etc. Changed SPDX Tag Detection : Improved regex to capture multi-word licenses like \"Apache 2.0\", \"GPL v3\" Normalization Method : Refactored to use data-driven approach with bundled mappings Import Organization : Moved module-level imports to avoid inline imports Fixed Duplicate Methods : Removed duplicate _normalize_text() and get_all_license_ids() methods in spdx_licenses.py Dead Code : Removed unused methods and unreachable code sections Import Issues : Fixed repeated inline imports of re module License Detection : Fixed normalization for licenses with spaces (e.g., \"Apache 2.0\" \u2192 \"Apache-2.0\") Suffix Handling : Proper handling of deprecated + suffix licenses (GPL-3.0+ \u2192 GPL-3.0-or-later) Performance Code Quality : Reduced duplication and improved maintainability Normalization Coverage : Increased from ~12% to 99.1% for SPDX license ID variations [1.2.6] - 2025-08-17 Changed Project Description : Updated to \"Semantic Copycat Open Source License Identification Library\" [1.2.5] - 2025-08-17 Added TLSH Confirmation Mechanism : Dice-S\u00f8rensen matches are now confirmed with TLSH to prevent false positives Required TLSH Dependency : python-tlsh>=4.5.0 is now a required dependency (was optional) Enhanced Documentation : Comprehensive explanation of three-tier detection system in README and docs TLSH Confirmation Method : New confirm_license_match() method with configurable threshold Changed TLSH Thresholds : Strict threshold (30) for standalone detection, relaxed (100) for confirmation Detection Flow : Tier 1 now includes TLSH confirmation for all Dice-S\u00f8rensen matches Documentation : Updated README with detailed \"How It Works\" section Project Status : Updated CLAUDE.md to reflect v1.2.5 improvements Fixed False Positive Prevention : TLSH confirmation significantly reduces false positives Code Cleanup : Removed 8 unused utility methods from ConfigLoader and InputProcessor Performance Testing Coverage : Validated on 10+ language ecosystems with 97-100% accuracy Detection Accuracy : Maintained 97%+ accuracy while reducing false positives [1.2.0] - 2025-08-16 Added Parallel Processing : Multi-threaded scanning with ThreadPoolExecutor for significantly faster performance Enhanced License Detection : Improved regex patterns for package metadata (package.json, METADATA, pyproject.toml) Smart File Handling : Intelligent sampling for large files (>10MB) without timeouts Complete File Coverage : Scans ALL readable text files, not limited to specific extensions 700+ SPDX Support : Full support for all SPDX license IDs with alias normalization Text Normalization : Added _normalize_text() method for consistent license comparison Configurable Threading : CLI option --threads to control parallel processing (default: 4) Better Metadata Detection : Detects \"license\": \"MIT\" in package.json Detects License-Expression: MIT in Python METADATA files Detects license = {text = \"Apache-2.0\"} in pyproject.toml Changed File Processing : Now uses parallel processing for license and copyright detection File Reading : Smart reading strategy - full read for <10MB, sampling for larger files Error Handling : Improved with specific exception types and per-file timeouts (30s) License Matching : Enhanced normalization handles more variations (Apache 2.0 \u2192 Apache-2.0) False Positive Filtering : Better detection and filtering of code patterns in both license and copyright extraction Fixed Removed duplicate _normalize_license_id() method Removed unused imports ( time , redundant fnmatch ) Fixed bare except: clauses with specific exception types Removed redundant hasattr() checks Improved copyright holder validation to filter more false positives Performance Improvements Parallel file processing reduces scan time by up to 75% on multi-core systems Smart file sampling for large files prevents memory issues Deduplication during processing reduces post-processing time Lazy loading of SPDX data improves startup time [1.1.2] - 2025-01-16 Breaking Changes Removed package URL (purl) support : Tool no longer downloads or processes packages from PyPI, npm, etc. Removed external API integrations : ClearlyDefined, PyPI, and npm APIs have been removed Focus on local scanning only : Tool now exclusively scans local directories and files Changed Core functionality : Refocused on local source code license and copyright identification Input handling : Now only accepts local file paths and directories Attribution format : Changed from purl-based to path-based attribution Dependencies : Removed packageurl-python dependency Removed Package downloading and extraction capabilities Purl file parsing functionality External API data sources (ClearlyDefined, PyPI, npm) Network timeout configuration Online/offline mode distinction (tool is always offline) What the Tool Now Does Scans local source code for SPDX license identification Extracts copyright information from local files Identifies license files and matches them with bundled SPDX data Uses multi-tier detection: Dice-S\u00f8rensen similarity, TLSH fuzzy hashing, and regex patterns Generates attribution reports in KissBOM, CycloneDX, and human-readable formats [1.1.1] - 2025-01-16 Added Offline-first operation : Tool now works offline by default, no API calls unless explicitly requested --online flag : New CLI option to enable external API sources (ClearlyDefined, PyPI, npm) Bundled SPDX license data : Package includes 700+ SPDX license definitions with full text for 40+ common licenses License text in notices : Human-readable notices now include full license text Debug logging : Added comprehensive debug logging for troubleshooting copyright extraction Copyright validation : Improved filtering of invalid copyright patterns (URLs, code snippets, etc.) Build automation : Scripts to update SPDX license data during package build Changed Default behavior : Changed from online-first to offline-first operation API usage : External APIs now supplement rather than replace local analysis Copyright extraction : Significantly improved accuracy with better pattern matching and deduplication Logging : Reduced verbosity in normal mode, cleaner output Fixed Copyright false positives : Fixed extraction of code patterns as copyright holders Duplicate copyrights : Improved deduplication of copyright holders with variations Invalid domains : Fixed \"domain.invalid\" and URL patterns appearing in copyright SSL warnings : Suppressed urllib3 SSL warnings on macOS systems Package build : Fixed missing submodules in wheel distribution Technical Improvements Performance : Faster processing without network calls in default mode Reliability : Works without internet connection Privacy : No data sent to external services by default Size : Package includes all necessary data (1.5MB of SPDX licenses) [0.1.0] - 2025-01-15 Initial Release Multi-source input : Process single purls, purl files, or local directories Three-tier license detection : Tier 1: Dice-S\u00f8rensen similarity (97% threshold) Tier 2: TLSH fuzzy hashing Tier 3: Regex pattern matching Copyright extraction : Pattern-based extraction from source files Multiple output formats : KissBOM, CycloneDX, human-readable notices External data sources : Integration with ClearlyDefined, PyPI, npm APIs CLI and library interfaces : Use as command-line tool or Python library Multi-threaded processing : Configurable parallel processing Configuration system : YAML-based configuration with environment variables Package Metadata Author: Oscar Valenzuela B. Email: oscar.valenzuela.b@gmail.com License: Apache-2.0 Repository: https://github.com/oscarvalenzuelab/semantic-copycat-oslili","title":"Changelog"},{"location":"osslili/CHANGELOG/#changelog","text":"All notable changes to osslili will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"osslili/CHANGELOG/#unreleased","text":"","title":"[Unreleased]"},{"location":"osslili/CHANGELOG/#157-2025-10-30","text":"","title":"[1.5.7] - 2025-10-30"},{"location":"osslili/CHANGELOG/#changed","text":"Performance Optimization : Updated default values for better performance Reduced default max recursion depth from 10 to 4 for faster directory scans Set explicit thread count default to 4 in CLI (previously inherited from Config) Aligned CLI and Config model defaults for consistency","title":"Changed"},{"location":"osslili/CHANGELOG/#technical","text":"CLI Defaults : Added explicit default values in CLI options for better visibility Configuration : Synchronized default values between CLI and Config model","title":"Technical"},{"location":"osslili/CHANGELOG/#156-2025-10-27","text":"","title":"[1.5.6] - 2025-10-27"},{"location":"osslili/CHANGELOG/#changed_1","text":"Project Rename : Renamed project from semantic-copycat-oslili to osslili Updated package name and imports throughout codebase Changed CLI command from oslili to osslili Updated repository URL to https://github.com/SemClone/osslili Renamed main Python package directory from semantic_copycat_oslili to osslili Updated all documentation, configuration files, and scripts Simplified project description to \"Open Source License Identification Library\"","title":"Changed"},{"location":"osslili/CHANGELOG/#technical_1","text":"Package Structure : Completely reorganized package structure for the new name Import Compatibility : All import statements updated to use new package name Documentation : Updated all references across README, docs, and examples","title":"Technical"},{"location":"osslili/CHANGELOG/#155-2025-10-24","text":"","title":"[1.5.5] - 2025-10-24"},{"location":"osslili/CHANGELOG/#fixed","text":"False Positive Copyright Detection : Eliminated false positive copyright holder detections Fixed overly broad regex patterns that captured programming language constructs Added filtering for Fortran data types (integer*1, character) being detected as copyright holders Enhanced filtering for Python code fragments (is not None, or sig_pattern, is np, is not np) Improved regex patterns to stop at programming keywords (is, or, and) Added exact match filtering for known false positive patterns Better handling of contributor phrases like \"and individual contributors\"","title":"Fixed"},{"location":"osslili/CHANGELOG/#improved","text":"Copyright Extraction Accuracy : More precise copyright holder identification with significantly fewer false positives Code Pattern Detection : Enhanced recognition of programming language constructs to prevent them from being interpreted as copyright information","title":"Improved"},{"location":"osslili/CHANGELOG/#154-2025-10-24","text":"","title":"[1.5.4] - 2025-10-24"},{"location":"osslili/CHANGELOG/#fixed_1","text":"False Positive License Detection : Significantly reduced false positive license detections Fixed overly broad keyword patterns for Python-2.0, ISC, and Perl licenses Enhanced context validation to require license-specific contexts for matches Added filtering for generic programming language names being detected as licenses Improved ISC license pattern specificity to require actual ISC license text Strengthened validation to prevent common programming terms from being flagged as licenses","title":"Fixed"},{"location":"osslili/CHANGELOG/#improved_1","text":"License Detection Accuracy : More precise detection with fewer false positives while maintaining legitimate detection coverage Context Checking : Enhanced validation that license keywords appear in actual license contexts rather than general code comments","title":"Improved"},{"location":"osslili/CHANGELOG/#153-2025-10-21","text":"","title":"[1.5.3] - 2025-10-21"},{"location":"osslili/CHANGELOG/#added","text":"Evidence Detail Levels : New --evidence-detail CLI option with 4 levels for controlling output verbosity minimal : Just license counts (compact 1KB output) summary : Adds detection method breakdown (1KB output) detailed : Includes sample evidence (72KB output) - default full : Complete evidence (several MB output) License Normalizer Utility : New utility class for consistent license ID normalization Regex Pattern Matcher : Optimized regex matching with lookup tables for better performance","title":"Added"},{"location":"osslili/CHANGELOG/#fixed_2","text":"Critical Deduplication Bug : Fixed license detection deduplication that was discarding 99% of detections Changed deduplication key from (license_id, confidence) to (license_id, confidence, source_file) Increases detection coverage from ~1% to 99%+ of expected files File Readability Detection : Enhanced detection for better source file coverage Added more permissive encoding detection (UTF-8, Latin-1, cp1252, ISO-8859-1) Improved binary file detection with magic number signatures Better handling of files with mixed encodings","title":"Fixed"},{"location":"osslili/CHANGELOG/#improved_2","text":"License Detection Coverage : Reduced false negatives while maintaining low false positive rate Reduced license text indicator threshold from 3 to 1 for better coverage Added validation filtering to reduce false positives Enhanced match type categorization (license_file, spdx_identifier, package_metadata, etc.) Performance Optimizations : Maintained ~117 files/second processing speed Memory-efficient streaming processing for large files Optimized regex pattern matching with lookup tables Parallel processing improvements","title":"Improved"},{"location":"osslili/CHANGELOG/#changed_2","text":"Evidence Formatter : Enhanced with detail level filtering and better match type descriptions License Detector : Improved categorization logic and false positive filtering","title":"Changed"},{"location":"osslili/CHANGELOG/#151-2025-10-17","text":"","title":"[1.5.1] - 2025-10-17"},{"location":"osslili/CHANGELOG/#fixed_3","text":"Copyright Detection : Fixed overly aggressive filtering of copyright holders (issue #32) Copyright holders containing words like \"Test\", \"Demo\", etc. are now correctly detected when part of legitimate names \"Test Corporation\", \"TestCo Inc\", and similar names are now properly recognized Only standalone test/demo placeholders are filtered out (e.g., just \"test\" or \"demo\") Maintains filtering of actual placeholder text while allowing real organizations with these words","title":"Fixed"},{"location":"osslili/CHANGELOG/#150-2025-10-15","text":"","title":"[1.5.0] - 2025-10-15"},{"location":"osslili/CHANGELOG/#added_1","text":"Enhanced License Detection Accuracy : Significantly improved license detection with multi-pattern support (PR #30, issue #29) Multi-line pattern detection for licenses split across lines Fuzzy matching for common typos (e.g., \"Lisense\" to \"License\") Version suffix handling (GPLv2+ to GPL-2.0-or-later) License keyword detection with 47 comprehensive patterns Support for detecting licenses in all file types Comprehensive Benchmark : Added detailed comparison with ScanCode Toolkit Performance comparison showing 1.8x-30x faster execution Detection accuracy analysis with feature comparison matrix Use case recommendations for both tools","title":"Added"},{"location":"osslili/CHANGELOG/#improved_3","text":"4-Tier License Detection : All detection methods now engage for maximum accuracy Hash matching for exact license files Dice-S\u00f8rensen similarity for text similarity TLSH fuzzy hashing for variant detection Enhanced regex patterns for edge cases Edge Case Handling : Fixed detection for numerous previously failing cases Python Software Foundation License full phrase GNU Lesser General Public License v2.1 Generic GPL references with context-aware version detection MIT licenses in copyright lines Apache License with newlines in header Pattern Library : Integrated patterns from scancode-licensedb Added 47+ license patterns for comprehensive coverage Improved detection for permissive, copyleft, and proprietary licenses Better handling of license variations and aliases","title":"Improved"},{"location":"osslili/CHANGELOG/#fixed_4","text":"License Normalization : Improved SPDX ID normalization GNU-GPL-v2 to GPL-2.0 GPLv2+ to GPL-2.0-or-later Better handling of version suffixes and variations False Negative Reduction : Reduced false negative rate from 46.7% to near 0% Previously undetected licenses now properly identified Improved coverage across different file types and formats","title":"Fixed"},{"location":"osslili/CHANGELOG/#performance","text":"Copyright Extraction : 26x more comprehensive than comparable tools Speed : Maintained 1.8x-30x faster performance while improving accuracy Scalability : Successfully tested on large codebases (FFmpeg-8.0)","title":"Performance"},{"location":"osslili/CHANGELOG/#141-2025-10-12","text":"","title":"[1.4.1] - 2025-10-12"},{"location":"osslili/CHANGELOG/#fixed_5","text":"pyproject.toml PEP 639 File Reference : Fixed license detection from license = {file = \"LICENSE\"} format Changed from non-existent _detect_license_from_text() to proper _detect_from_full_text() method Now correctly reads and detects licenses from referenced files in pyproject.toml Properly sets category as DECLARED for licenses from metadata file references Added debug logging when referenced license file doesn't exist","title":"Fixed"},{"location":"osslili/CHANGELOG/#removed","text":"Notices Output Format : Removed human-readable notices format to focus on scanning and verification Removed notices_formatter.py module Removed generate_notices() method from LicenseCopyrightDetector Removed notices option from CLI output formats Updated documentation to remove references to notices format This simplifies the codebase and clarifies the tool's primary purpose as a scanner/verifier","title":"Removed"},{"location":"osslili/CHANGELOG/#140-2025-10-12","text":"","title":"[1.4.0] - 2025-10-12"},{"location":"osslili/CHANGELOG/#added_2","text":"Source Header License Detection in Metadata Files : Extract SPDX tags and license references from comments/headers Detects licenses in XML comments (pom.xml) Detects licenses in Python comments (setup.py, setup.cfg) Detects licenses in TOML comments (Cargo.toml) Detects licenses in Ruby comments (*.gemspec) New _extract_header_licenses() method for comprehensive header scanning Enhanced Package Metadata Support : Added extraction methods for additional formats Full support for package.json (Node.js) with SPDX expressions and arrays Full support for composer.json (PHP) with comment cleaning Improved extraction from all major package formats Fast-path Metadata API : New extract_package_metadata() method for metadata-only extraction Skips full text analysis for faster processing Supports all major package metadata formats Returns licenses from both structured metadata and source headers","title":"Added"},{"location":"osslili/CHANGELOG/#improved_4","text":"Intelligent License Deduplication : Smart handling when same license found in multiple locations Prefers metadata version over header version as more authoritative Prevents duplicate licenses in results Tracks licenses by (spdx_id, match_type) for accurate deduplication Python Classifier Extraction : Fixed to handle both quoted and unquoted formats Works with setup.py quoted classifiers Works with setup.cfg unquoted classifiers Properly extracts OSI Approved licenses from trove classifiers File Pattern Matching : Enhanced to handle temporary files and various naming conventions Supports files ending with metadata names (e.g., temp_xyz.package.json) Better handling of edge cases in file detection Gemspec and Cargo.toml Processing : Added duplicate prevention Tracks found licenses to avoid duplicates Handles both single and array license declarations","title":"Improved"},{"location":"osslili/CHANGELOG/#fixed_6","text":"Duplicate License Detection : Resolved issues with licenses appearing multiple times Fixed gemspec pattern matching causing duplicates Fixed Cargo.toml SPDX expression parsing duplicates Improved overall deduplication logic","title":"Fixed"},{"location":"osslili/CHANGELOG/#136-2025-09-06","text":"","title":"[1.3.6] - 2025-09-06"},{"location":"osslili/CHANGELOG/#added_3","text":"Tier 0 Exact Hash Matching : Added SHA-256 and MD5 hash matching as the first detection tier Pre-computed hashes for all 699 SPDX licenses Support for license variants and aliases 100% confidence for exact matches New DetectionMethod.HASH enum value Hash Inventory System : Comprehensive hash inventory for license matching Standard SPDX license hashes Common variants (e.g., gradle-wrapper Apache-2.0) Hash lookup tables for fast matching Support for hash collisions (e.g., GPL versions)","title":"Added"},{"location":"osslili/CHANGELOG/#improved_5","text":"Detection Tier Reorganization : Four-tier system: Hash \u2192 Dice-S\u00f8rensen \u2192 TLSH \u2192 Regex Exact hash matching runs first for perfect matches Dice-S\u00f8rensen no longer requires TLSH confirmation for >95% confidence Better performance and accuracy Apache-2.0 vs Pixar Disambiguation : Special handling for Modified Apache 2.0 License Prefers Apache-2.0 over Pixar when Dice-S\u00f8rensen scores are within 1% Fixes issue #16 where Apache-2.0 was incorrectly detected as Pixar Handles gradle-wrapper.jar Apache license variant correctly","title":"Improved"},{"location":"osslili/CHANGELOG/#fixed_7","text":"TLSH Hash Collision : Resolved Apache-2.0 being misidentified as Pixar license TLSH hashes were too similar (distance 8-24) Now handled by preferring base license over modified versions Exact hash matching bypasses fuzzy matching issues License Loading : Fixed get_all_license_ids() to properly handle dictionary format","title":"Fixed"},{"location":"osslili/CHANGELOG/#135-2025-09-03","text":"","title":"[1.3.5] - 2025-09-03"},{"location":"osslili/CHANGELOG/#added_4","text":"Expanded License File Detection : Added comprehensive license file patterns GPL variants ( *GPL* ) Copyleft files ( *COPYLEFT* ) EULA files ( *EULA* ) Commercial license files ( *COMMERCIAL* ) Agreement files ( *AGREEMENT* ) Bundle license files ( *BUNDLE* ) Third-party license files ( *THIRD-PARTY* , *THIRD_PARTY* ) Legal documents ( LEGAL* )","title":"Added"},{"location":"osslili/CHANGELOG/#improved_6","text":"License Detection Coverage : Extended fallback keyword detection to include: gpl, copyleft, eula, commercial, agreement, bundle, third-party, third_party Pattern Flexibility : All patterns now support characters before/after keywords (., -, _, etc.)","title":"Improved"},{"location":"osslili/CHANGELOG/#134-2025-09-02","text":"","title":"[1.3.4] - 2025-09-02"},{"location":"osslili/CHANGELOG/#added_5","text":"Enhanced Archive Support : Added support for additional archive formats: Java archives (.jar, .war, .ear) .NET packages (.nupkg) Ruby gems (.gem) with nested archive extraction Rust crates (.crate)","title":"Added"},{"location":"osslili/CHANGELOG/#improved_7","text":"Copyright Detection Completeness : Removed artificial 20-file limit for source file scanning Now scans ALL source files (.c, .h, .py, .js, .java, .cpp, .go, .rs, .ts, .tsx, .jsx) Improves detection from ~12 to 700+ copyright statements on large codebases Maintains 94% accuracy with comprehensive false positive filtering File Scanner Reliability : Fixed SafeFileScanner visited_inodes persistence bug Eliminates false \"symlink loop\" warnings on subsequent scans Enables proper scanning of multiple file extensions","title":"Improved"},{"location":"osslili/CHANGELOG/#fixed_8","text":"Single File Detection : Enhanced handling of directly-passed files as potential license content MIT License Detection : Improved regex patterns for partial MIT license text recognition Archive Extraction : Better support for nested archive formats and Ruby gem structure","title":"Fixed"},{"location":"osslili/CHANGELOG/#repository","text":"Cleanup : Removed test-packages/ directory and added to .gitignore to keep repository clean","title":"Repository"},{"location":"osslili/CHANGELOG/#133-2025-08-30","text":"","title":"[1.3.3] - 2025-08-30"},{"location":"osslili/CHANGELOG/#improved_8","text":"Confidence Scoring : Enhanced regex-based license detection with context-aware confidence scoring License files: 100% confidence for exact matches Full license headers in source files: 90% confidence License references: 30-50% confidence based on pattern matches Better distinction between comprehensive headers vs. brief references Categorization Logic : Improved license categorization to distinguish between full license headers and simple references Pattern Matching : Enhanced regex detection to track exact number of patterns matched for more accurate confidence scoring","title":"Improved"},{"location":"osslili/CHANGELOG/#technical-changes","text":"Added _adjust_regex_confidence method for intelligent confidence adjustment Enhanced pattern matching to differentiate license headers from references Improved license categorization logic for better accuracy assessment","title":"Technical Changes"},{"location":"osslili/CHANGELOG/#132-2025-08-30","text":"","title":"[1.3.2] - 2025-08-30"},{"location":"osslili/CHANGELOG/#fixed_9","text":"CLI Options : Fixed decorator ordering to enable -f output format option Documentation : Updated README with complete feature list and examples","title":"Fixed"},{"location":"osslili/CHANGELOG/#changed_3","text":"Version Option : Moved to proper position in CLI decorator chain","title":"Changed"},{"location":"osslili/CHANGELOG/#131-2025-08-30","text":"","title":"[1.3.1] - 2025-08-30"},{"location":"osslili/CHANGELOG/#added_6","text":"Archive Extraction : Restored archive extraction capability with configurable --max-extraction-depth option for nested archives Cache Functionality : Added caching support with --cache-dir option to speed up repeated scans Version Command : Added --version option to display the tool version Output Formats : Restored support for multiple output formats: kissbom : Simple JSON format with packages and licenses cyclonedx-json : CycloneDX SBOM in JSON format cyclonedx-xml : CycloneDX SBOM in XML format notices : Human-readable legal notices with license texts","title":"Added"},{"location":"osslili/CHANGELOG/#changed_4","text":"Directory Traversal : Restored --max-depth option with enhanced symlink loop protection using inode tracking Safe File Scanner : Implemented SafeFileScanner class for secure directory traversal with depth limiting","title":"Changed"},{"location":"osslili/CHANGELOG/#fixed_10","text":"Missing Features : Restored several features that were accidentally removed in previous refactoring Documentation : Updated all documentation to reflect current functionality Code Quality : Removed unused get_license_aliases method and other dead code","title":"Fixed"},{"location":"osslili/CHANGELOG/#129-2025-08-30","text":"","title":"[1.2.9] - 2025-08-30"},{"location":"osslili/CHANGELOG/#added_7","text":"License Hierarchy System : Categorizes licenses as 'declared', 'detected', or 'referenced' for better understanding of license provenance Enhanced Output Format : Summary now shows declared_licenses, detected_licenses, and referenced_licenses separately Copyright Holders List : Summary includes unique list of copyright holders Match Type Field : Each license detection includes match_type (e.g., license_file, spdx_identifier, text_similarity)","title":"Added"},{"location":"osslili/CHANGELOG/#changed_5","text":"Class Renamed : Main class renamed from LegalAttributionGenerator to LicenseCopyrightDetector to better reflect its functionality (BREAKING CHANGE) Model Renamed : AttributionResult renamed to DetectionResult to better reflect its purpose (BREAKING CHANGE)","title":"Changed"},{"location":"osslili/CHANGELOG/#fixed_11","text":"Copyright False Positives : Improved filtering to exclude placeholders like \"YYYY Name\", \"TODO\", and code fragments Invalid Copyright Holders : Added detection for fragments like \"in result\", \"lines that vary\", \"detector\", \"generator\" Placeholder Detection : Better filtering of template placeholders in copyright statements","title":"Fixed"},{"location":"osslili/CHANGELOG/#removed_1","text":"Dead Code : Removed unused max_extraction_depth configuration option Unused Import : Removed unused fuzz_process import from license_detector.py Misleading Function Name : Renamed _process_extracted_package() to _process_local_path() Test Files : Removed development test files from repository Build Directory : Cleaned up build artifacts Duplicate Method : Consolidated duplicate _is_license_file implementations","title":"Removed"},{"location":"osslili/CHANGELOG/#128-2025-08-29","text":"","title":"[1.2.8] - 2025-08-29"},{"location":"osslili/CHANGELOG/#fixed_12","text":"License Expression Parsing : Fixed incorrect splitting of \"or later\" suffix (e.g., \"LGPL 3 or later\" now correctly parsed as single license) False Positive Detection : Added filtering for TODO, FIXME, XXX, and placeholder text that were incorrectly detected as licenses MIT License Detection : Added quick pattern matching for MIT licenses before TLSH to prevent misidentification as JSON Test File Scanning : Fixed overly aggressive filtering that skipped all files with \"test_\" prefix, now only skips specific test patterns","title":"Fixed"},{"location":"osslili/CHANGELOG/#improved_9","text":"Detection Accuracy : Significantly reduced false positives in license identification Expression Handling : Better handling of license suffixes like \"or later\", \"or-later\", \"+\"","title":"Improved"},{"location":"osslili/CHANGELOG/#127-2025-08-29","text":"","title":"[1.2.7] - 2025-08-29"},{"location":"osslili/CHANGELOG/#added_8","text":"Dynamic License Normalization : Uses 1841+ name mappings from bundled SPDX data instead of hardcoding Properties for SPDX Data : Added aliases and name_mappings properties to SPDXLicenseData class Comprehensive Normalization : Support for 99.1% of SPDX licenses (694/700) with intelligent normalization Better Version Handling : GPL/LGPL/AGPL versions properly normalized (e.g., GPL-3 \u2192 GPL-3.0) Common Aliases : Added fallback aliases for \"New BSD\", \"Simplified BSD\", \"CC0\", etc.","title":"Added"},{"location":"osslili/CHANGELOG/#changed_6","text":"SPDX Tag Detection : Improved regex to capture multi-word licenses like \"Apache 2.0\", \"GPL v3\" Normalization Method : Refactored to use data-driven approach with bundled mappings Import Organization : Moved module-level imports to avoid inline imports","title":"Changed"},{"location":"osslili/CHANGELOG/#fixed_13","text":"Duplicate Methods : Removed duplicate _normalize_text() and get_all_license_ids() methods in spdx_licenses.py Dead Code : Removed unused methods and unreachable code sections Import Issues : Fixed repeated inline imports of re module License Detection : Fixed normalization for licenses with spaces (e.g., \"Apache 2.0\" \u2192 \"Apache-2.0\") Suffix Handling : Proper handling of deprecated + suffix licenses (GPL-3.0+ \u2192 GPL-3.0-or-later)","title":"Fixed"},{"location":"osslili/CHANGELOG/#performance_1","text":"Code Quality : Reduced duplication and improved maintainability Normalization Coverage : Increased from ~12% to 99.1% for SPDX license ID variations","title":"Performance"},{"location":"osslili/CHANGELOG/#126-2025-08-17","text":"","title":"[1.2.6] - 2025-08-17"},{"location":"osslili/CHANGELOG/#changed_7","text":"Project Description : Updated to \"Semantic Copycat Open Source License Identification Library\"","title":"Changed"},{"location":"osslili/CHANGELOG/#125-2025-08-17","text":"","title":"[1.2.5] - 2025-08-17"},{"location":"osslili/CHANGELOG/#added_9","text":"TLSH Confirmation Mechanism : Dice-S\u00f8rensen matches are now confirmed with TLSH to prevent false positives Required TLSH Dependency : python-tlsh>=4.5.0 is now a required dependency (was optional) Enhanced Documentation : Comprehensive explanation of three-tier detection system in README and docs TLSH Confirmation Method : New confirm_license_match() method with configurable threshold","title":"Added"},{"location":"osslili/CHANGELOG/#changed_8","text":"TLSH Thresholds : Strict threshold (30) for standalone detection, relaxed (100) for confirmation Detection Flow : Tier 1 now includes TLSH confirmation for all Dice-S\u00f8rensen matches Documentation : Updated README with detailed \"How It Works\" section Project Status : Updated CLAUDE.md to reflect v1.2.5 improvements","title":"Changed"},{"location":"osslili/CHANGELOG/#fixed_14","text":"False Positive Prevention : TLSH confirmation significantly reduces false positives Code Cleanup : Removed 8 unused utility methods from ConfigLoader and InputProcessor","title":"Fixed"},{"location":"osslili/CHANGELOG/#performance_2","text":"Testing Coverage : Validated on 10+ language ecosystems with 97-100% accuracy Detection Accuracy : Maintained 97%+ accuracy while reducing false positives","title":"Performance"},{"location":"osslili/CHANGELOG/#120-2025-08-16","text":"","title":"[1.2.0] - 2025-08-16"},{"location":"osslili/CHANGELOG/#added_10","text":"Parallel Processing : Multi-threaded scanning with ThreadPoolExecutor for significantly faster performance Enhanced License Detection : Improved regex patterns for package metadata (package.json, METADATA, pyproject.toml) Smart File Handling : Intelligent sampling for large files (>10MB) without timeouts Complete File Coverage : Scans ALL readable text files, not limited to specific extensions 700+ SPDX Support : Full support for all SPDX license IDs with alias normalization Text Normalization : Added _normalize_text() method for consistent license comparison Configurable Threading : CLI option --threads to control parallel processing (default: 4) Better Metadata Detection : Detects \"license\": \"MIT\" in package.json Detects License-Expression: MIT in Python METADATA files Detects license = {text = \"Apache-2.0\"} in pyproject.toml","title":"Added"},{"location":"osslili/CHANGELOG/#changed_9","text":"File Processing : Now uses parallel processing for license and copyright detection File Reading : Smart reading strategy - full read for <10MB, sampling for larger files Error Handling : Improved with specific exception types and per-file timeouts (30s) License Matching : Enhanced normalization handles more variations (Apache 2.0 \u2192 Apache-2.0) False Positive Filtering : Better detection and filtering of code patterns in both license and copyright extraction","title":"Changed"},{"location":"osslili/CHANGELOG/#fixed_15","text":"Removed duplicate _normalize_license_id() method Removed unused imports ( time , redundant fnmatch ) Fixed bare except: clauses with specific exception types Removed redundant hasattr() checks Improved copyright holder validation to filter more false positives","title":"Fixed"},{"location":"osslili/CHANGELOG/#performance-improvements","text":"Parallel file processing reduces scan time by up to 75% on multi-core systems Smart file sampling for large files prevents memory issues Deduplication during processing reduces post-processing time Lazy loading of SPDX data improves startup time","title":"Performance Improvements"},{"location":"osslili/CHANGELOG/#112-2025-01-16","text":"","title":"[1.1.2] - 2025-01-16"},{"location":"osslili/CHANGELOG/#breaking-changes","text":"Removed package URL (purl) support : Tool no longer downloads or processes packages from PyPI, npm, etc. Removed external API integrations : ClearlyDefined, PyPI, and npm APIs have been removed Focus on local scanning only : Tool now exclusively scans local directories and files","title":"Breaking Changes"},{"location":"osslili/CHANGELOG/#changed_10","text":"Core functionality : Refocused on local source code license and copyright identification Input handling : Now only accepts local file paths and directories Attribution format : Changed from purl-based to path-based attribution Dependencies : Removed packageurl-python dependency","title":"Changed"},{"location":"osslili/CHANGELOG/#removed_2","text":"Package downloading and extraction capabilities Purl file parsing functionality External API data sources (ClearlyDefined, PyPI, npm) Network timeout configuration Online/offline mode distinction (tool is always offline)","title":"Removed"},{"location":"osslili/CHANGELOG/#what-the-tool-now-does","text":"Scans local source code for SPDX license identification Extracts copyright information from local files Identifies license files and matches them with bundled SPDX data Uses multi-tier detection: Dice-S\u00f8rensen similarity, TLSH fuzzy hashing, and regex patterns Generates attribution reports in KissBOM, CycloneDX, and human-readable formats","title":"What the Tool Now Does"},{"location":"osslili/CHANGELOG/#111-2025-01-16","text":"","title":"[1.1.1] - 2025-01-16"},{"location":"osslili/CHANGELOG/#added_11","text":"Offline-first operation : Tool now works offline by default, no API calls unless explicitly requested --online flag : New CLI option to enable external API sources (ClearlyDefined, PyPI, npm) Bundled SPDX license data : Package includes 700+ SPDX license definitions with full text for 40+ common licenses License text in notices : Human-readable notices now include full license text Debug logging : Added comprehensive debug logging for troubleshooting copyright extraction Copyright validation : Improved filtering of invalid copyright patterns (URLs, code snippets, etc.) Build automation : Scripts to update SPDX license data during package build","title":"Added"},{"location":"osslili/CHANGELOG/#changed_11","text":"Default behavior : Changed from online-first to offline-first operation API usage : External APIs now supplement rather than replace local analysis Copyright extraction : Significantly improved accuracy with better pattern matching and deduplication Logging : Reduced verbosity in normal mode, cleaner output","title":"Changed"},{"location":"osslili/CHANGELOG/#fixed_16","text":"Copyright false positives : Fixed extraction of code patterns as copyright holders Duplicate copyrights : Improved deduplication of copyright holders with variations Invalid domains : Fixed \"domain.invalid\" and URL patterns appearing in copyright SSL warnings : Suppressed urllib3 SSL warnings on macOS systems Package build : Fixed missing submodules in wheel distribution","title":"Fixed"},{"location":"osslili/CHANGELOG/#technical-improvements","text":"Performance : Faster processing without network calls in default mode Reliability : Works without internet connection Privacy : No data sent to external services by default Size : Package includes all necessary data (1.5MB of SPDX licenses)","title":"Technical Improvements"},{"location":"osslili/CHANGELOG/#010-2025-01-15","text":"","title":"[0.1.0] - 2025-01-15"},{"location":"osslili/CHANGELOG/#initial-release","text":"Multi-source input : Process single purls, purl files, or local directories Three-tier license detection : Tier 1: Dice-S\u00f8rensen similarity (97% threshold) Tier 2: TLSH fuzzy hashing Tier 3: Regex pattern matching Copyright extraction : Pattern-based extraction from source files Multiple output formats : KissBOM, CycloneDX, human-readable notices External data sources : Integration with ClearlyDefined, PyPI, npm APIs CLI and library interfaces : Use as command-line tool or Python library Multi-threaded processing : Configurable parallel processing Configuration system : YAML-based configuration with environment variables","title":"Initial Release"},{"location":"osslili/CHANGELOG/#package-metadata","text":"Author: Oscar Valenzuela B. Email: oscar.valenzuela.b@gmail.com License: Apache-2.0 Repository: https://github.com/oscarvalenzuelab/semantic-copycat-oslili","title":"Package Metadata"},{"location":"osslili/CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Contributor Covenant Code of Conduct"},{"location":"osslili/CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"osslili/CODE_OF_CONDUCT/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"osslili/CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"osslili/CODE_OF_CONDUCT/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"osslili/CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"osslili/CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"osslili/CODE_OF_CONDUCT/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"osslili/CODE_OF_CONDUCT/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"osslili/CODE_OF_CONDUCT/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"osslili/CODE_OF_CONDUCT/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"osslili/CODE_OF_CONDUCT/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"osslili/CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Attribution"},{"location":"osslili/CONTRIBUTING/","text":"Contributing to osslili First off, thank you for considering contributing to osslili! It's people like you that make osslili such a great tool. Code of Conduct This project and everyone participating in it is governed by the Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to conduct@semcl.one . How Can I Contribute? Reporting Bugs Before creating bug reports, please check existing issues as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one. How Do I Submit A Good Bug Report? Bugs are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem. If the problem wasn't triggered by a specific action , describe what you were doing before the problem happened and share more information using the guidelines below. Suggesting Enhancements Enhancement suggestions are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps . Include copy/pasteable snippets which you use in those examples. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users. List some other projects where this enhancement exists. Your First Code Contribution Unsure where to begin contributing? You can start by looking through these beginner and help-wanted issues: [Beginner issues][beginner] - issues which should only require a few lines of code, and a test or two. [Help wanted issues][help-wanted] - issues which should be a bit more involved than beginner issues. Pull Requests The process described here has several goals: Maintain code quality Fix problems that are important to users Engage the community in working toward the best possible product Enable a sustainable system for maintainers to review contributions Please follow these steps to have your contribution considered by the maintainers: Follow all instructions in the template Follow the styleguides After you submit your pull request, verify that all status checks are passing While the prerequisites above must be satisfied prior to having your pull request reviewed, the reviewer(s) may ask you to complete additional design work, tests, or other changes before your pull request can be ultimately accepted. Styleguides Git Commit Messages Use the present tense (\"Add feature\" not \"Added feature\") Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit the first line to 72 characters or less Reference issues and pull requests liberally after the first line When only changing documentation, include [ci skip] in the commit title Python Styleguide All Python code must adhere to PEP 8 . Use type hints where appropriate Include docstrings for all public functions, classes, and modules Prefer explicit over implicit Write tests for new functionality Documentation Styleguide Use Markdown . Reference functions and classes in backticks: `function_name()`. Include code examples where appropriate. Development Process Fork the repo and create your branch from main . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request! Development Setup # Clone your fork git clone https://github.com/your-username/osslili.git cd osslili # Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # Install dependencies pip install -e .[dev] # Run tests pytest # Run linting ruff check . black --check . Running Tests # Run all tests pytest # Run with coverage pytest --cov=osslili # Run specific test file pytest tests/test_specific.py Community You can chat with the community on: - GitHub Discussions - Issues Recognition Contributors who have made significant contributions will be recognized in our AUTHORS file. Thank you for contributing!","title":"Contributing to osslili"},{"location":"osslili/CONTRIBUTING/#contributing-to-osslili","text":"First off, thank you for considering contributing to osslili! It's people like you that make osslili such a great tool.","title":"Contributing to osslili"},{"location":"osslili/CONTRIBUTING/#code-of-conduct","text":"This project and everyone participating in it is governed by the Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to conduct@semcl.one .","title":"Code of Conduct"},{"location":"osslili/CONTRIBUTING/#how-can-i-contribute","text":"","title":"How Can I Contribute?"},{"location":"osslili/CONTRIBUTING/#reporting-bugs","text":"Before creating bug reports, please check existing issues as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one.","title":"Reporting Bugs"},{"location":"osslili/CONTRIBUTING/#how-do-i-submit-a-good-bug-report","text":"Bugs are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem. If the problem wasn't triggered by a specific action , describe what you were doing before the problem happened and share more information using the guidelines below.","title":"How Do I Submit A Good Bug Report?"},{"location":"osslili/CONTRIBUTING/#suggesting-enhancements","text":"Enhancement suggestions are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps . Include copy/pasteable snippets which you use in those examples. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users. List some other projects where this enhancement exists.","title":"Suggesting Enhancements"},{"location":"osslili/CONTRIBUTING/#your-first-code-contribution","text":"Unsure where to begin contributing? You can start by looking through these beginner and help-wanted issues: [Beginner issues][beginner] - issues which should only require a few lines of code, and a test or two. [Help wanted issues][help-wanted] - issues which should be a bit more involved than beginner issues.","title":"Your First Code Contribution"},{"location":"osslili/CONTRIBUTING/#pull-requests","text":"The process described here has several goals: Maintain code quality Fix problems that are important to users Engage the community in working toward the best possible product Enable a sustainable system for maintainers to review contributions Please follow these steps to have your contribution considered by the maintainers: Follow all instructions in the template Follow the styleguides After you submit your pull request, verify that all status checks are passing While the prerequisites above must be satisfied prior to having your pull request reviewed, the reviewer(s) may ask you to complete additional design work, tests, or other changes before your pull request can be ultimately accepted.","title":"Pull Requests"},{"location":"osslili/CONTRIBUTING/#styleguides","text":"","title":"Styleguides"},{"location":"osslili/CONTRIBUTING/#git-commit-messages","text":"Use the present tense (\"Add feature\" not \"Added feature\") Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit the first line to 72 characters or less Reference issues and pull requests liberally after the first line When only changing documentation, include [ci skip] in the commit title","title":"Git Commit Messages"},{"location":"osslili/CONTRIBUTING/#python-styleguide","text":"All Python code must adhere to PEP 8 . Use type hints where appropriate Include docstrings for all public functions, classes, and modules Prefer explicit over implicit Write tests for new functionality","title":"Python Styleguide"},{"location":"osslili/CONTRIBUTING/#documentation-styleguide","text":"Use Markdown . Reference functions and classes in backticks: `function_name()`. Include code examples where appropriate.","title":"Documentation Styleguide"},{"location":"osslili/CONTRIBUTING/#development-process","text":"Fork the repo and create your branch from main . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request!","title":"Development Process"},{"location":"osslili/CONTRIBUTING/#development-setup","text":"# Clone your fork git clone https://github.com/your-username/osslili.git cd osslili # Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # Install dependencies pip install -e .[dev] # Run tests pytest # Run linting ruff check . black --check .","title":"Development Setup"},{"location":"osslili/CONTRIBUTING/#running-tests","text":"# Run all tests pytest # Run with coverage pytest --cov=osslili # Run specific test file pytest tests/test_specific.py","title":"Running Tests"},{"location":"osslili/CONTRIBUTING/#community","text":"You can chat with the community on: - GitHub Discussions - Issues","title":"Community"},{"location":"osslili/CONTRIBUTING/#recognition","text":"Contributors who have made significant contributions will be recognized in our AUTHORS file. Thank you for contributing!","title":"Recognition"},{"location":"osslili/SECURITY/","text":"Security Policy Supported Versions We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release Reporting a Vulnerability Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. Preferred Languages We prefer all communications to be in English. Policy We follow the principle of Coordinated Vulnerability Disclosure.","title":"Security Policy"},{"location":"osslili/SECURITY/#security-policy","text":"","title":"Security Policy"},{"location":"osslili/SECURITY/#supported-versions","text":"We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release","title":"Supported Versions"},{"location":"osslili/SECURITY/#reporting-a-vulnerability","text":"Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly.","title":"Reporting a Vulnerability"},{"location":"osslili/SECURITY/#preferred-languages","text":"We prefer all communications to be in English.","title":"Preferred Languages"},{"location":"osslili/SECURITY/#policy","text":"We follow the principle of Coordinated Vulnerability Disclosure.","title":"Policy"},{"location":"osslili/SUPPORT/","text":"Support How to Get Help Thank you for using this project! Here are the best ways to get help: Documentation Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available) Getting Answers Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly Reporting Issues If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue Feature Requests We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project Security Issues For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines. Community Guidelines Please review our Code of Conduct before participating in discussions. Response Times This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours Additional Resources Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Support"},{"location":"osslili/SUPPORT/#support","text":"","title":"Support"},{"location":"osslili/SUPPORT/#how-to-get-help","text":"Thank you for using this project! Here are the best ways to get help:","title":"How to Get Help"},{"location":"osslili/SUPPORT/#documentation","text":"Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available)","title":"Documentation"},{"location":"osslili/SUPPORT/#getting-answers","text":"Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly","title":"Getting Answers"},{"location":"osslili/SUPPORT/#reporting-issues","text":"If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue","title":"Reporting Issues"},{"location":"osslili/SUPPORT/#feature-requests","text":"We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project","title":"Feature Requests"},{"location":"osslili/SUPPORT/#security-issues","text":"For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines.","title":"Security Issues"},{"location":"osslili/SUPPORT/#community-guidelines","text":"Please review our Code of Conduct before participating in discussions.","title":"Community Guidelines"},{"location":"osslili/SUPPORT/#response-times","text":"This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours","title":"Response Times"},{"location":"osslili/SUPPORT/#additional-resources","text":"Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Additional Resources"},{"location":"upmex/","text":"UPMEX - Universal Package Metadata Extractor Extract metadata and license information from packages across 15+ ecosystems with a single tool. Native extraction without external package managers, providing standardized JSON output with dependency mapping, license detection, and API enrichment capabilities. Features Universal Package Support : Extract metadata from 15+ package ecosystems Standardized Output : Consistent JSON structure across all formats Native Extraction : No dependency on external package managers SEMCL.ONE Integration : Works seamlessly with osslili, purl2notices, and ecosystem tools Installation pip install upmex For development: git clone https://github.com/SemClone/upmex.git cd upmex pip install -e . Quick Start # Extract metadata from any package upmex extract package.whl # With API enrichment upmex extract --api all package.jar # Output to file with pretty formatting upmex extract --pretty package.gem -o metadata.json Usage CLI Usage # Basic extraction (offline mode) upmex extract package.whl # Registry mode - fetch missing metadata upmex extract --registry package.jar # API enrichment modes upmex extract --api clearlydefined package.whl upmex extract --api ecosystems package.tgz upmex extract --api purldb package.gem upmex extract --api vulnerablecode package.jar # Combined enrichment upmex extract --registry --api all package.jar # Detect package type upmex detect package.jar # Extract license information upmex license package.tgz # Text format output upmex extract --format text package.tar.gz Python API from upmex import PackageExtractor # Create extractor extractor = PackageExtractor() # Extract metadata metadata = extractor.extract(\"path/to/package.whl\") # Access metadata print(f\"Package: {metadata.name} v{metadata.version}\") print(f\"Type: {metadata.package_type.value}\") print(f\"License: {metadata.licenses[0].spdx_id if metadata.licenses else 'Unknown'}\") # Convert to JSON import json print(json.dumps(metadata.to_dict(), indent=2)) Supported Package Types Ecosystem Formats Registry API Support Python .whl, .tar.gz, .zip PyPI ClearlyDefined, Ecosyste.ms NPM/Node.js .tgz, .tar.gz NPM ClearlyDefined, Ecosyste.ms Java/Maven .jar, .war, .ear Maven Central ClearlyDefined, PurlDB Ruby .gem RubyGems ClearlyDefined, Ecosyste.ms Rust .crate crates.io ClearlyDefined, Ecosyste.ms Go .zip, go.mod Go Modules ClearlyDefined, PurlDB NuGet/.NET .nupkg NuGet ClearlyDefined, Ecosyste.ms Conda .conda, .tar.bz2 Anaconda Ecosyste.ms Perl/CPAN .tar.gz, .zip CPAN Ecosyste.ms CocoaPods .podspec, .podspec.json CocoaPods Ecosyste.ms Conan C/C++ conanfile.py/.txt, .tgz Conan Center Limited Gradle build.gradle(.kts) Maven/Gradle Limited Debian .deb Debian Limited RPM .rpm RPM repos Limited Advanced Features Metadata Extraction Package Information : Name, version, description, homepage Author Parsing : Intelligent name/email extraction and normalization Repository Detection : Automatic VCS URL extraction Platform Support : Architecture and OS requirement detection Package URL (PURL) : Generate standard Package URLs File Hashing : SHA-1, MD5, and fuzzy hash (TLSH) Data Provenance : Track source of each data field License Detection Powered by osslili v1.5.0+: SPDX identifier detection in metadata License file extraction (LICENSE, COPYING, etc.) Package manifest license field parsing Three-tier detection system with high accuracy Dependency Mapping Full dependency tree with version constraints Development vs. runtime dependency classification Optional dependency tracking Version range resolution API Enrichment Enhance metadata with third-party APIs: ClearlyDefined upmex extract --api clearlydefined package.whl License and compliance data Attribution information Security assessments Ecosyste.ms upmex extract --api ecosystems package.jar Package registry metadata Dependency information Version history PurlDB upmex extract --api purldb package.gem Comprehensive package metadata Cross-ecosystem information Historical data VulnerableCode upmex extract --api vulnerablecode package.jar Security vulnerability scanning CVE mapping Risk assessment Configuration Environment Variables # API Keys export PME_CLEARLYDEFINED_API_KEY=your-api-key export PME_ECOSYSTEMS_API_KEY=your-api-key export PME_PURLDB_API_KEY=your-api-key export PME_VULNERABLECODE_API_KEY=your-api-key # Settings export PME_LOG_LEVEL=DEBUG export PME_CACHE_DIR=/path/to/cache export PME_OUTPUT_FORMAT=json Configuration File Create config.json : { \"api\": { \"clearlydefined\": { \"enabled\": true, \"api_key\": null }, \"ecosystems\": { \"enabled\": true, \"api_key\": null } }, \"output\": { \"format\": \"json\", \"pretty_print\": true }, \"cache\": { \"enabled\": true, \"directory\": \"~/.cache/upmex\" } } Output Format Standard JSON Structure { \"package\": { \"name\": \"example-package\", \"version\": \"1.2.3\", \"type\": \"pypi\", \"purl\": \"pkg:pypi/example-package@1.2.3\", \"description\": \"Package description\" }, \"metadata\": { \"homepage\": \"https://example.com\", \"repository\": \"https://github.com/example/package\", \"documentation\": \"https://docs.example.com\" }, \"people\": { \"authors\": [ { \"name\": \"John Doe\", \"email\": \"john@example.com\" } ], \"maintainers\": [] }, \"licensing\": { \"licenses\": [ { \"spdx_id\": \"MIT\", \"name\": \"MIT License\", \"text\": \"...\" } ] }, \"dependencies\": { \"runtime\": [ { \"name\": \"requests\", \"version_constraint\": \">=2.0.0\" } ], \"development\": [] }, \"provenance\": { \"source\": \"package_metadata\", \"enrichment\": [\"clearlydefined\", \"ecosystems\"] } } Integration with SEMCL.ONE UPMEX is a core component of the SEMCL.ONE ecosystem: Powers purl2notices for legal notice generation Uses osslili for enhanced license detection Supports src2purl for package identification Integrates with ospac for policy evaluation Works with purl2src for source retrieval Workflow Example # 1. Extract metadata from package upmex extract library.jar -o metadata.json # 2. Generate legal notices purl2notices -i metadata.json -o NOTICE.txt # 3. Validate compliance ospac evaluate NOTICE.txt --policy compliance.yaml Performance Process packages up to 500MB in under 10 seconds Efficient caching for API responses Parallel processing for batch operations Memory-efficient streaming for large files Documentation User Guide - Comprehensive usage documentation API Reference - Python API documentation Configuration Guide - Detailed configuration options Examples - Common use cases and workflows Contributing We welcome contributions! Please see CONTRIBUTING.md for details on: - Code of conduct - Development setup - Submitting pull requests - Reporting issues Support For support and questions: - GitHub Issues - Bug reports and feature requests - Documentation - Complete project documentation - SEMCL.ONE Community - Ecosystem support and discussions License Apache License 2.0 - see LICENSE file for details. Authors See AUTHORS.md for a list of contributors. Part of the SEMCL.ONE ecosystem for comprehensive OSS compliance and code analysis.","title":"upmex"},{"location":"upmex/#upmex-universal-package-metadata-extractor","text":"Extract metadata and license information from packages across 15+ ecosystems with a single tool. Native extraction without external package managers, providing standardized JSON output with dependency mapping, license detection, and API enrichment capabilities.","title":"UPMEX - Universal Package Metadata Extractor"},{"location":"upmex/#features","text":"Universal Package Support : Extract metadata from 15+ package ecosystems Standardized Output : Consistent JSON structure across all formats Native Extraction : No dependency on external package managers SEMCL.ONE Integration : Works seamlessly with osslili, purl2notices, and ecosystem tools","title":"Features"},{"location":"upmex/#installation","text":"pip install upmex For development: git clone https://github.com/SemClone/upmex.git cd upmex pip install -e .","title":"Installation"},{"location":"upmex/#quick-start","text":"# Extract metadata from any package upmex extract package.whl # With API enrichment upmex extract --api all package.jar # Output to file with pretty formatting upmex extract --pretty package.gem -o metadata.json","title":"Quick Start"},{"location":"upmex/#usage","text":"","title":"Usage"},{"location":"upmex/#cli-usage","text":"# Basic extraction (offline mode) upmex extract package.whl # Registry mode - fetch missing metadata upmex extract --registry package.jar # API enrichment modes upmex extract --api clearlydefined package.whl upmex extract --api ecosystems package.tgz upmex extract --api purldb package.gem upmex extract --api vulnerablecode package.jar # Combined enrichment upmex extract --registry --api all package.jar # Detect package type upmex detect package.jar # Extract license information upmex license package.tgz # Text format output upmex extract --format text package.tar.gz","title":"CLI Usage"},{"location":"upmex/#python-api","text":"from upmex import PackageExtractor # Create extractor extractor = PackageExtractor() # Extract metadata metadata = extractor.extract(\"path/to/package.whl\") # Access metadata print(f\"Package: {metadata.name} v{metadata.version}\") print(f\"Type: {metadata.package_type.value}\") print(f\"License: {metadata.licenses[0].spdx_id if metadata.licenses else 'Unknown'}\") # Convert to JSON import json print(json.dumps(metadata.to_dict(), indent=2))","title":"Python API"},{"location":"upmex/#supported-package-types","text":"Ecosystem Formats Registry API Support Python .whl, .tar.gz, .zip PyPI ClearlyDefined, Ecosyste.ms NPM/Node.js .tgz, .tar.gz NPM ClearlyDefined, Ecosyste.ms Java/Maven .jar, .war, .ear Maven Central ClearlyDefined, PurlDB Ruby .gem RubyGems ClearlyDefined, Ecosyste.ms Rust .crate crates.io ClearlyDefined, Ecosyste.ms Go .zip, go.mod Go Modules ClearlyDefined, PurlDB NuGet/.NET .nupkg NuGet ClearlyDefined, Ecosyste.ms Conda .conda, .tar.bz2 Anaconda Ecosyste.ms Perl/CPAN .tar.gz, .zip CPAN Ecosyste.ms CocoaPods .podspec, .podspec.json CocoaPods Ecosyste.ms Conan C/C++ conanfile.py/.txt, .tgz Conan Center Limited Gradle build.gradle(.kts) Maven/Gradle Limited Debian .deb Debian Limited RPM .rpm RPM repos Limited","title":"Supported Package Types"},{"location":"upmex/#advanced-features","text":"","title":"Advanced Features"},{"location":"upmex/#metadata-extraction","text":"Package Information : Name, version, description, homepage Author Parsing : Intelligent name/email extraction and normalization Repository Detection : Automatic VCS URL extraction Platform Support : Architecture and OS requirement detection Package URL (PURL) : Generate standard Package URLs File Hashing : SHA-1, MD5, and fuzzy hash (TLSH) Data Provenance : Track source of each data field","title":"Metadata Extraction"},{"location":"upmex/#license-detection","text":"Powered by osslili v1.5.0+: SPDX identifier detection in metadata License file extraction (LICENSE, COPYING, etc.) Package manifest license field parsing Three-tier detection system with high accuracy","title":"License Detection"},{"location":"upmex/#dependency-mapping","text":"Full dependency tree with version constraints Development vs. runtime dependency classification Optional dependency tracking Version range resolution","title":"Dependency Mapping"},{"location":"upmex/#api-enrichment","text":"Enhance metadata with third-party APIs:","title":"API Enrichment"},{"location":"upmex/#clearlydefined","text":"upmex extract --api clearlydefined package.whl License and compliance data Attribution information Security assessments","title":"ClearlyDefined"},{"location":"upmex/#ecosystems","text":"upmex extract --api ecosystems package.jar Package registry metadata Dependency information Version history","title":"Ecosyste.ms"},{"location":"upmex/#purldb","text":"upmex extract --api purldb package.gem Comprehensive package metadata Cross-ecosystem information Historical data","title":"PurlDB"},{"location":"upmex/#vulnerablecode","text":"upmex extract --api vulnerablecode package.jar Security vulnerability scanning CVE mapping Risk assessment","title":"VulnerableCode"},{"location":"upmex/#configuration","text":"","title":"Configuration"},{"location":"upmex/#environment-variables","text":"# API Keys export PME_CLEARLYDEFINED_API_KEY=your-api-key export PME_ECOSYSTEMS_API_KEY=your-api-key export PME_PURLDB_API_KEY=your-api-key export PME_VULNERABLECODE_API_KEY=your-api-key # Settings export PME_LOG_LEVEL=DEBUG export PME_CACHE_DIR=/path/to/cache export PME_OUTPUT_FORMAT=json","title":"Environment Variables"},{"location":"upmex/#configuration-file","text":"Create config.json : { \"api\": { \"clearlydefined\": { \"enabled\": true, \"api_key\": null }, \"ecosystems\": { \"enabled\": true, \"api_key\": null } }, \"output\": { \"format\": \"json\", \"pretty_print\": true }, \"cache\": { \"enabled\": true, \"directory\": \"~/.cache/upmex\" } }","title":"Configuration File"},{"location":"upmex/#output-format","text":"","title":"Output Format"},{"location":"upmex/#standard-json-structure","text":"{ \"package\": { \"name\": \"example-package\", \"version\": \"1.2.3\", \"type\": \"pypi\", \"purl\": \"pkg:pypi/example-package@1.2.3\", \"description\": \"Package description\" }, \"metadata\": { \"homepage\": \"https://example.com\", \"repository\": \"https://github.com/example/package\", \"documentation\": \"https://docs.example.com\" }, \"people\": { \"authors\": [ { \"name\": \"John Doe\", \"email\": \"john@example.com\" } ], \"maintainers\": [] }, \"licensing\": { \"licenses\": [ { \"spdx_id\": \"MIT\", \"name\": \"MIT License\", \"text\": \"...\" } ] }, \"dependencies\": { \"runtime\": [ { \"name\": \"requests\", \"version_constraint\": \">=2.0.0\" } ], \"development\": [] }, \"provenance\": { \"source\": \"package_metadata\", \"enrichment\": [\"clearlydefined\", \"ecosystems\"] } }","title":"Standard JSON Structure"},{"location":"upmex/#integration-with-semclone","text":"UPMEX is a core component of the SEMCL.ONE ecosystem: Powers purl2notices for legal notice generation Uses osslili for enhanced license detection Supports src2purl for package identification Integrates with ospac for policy evaluation Works with purl2src for source retrieval","title":"Integration with SEMCL.ONE"},{"location":"upmex/#workflow-example","text":"# 1. Extract metadata from package upmex extract library.jar -o metadata.json # 2. Generate legal notices purl2notices -i metadata.json -o NOTICE.txt # 3. Validate compliance ospac evaluate NOTICE.txt --policy compliance.yaml","title":"Workflow Example"},{"location":"upmex/#performance","text":"Process packages up to 500MB in under 10 seconds Efficient caching for API responses Parallel processing for batch operations Memory-efficient streaming for large files","title":"Performance"},{"location":"upmex/#documentation","text":"User Guide - Comprehensive usage documentation API Reference - Python API documentation Configuration Guide - Detailed configuration options Examples - Common use cases and workflows","title":"Documentation"},{"location":"upmex/#contributing","text":"We welcome contributions! Please see CONTRIBUTING.md for details on: - Code of conduct - Development setup - Submitting pull requests - Reporting issues","title":"Contributing"},{"location":"upmex/#support","text":"For support and questions: - GitHub Issues - Bug reports and feature requests - Documentation - Complete project documentation - SEMCL.ONE Community - Ecosystem support and discussions","title":"Support"},{"location":"upmex/#license","text":"Apache License 2.0 - see LICENSE file for details.","title":"License"},{"location":"upmex/#authors","text":"See AUTHORS.md for a list of contributors. Part of the SEMCL.ONE ecosystem for comprehensive OSS compliance and code analysis.","title":"Authors"},{"location":"upmex/AUTHORS/","text":"Authors Project Lead Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Authors"},{"location":"upmex/AUTHORS/#authors","text":"","title":"Authors"},{"location":"upmex/AUTHORS/#project-lead","text":"Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Project Lead"},{"location":"upmex/CHANGELOG/","text":"Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [1.6.7] - 2025-10-27 Changed License Detection Library Migration : Migrated from deprecated semantic-copycat-oslili to osslili Updated dependency from semantic-copycat-oslili>=1.5.5 to osslili>=1.5.5 Renamed license detection module: oslili_subprocess.py \u2192 osslili_subprocess.py Renamed detector class: OsliliSubprocessDetector \u2192 OssliliSubprocessDetector Updated all function names, comments, and references to use \"osslili\" naming convention Updated GitHub workflow to install osslili instead of deprecated package Updated documentation references to point to new osslili repository Technical Maintained full backward compatibility for license detection functionality CLI commands from oslili to osslili for consistency with new package naming Updated all variable names and method references throughout codebase All extractors now reference \"osslili\" for detection method tracking Dependencies Breaking : Removed deprecated semantic-copycat-oslili dependency Added : osslili>=1.5.5 (successor package with improved functionality) [1.6.6] - 2025-10-27 Changed Moving to official repository and simplifying name Renamed project from semantic-copycat-upmex to upmex Updated repository URLs to point to https://github.com/SemClone/upmex Updated all documentation and installation instructions [1.6.5] - 2025-10-25 Added PurlDB API Integration : New enrichment source for comprehensive package metadata Query packages by PURL (Package URL) for enhanced metadata Extract detailed licensing, authorship, and dependency information Support for all package ecosystems with proper namespace handling VulnerableCode API Integration : Security vulnerability scanning and assessment PURL-based vulnerability queries for comprehensive security analysis CVSS v3.1 severity scoring with automatic categorization (Critical/High/Medium/Low) Vulnerability aliases (CVE IDs) and fix version recommendations Summary statistics by severity level for quick assessment Enhanced CLI Flag Structure : Improved separation of concerns Renamed --online to --registry for clarity (fetches from package registries) Separate --api flag for third-party API integrations (clearlydefined, ecosystems, purldb, vulnerablecode) Support for combined usage: --registry --api all for comprehensive enrichment Enrichment Tracking System : Full transparency on data sources Track all external data sources with timestamps and applied fields Clear differentiation between package metadata and external API data Enrichment provenance for compliance and attestation purposes Vulnerability Information Display : Comprehensive security reporting Text format shows vulnerability counts, severity breakdown, and affected packages JSON format includes detailed vulnerability metadata with CVSS scores Support for both vulnerable and fixing package information Changed CLI Structure Reorganization : Improved flag naming and functionality --online flag renamed to --registry for clarity API enrichment separated from registry operations for better control Updated help text and examples to reflect new flag structure Info Command Accuracy : Updated to reflect actual capabilities Corrected registry support information (only Maven Central currently implemented) Removed outdated license detection information (now handled by OSLiLi) Added new API integrations to supported features list Dependency Updates : Bumped OSLiLi to v1.5.5 for improved license detection Enhanced API Integration Coverage : Expanded external data source support ClearlyDefined: License and compliance data enrichment Ecosystems: Package registry metadata and dependencies PurlDB: Comprehensive package metadata from Package URL database VulnerableCode: Security vulnerability scanning and assessment Output Format Improvements : Enhanced text and JSON output Vulnerability section in text format with severity breakdown Enrichment data section showing all external data sources Improved formatting for vulnerability information display Technical Added VulnerableCodeAPI class for vulnerability scanning integration Added PurlDBAPI class for package metadata enrichment Enhanced PackageMetadata model with vulnerability tracking field Updated OutputFormatter to display vulnerability and enrichment information Improved error handling and API key validation for all integrations Maintained backward compatibility while adding new functionality Testing Comprehensive testing across all package types with new API integrations Verified vulnerability scanning functionality (requires API keys for full testing) Validated enrichment tracking and data source transparency Confirmed proper flag separation between registry and API operations [1.6.2] - 2025-10-16 Added Enhanced online mode with intelligent package-type-specific enrichment strategies Unified --online flag that provides appropriate enrichment for each package type Package-type-aware namespace parsing for scoped packages (@scope/name, groupId:artifactId) ClearlyDefined API integration for NPM and Python packages in online mode Enhanced Maven online mode with Parent POM \u2192 ClearlyDefined API fallback chain Comprehensive provenance tracking for all enrichment data sources Improved error handling and graceful fallbacks for online enrichment Fixed NPM contributor parsing now correctly includes all contributors as authors NuGet copyright field assignment bug that prevented copyright extraction Enhanced copyright detection that prioritizes package metadata over file scanning Function name corrections in OSLiLi subprocess integration Changed Maven packages in online mode now use Parent POM fetching with ClearlyDefined fallback NPM and Python packages in online mode now use direct ClearlyDefined enrichment Online mode behavior is now package-type-specific and more intelligent CLI shows compatibility notes when both --online and --api flags are used together Technical Added enrich_with_clearlydefined() method to BaseExtractor class Enhanced Java extractor with ClearlyDefined fallback after Parent POM processing Updated CLI integration to unify enrichment under single --online flag Improved namespace parsing for Maven (groupId:artifactId) and NPM (@scope/name) formats Maintained backward compatibility with existing --api flag Testing Comprehensive parity testing shows correct enrichment across all package types NPM Express: 2\u21923 licenses with ClearlyDefined enrichment Maven GSON: 0\u21921 authors with Parent POM enrichment Python Requests: 2\u21923 licenses with ClearlyDefined enrichment Maven Guava: 0\u21921 authors with Parent POM + ClearlyDefined fallback Output format consistency maintained between offline and online modes Resolved output formatter test failures Removed Cleanup Removed incorrectly committed gin-test extraction output directory Added gin-test/ to .gitignore to prevent future commits [1.6.0] - 2025-10-16 Changed Major code cleanup after OSLiLi integration Removed 38,000+ lines of obsolete license detection code Removed entire src/upmex/licenses/data/ directory with 400+ SPDX license files Removed obsolete oslili_detector.py and spdx_manager.py modules Cleaned up unused imports across multiple extractors Removed deprecated CLI flags (--all-methods, --no-cache, --confidence) Removed obsolete docs folder Added Comprehensive test package coverage Added test packages for all 15 supported ecosystems Achieved 100% test success rate across all package types and CLI functions Enhanced Conda support Added support for new Conda format v2 (.conda with zstandard compression) Improved compatibility with modern conda-forge packages Fixed Output formatter improvements Fixed output formatter to handle both dict and list dependency formats Improved consistency across different package type outputs [1.5.9] - 2025-09-17 Fixed NPM extractor prioritizes root package.json (#45) Fixed issue where NPM packages with multiple package.json files would use the wrong one Now prioritizes package/package.json (root) over nested package.json files Added error handling for empty or corrupt package.json files Resolves homepage field extraction issue for packages like yargs [1.5.8] - 2025-09-16 Fixed Missing toml dependency (#43) Added toml package as explicit dependency for Rust crate extraction Fixes ImportError when extracting Rust packages in fresh installations [1.5.7] - 2025-09-06 Added RPM Package Support (#19) New RPM package extractor with filename parsing fallback Optional rpm command integration for richer metadata extraction License normalization from RPM format to SPDX identifiers Dependency extraction when rpm command is available Debian Package Support (#18) New Debian (.deb) package extractor with filename parsing fallback Optional dpkg command integration for enhanced metadata Control file parsing for package information Copyright file extraction for license detection Dependency parsing with version constraints Changed Added PackageType.RPM and PackageType.DEB enum values Updated package detector to recognize .rpm and .deb file extensions Registered new extractors in main PackageExtractor class Fixed Test format compatibility with new JSON output structure [1.5.6] - 2025-09-03 Fixed oslili License Detection for Short Identifiers Fixed oslili not detecting short license identifiers like \"MIT\" or \"Apache-2.0\" All extractors now format short license text (< 20 chars) as \"License: \" for better oslili tag detection Updated oslili subprocess to handle both JSON formats (scan_results and results) for compatibility Removed similarity threshold filtering to allow tag detection to work properly Fixed EnhancedLicenseDetector minimum text length check from 20 to 2 characters Ensures consistent license detection across all package formats using oslili tags [1.5.5] - 2025-09-03 Added Copyright Statement Extraction Extracts copyright statements from source files using oslili CLI Adds new copyright field to metadata schema Scans up to 100 files per package for copyright information Supports all package formats (NPM, Python, Java, Ruby, Go, Rust, NuGet) Author Unification with Copyright Holders Automatically merges copyright holders into the authors list Copyright holders are tagged with source: \"copyright\" for provenance Prevents duplicate entries when copyright holder already exists as author Recognizes that copyright holders and authors are often the same people Changed License Detection Migration to oslili Replaced custom license detection with oslili library integration Uses oslili CLI via subprocess for maximum compatibility Improved accuracy with 0.95 confidence threshold Filters known false positives (e.g., Pixar license confusion) Fixed oslili JSON Parsing Fixed parsing of oslili CLI output that includes non-JSON header lines Properly handles both license and copyright detection results Improved error handling for subprocess calls [1.5.1] - 2025-09-02 Fixed Java License Detection Enhancement Java extractor now scans for license files within JAR archives (e.g., META-INF/LICENSE) Previously relied only on POM metadata for license detection Improves license detection coverage for packages like Guava that include license files but don't declare them in POM Merges detected licenses with existing POM-declared licenses while avoiding duplicates [1.5.0] - 2025-08-11 Added Enhanced License Detection with SPDX Support Full SPDX license database integration with 400+ official license texts Fuzzy hash (LSH) matching against normalized license texts Improved Dice-S\u00f8rensen similarity with trigram analysis Full text similarity comparison using SequenceMatcher License alias resolution (GPL-3.0, GPLv3, GPL v3 all map correctly) Text normalization removing copyright notices, dates, and variables Detection method tracking for provenance and attestation Support for detecting dual/multiple licensing scenarios Automatic extraction of LICENSE, COPYING, COPYRIGHT, NOTICE files from archives File Hashing Improvements SHA-1 hash for package files (industry standard) MD5 hash for legacy compatibility TLSH/LSH fuzzy hash for similarity detection All hashes included in file_info section Package URL (PURL) Generation Standard Package URL generation for all supported package types Follows PURL specification for cross-ecosystem compatibility JSON Output Reorganization Structured sections: package, metadata, people, licensing, dependencies, file_info, extraction_info, provenance Clear separation of concerns for better parsing Provenance tracking showing data sources for each field API Improvements Fixed ClearlyDefined API URL format (removed /v1, added provider) Better online mode data enrichment without overwriting existing data Improved maintainer extraction from Ecosyste.ms API Developer Experience Templates directory removed (unused) License manager for SPDX data caching and management Enhanced detector with fallback chain for maximum detection rate Changed License detection now uses multiple methods in priority order: SPDX-License-Identifier exact matching Fuzzy hash matching against SPDX texts Dice-S\u00f8rensen similarity comparison Full text similarity matching Regex pattern matching (fallback) Description fields now normalized to remove extra whitespace Online mode only enriches missing data instead of overwriting Parent POM extraction includes description field Developer extraction handles id/organization when name/email missing Fixed ClearlyDefined API now working correctly with proper URL format JSON output provenance tracking for data attestation Author extraction from Maven POMs with only organization field Description extraction from parent POMs Maintainer information properly extracted from all sources Performance SPDX license texts cached locally for offline operation Pre-computed fuzzy hashes for all license texts Efficient fallback chain minimizes processing time Testing All 11 test packages now correctly detect licenses Enhanced detection achieves 100% success rate on test suite Multiple detection methods provide validation and higher confidence [1.1.3] - 2025-08-10 Changed Major Code Refactoring - Eliminated significant code duplication across all extractors Enhanced BaseExtractor with common functionality for license detection, author parsing, and archive extraction Created reusable utility modules: author_parser.py for consistent author string parsing Created archive_utils.py for common archive extraction operations All 11 extractors now use consistent patterns and share common functionality Reduced codebase size by approximately 30-40% while maintaining full functionality Improved maintainability and consistency across all package format extractors Fixed Fixed indentation issues in Rust extractor that prevented proper parsing Updated all extractors to correctly handle list returns from detect_licenses_from_text method Fixed Java extractor missing maven_central_url attribute for online mode Corrected test assertions to match current version numbering [1.1.2] - 2025-08-10 Added Perl/CPAN Package Support (Issue #21) Full support for .tar.gz and .zip Perl packages Parse META.json and META.yml metadata files Support for MYMETA.json and MYMETA.yml (build-time metadata) Extract dependencies with phase (runtime, test, configure) and relationship info Map Perl license strings to SPDX identifiers Author parsing with email extraction License file detection (LICENSE, COPYING, ARTISTIC, GPL) Conan C/C++ Package Support (Issue #22) Support for conanfile.py (Python-based recipes) and conanfile.txt (INI-style) Parse conaninfo.txt for package metadata Extract from .tgz package archives AST-based and regex-based parsing for Python files Dependencies with version constraints and tool_requires Multi-license support with comma-separated values Topics extraction as keywords Conda Package Support (Issue #23) Full support for .conda (new zip-based format) and .tar.bz2 (traditional format) packages Parse info/index.json for core package metadata Parse info/recipe/meta.yaml or info/recipe.json for detailed build information Metadata extraction: name, version, build string, build number Dependency parsing: runtime, build, host dependencies with version constraints License detection from package metadata Author/maintainer extraction from recipe maintainers Platform and architecture information (subdir) Channel and feature tracking Homepage and repository URL extraction Support for both conda-forge and Anaconda repository packages CocoaPods Support (Issue #24) Full support for .podspec (Ruby DSL) and .podspec.json files Support for both Ruby DSL and JSON podspec formats Metadata extraction: name, version, summary, description Platform requirements parsing (iOS, macOS, tvOS, watchOS, visionOS) Dependency parsing with version requirements License detection from podspec configuration and external files Author and maintainer extraction from podspec metadata Repository URL extraction from source configuration Homepage URL extraction from podspec Framework and library dependencies Keywords extraction from platforms and frameworks Compatible with all CocoaPods project types Gradle Build File Support (Issue #20) Full support for build.gradle and build.gradle.kts files Support for both Groovy DSL and Kotlin DSL syntax Metadata extraction: name, version, group, description Dependency parsing for implementation, api, runtime, and test scopes License detection from publishing/pom configuration blocks Author/developer extraction from publishing metadata Repository URL extraction from SCM configuration Homepage URL extraction from publishing configuration Keywords extraction from project metadata Compatible with Gradle projects and multi-module builds Ruby Gem Support (Issue #3) Full .gem package extraction support Custom YAML loader for Ruby-specific metadata format Extraction from both metadata.gz and data.tar.gz Dependency parsing for runtime and development dependencies Author and email extraction from gemspec License detection from gemspec and LICENSE files Repository URL extraction from metadata URIs Platform and Ruby version requirement extraction Rust Crate Support (Issue #4) Full .crate package extraction support Cargo.toml parsing with TOML library Support for Cargo.toml.orig when available Dependency extraction (normal, dev, build dependencies) Target-specific dependency parsing with platform annotations Author email parsing from \"Name \" format Keywords and categories extraction Rust edition detection License detection from Cargo.toml and LICENSE files Go Module Support (Issue #17) Full Go module package extraction support Support for .zip archives from proxy.golang.org Parse go.mod files for module metadata Extract require, indirect, and replace dependencies Infer repository URLs from module paths (GitHub, GitLab, etc.) Go version requirement extraction License detection from LICENSE files in archives Description extraction from README files NuGet Package Support (Issue #16) Full .nupkg package extraction support XML-based .nuspec metadata parsing with namespace handling Dependency extraction with target framework annotations Support for grouped and flat dependency formats License extraction from expressions, files, and URLs Framework assembly dependency tracking Author and owner (maintainer) extraction Tags (keywords) and release notes parsing Repository URL extraction from multiple sources Modern and legacy NuGet format compatibility Package detector enhancements: Ruby gem detection by .gem extension and tar structure Rust crate detection by .crate extension and Cargo.toml presence Go module detection by .mod files and .zip archives with go.mod NuGet package detection by .nupkg extension and .nuspec presence API integration for new package types: ClearlyDefined support for gem, crate, go, and nuget packages Ecosyste.ms support via rubygems.org, crates.io, proxy.golang.org, and nuget.org registries Successfully tested with real packages: Perl: Moose 2.2207 (177 dependencies extracted) Conan: zlib example with full metadata Conda: numpy 1.21.5, pandas 1.5.3 (from Anaconda repository) CocoaPods: Alamofire 5.10.2, SDWebImage 5.21.1, FirebaseCore 12.2.0 Ruby: Rails 7.1.5 Rust: serde 1.0.210, tokio 1.41.0 Go: gin v1.10.0, cobra v1.8.1 NuGet: Newtonsoft.Json 13.0.3, Serilog 3.1.1 Fixed urllib3 LibreSSL warning suppression on macOS systems Added warning filters at module initialization Prevents NotOpenSSLWarning from appearing in CLI output Ensures clean user experience on systems with LibreSSL Changed Version updated to 1.1.2 Updated development status to stable [0.2.0] - 2025-08-09 Added License Detection System (Issues #1, #2) Regex-based license detection for 24+ SPDX identifiers Dice-S\u00f8rensen coefficient for fuzzy license matching Confidence scoring and detection method tracking Multi-license detection support Integration with all package extractors License Detection Module ( src/upmex/utils/license_detector.py ) Pattern matching for metadata fields SPDX normalization License file detection Dice-S\u00f8rensen Implementation ( src/upmex/utils/dice_sorensen.py ) N-gram based text similarity Bigram and unigram matching strategies Pre-computed license snippet database Comprehensive Test Suite 95+ tests covering all functionality Unit tests for license detection algorithms Integration tests for package extraction End-to-end tests for CLI commands Online mode (--online flag) for enhanced metadata extraction Maven parent POM fetching from Maven Central ClearlyDefined API integration for license information Ecosyste.ms API integration for metadata enrichment POM header comment parsing for license and author data NO-ASSERTION constant for fields where data cannot be determined Standardized metadata output across all package types Improved author parsing with consistent name/email separation Repository URL extraction for Python packages Developer extraction from Maven POMs Changed Standardized author format across all extractors (dict with name/email) Maven extractor now fetches parent POMs in online mode Python extractor now extracts repository from Project-URL metadata Default mode is offline (no external API calls) Fixed Maven package name extraction now uses parent groupId when needed Author email parsing for combined \"Name \" format Repository URL extraction for all package types Removed YAML output format (was broken due to missing PyYAML dependency) [0.1.0] - 2025-08-09 Added Initial project setup and structure Core package extraction framework Multi-ecosystem package support: Python packages (wheel, sdist) NPM packages (tgz) Java/Maven packages (JAR) Package type auto-detection CLI interface with commands: extract : Extract metadata from packages detect : Detect package type license : Extract license information info : Show tool information Output format support (JSON, YAML, text) Configuration system with environment variable support Comprehensive test suite Tested Successfully tested extraction against real packages: Python: requests-2.32.4 (wheel) - full metadata extraction NPM: express-5.1.0 (tgz) - complete package.json parsing Maven: guava-33.4.0-jre (JAR) - POM metadata extraction Verified all core metadata fields are properly extracted: Package name, version, description Authors, maintainers, homepage Dependencies (runtime and dev) Keywords, classifiers, repository info Changed Renamed project from package-metadata-extractor to upmex Renamed CLI command from package-metadata-extractor to upmex Simplified source structure from package_metadata_extractor to upmex Changed license from Apache 2.0 to MIT Removed Batch processing functionality (focus on single package extraction) CSV and JSONL output formats Batch command from CLI Security Path validation for safe extraction Resource limits for large packages [0.0.1] - 2025-08-09 Added Initial repository creation Basic project structure README and LICENSE files","title":"Changelog"},{"location":"upmex/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"upmex/CHANGELOG/#167-2025-10-27","text":"","title":"[1.6.7] - 2025-10-27"},{"location":"upmex/CHANGELOG/#changed","text":"License Detection Library Migration : Migrated from deprecated semantic-copycat-oslili to osslili Updated dependency from semantic-copycat-oslili>=1.5.5 to osslili>=1.5.5 Renamed license detection module: oslili_subprocess.py \u2192 osslili_subprocess.py Renamed detector class: OsliliSubprocessDetector \u2192 OssliliSubprocessDetector Updated all function names, comments, and references to use \"osslili\" naming convention Updated GitHub workflow to install osslili instead of deprecated package Updated documentation references to point to new osslili repository","title":"Changed"},{"location":"upmex/CHANGELOG/#technical","text":"Maintained full backward compatibility for license detection functionality CLI commands from oslili to osslili for consistency with new package naming Updated all variable names and method references throughout codebase All extractors now reference \"osslili\" for detection method tracking","title":"Technical"},{"location":"upmex/CHANGELOG/#dependencies","text":"Breaking : Removed deprecated semantic-copycat-oslili dependency Added : osslili>=1.5.5 (successor package with improved functionality)","title":"Dependencies"},{"location":"upmex/CHANGELOG/#166-2025-10-27","text":"","title":"[1.6.6] - 2025-10-27"},{"location":"upmex/CHANGELOG/#changed_1","text":"Moving to official repository and simplifying name Renamed project from semantic-copycat-upmex to upmex Updated repository URLs to point to https://github.com/SemClone/upmex Updated all documentation and installation instructions","title":"Changed"},{"location":"upmex/CHANGELOG/#165-2025-10-25","text":"","title":"[1.6.5] - 2025-10-25"},{"location":"upmex/CHANGELOG/#added","text":"PurlDB API Integration : New enrichment source for comprehensive package metadata Query packages by PURL (Package URL) for enhanced metadata Extract detailed licensing, authorship, and dependency information Support for all package ecosystems with proper namespace handling VulnerableCode API Integration : Security vulnerability scanning and assessment PURL-based vulnerability queries for comprehensive security analysis CVSS v3.1 severity scoring with automatic categorization (Critical/High/Medium/Low) Vulnerability aliases (CVE IDs) and fix version recommendations Summary statistics by severity level for quick assessment Enhanced CLI Flag Structure : Improved separation of concerns Renamed --online to --registry for clarity (fetches from package registries) Separate --api flag for third-party API integrations (clearlydefined, ecosystems, purldb, vulnerablecode) Support for combined usage: --registry --api all for comprehensive enrichment Enrichment Tracking System : Full transparency on data sources Track all external data sources with timestamps and applied fields Clear differentiation between package metadata and external API data Enrichment provenance for compliance and attestation purposes Vulnerability Information Display : Comprehensive security reporting Text format shows vulnerability counts, severity breakdown, and affected packages JSON format includes detailed vulnerability metadata with CVSS scores Support for both vulnerable and fixing package information","title":"Added"},{"location":"upmex/CHANGELOG/#changed_2","text":"CLI Structure Reorganization : Improved flag naming and functionality --online flag renamed to --registry for clarity API enrichment separated from registry operations for better control Updated help text and examples to reflect new flag structure Info Command Accuracy : Updated to reflect actual capabilities Corrected registry support information (only Maven Central currently implemented) Removed outdated license detection information (now handled by OSLiLi) Added new API integrations to supported features list Dependency Updates : Bumped OSLiLi to v1.5.5 for improved license detection","title":"Changed"},{"location":"upmex/CHANGELOG/#enhanced","text":"API Integration Coverage : Expanded external data source support ClearlyDefined: License and compliance data enrichment Ecosystems: Package registry metadata and dependencies PurlDB: Comprehensive package metadata from Package URL database VulnerableCode: Security vulnerability scanning and assessment Output Format Improvements : Enhanced text and JSON output Vulnerability section in text format with severity breakdown Enrichment data section showing all external data sources Improved formatting for vulnerability information display","title":"Enhanced"},{"location":"upmex/CHANGELOG/#technical_1","text":"Added VulnerableCodeAPI class for vulnerability scanning integration Added PurlDBAPI class for package metadata enrichment Enhanced PackageMetadata model with vulnerability tracking field Updated OutputFormatter to display vulnerability and enrichment information Improved error handling and API key validation for all integrations Maintained backward compatibility while adding new functionality","title":"Technical"},{"location":"upmex/CHANGELOG/#testing","text":"Comprehensive testing across all package types with new API integrations Verified vulnerability scanning functionality (requires API keys for full testing) Validated enrichment tracking and data source transparency Confirmed proper flag separation between registry and API operations","title":"Testing"},{"location":"upmex/CHANGELOG/#162-2025-10-16","text":"","title":"[1.6.2] - 2025-10-16"},{"location":"upmex/CHANGELOG/#added_1","text":"Enhanced online mode with intelligent package-type-specific enrichment strategies Unified --online flag that provides appropriate enrichment for each package type Package-type-aware namespace parsing for scoped packages (@scope/name, groupId:artifactId) ClearlyDefined API integration for NPM and Python packages in online mode Enhanced Maven online mode with Parent POM \u2192 ClearlyDefined API fallback chain Comprehensive provenance tracking for all enrichment data sources Improved error handling and graceful fallbacks for online enrichment","title":"Added"},{"location":"upmex/CHANGELOG/#fixed","text":"NPM contributor parsing now correctly includes all contributors as authors NuGet copyright field assignment bug that prevented copyright extraction Enhanced copyright detection that prioritizes package metadata over file scanning Function name corrections in OSLiLi subprocess integration","title":"Fixed"},{"location":"upmex/CHANGELOG/#changed_3","text":"Maven packages in online mode now use Parent POM fetching with ClearlyDefined fallback NPM and Python packages in online mode now use direct ClearlyDefined enrichment Online mode behavior is now package-type-specific and more intelligent CLI shows compatibility notes when both --online and --api flags are used together","title":"Changed"},{"location":"upmex/CHANGELOG/#technical_2","text":"Added enrich_with_clearlydefined() method to BaseExtractor class Enhanced Java extractor with ClearlyDefined fallback after Parent POM processing Updated CLI integration to unify enrichment under single --online flag Improved namespace parsing for Maven (groupId:artifactId) and NPM (@scope/name) formats Maintained backward compatibility with existing --api flag","title":"Technical"},{"location":"upmex/CHANGELOG/#testing_1","text":"Comprehensive parity testing shows correct enrichment across all package types NPM Express: 2\u21923 licenses with ClearlyDefined enrichment Maven GSON: 0\u21921 authors with Parent POM enrichment Python Requests: 2\u21923 licenses with ClearlyDefined enrichment Maven Guava: 0\u21921 authors with Parent POM + ClearlyDefined fallback Output format consistency maintained between offline and online modes Resolved output formatter test failures","title":"Testing"},{"location":"upmex/CHANGELOG/#removed","text":"Cleanup Removed incorrectly committed gin-test extraction output directory Added gin-test/ to .gitignore to prevent future commits","title":"Removed"},{"location":"upmex/CHANGELOG/#160-2025-10-16","text":"","title":"[1.6.0] - 2025-10-16"},{"location":"upmex/CHANGELOG/#changed_4","text":"Major code cleanup after OSLiLi integration Removed 38,000+ lines of obsolete license detection code Removed entire src/upmex/licenses/data/ directory with 400+ SPDX license files Removed obsolete oslili_detector.py and spdx_manager.py modules Cleaned up unused imports across multiple extractors Removed deprecated CLI flags (--all-methods, --no-cache, --confidence) Removed obsolete docs folder","title":"Changed"},{"location":"upmex/CHANGELOG/#added_2","text":"Comprehensive test package coverage Added test packages for all 15 supported ecosystems Achieved 100% test success rate across all package types and CLI functions Enhanced Conda support Added support for new Conda format v2 (.conda with zstandard compression) Improved compatibility with modern conda-forge packages","title":"Added"},{"location":"upmex/CHANGELOG/#fixed_1","text":"Output formatter improvements Fixed output formatter to handle both dict and list dependency formats Improved consistency across different package type outputs","title":"Fixed"},{"location":"upmex/CHANGELOG/#159-2025-09-17","text":"","title":"[1.5.9] - 2025-09-17"},{"location":"upmex/CHANGELOG/#fixed_2","text":"NPM extractor prioritizes root package.json (#45) Fixed issue where NPM packages with multiple package.json files would use the wrong one Now prioritizes package/package.json (root) over nested package.json files Added error handling for empty or corrupt package.json files Resolves homepage field extraction issue for packages like yargs","title":"Fixed"},{"location":"upmex/CHANGELOG/#158-2025-09-16","text":"","title":"[1.5.8] - 2025-09-16"},{"location":"upmex/CHANGELOG/#fixed_3","text":"Missing toml dependency (#43) Added toml package as explicit dependency for Rust crate extraction Fixes ImportError when extracting Rust packages in fresh installations","title":"Fixed"},{"location":"upmex/CHANGELOG/#157-2025-09-06","text":"","title":"[1.5.7] - 2025-09-06"},{"location":"upmex/CHANGELOG/#added_3","text":"RPM Package Support (#19) New RPM package extractor with filename parsing fallback Optional rpm command integration for richer metadata extraction License normalization from RPM format to SPDX identifiers Dependency extraction when rpm command is available Debian Package Support (#18) New Debian (.deb) package extractor with filename parsing fallback Optional dpkg command integration for enhanced metadata Control file parsing for package information Copyright file extraction for license detection Dependency parsing with version constraints","title":"Added"},{"location":"upmex/CHANGELOG/#changed_5","text":"Added PackageType.RPM and PackageType.DEB enum values Updated package detector to recognize .rpm and .deb file extensions Registered new extractors in main PackageExtractor class","title":"Changed"},{"location":"upmex/CHANGELOG/#fixed_4","text":"Test format compatibility with new JSON output structure","title":"Fixed"},{"location":"upmex/CHANGELOG/#156-2025-09-03","text":"","title":"[1.5.6] - 2025-09-03"},{"location":"upmex/CHANGELOG/#fixed_5","text":"oslili License Detection for Short Identifiers Fixed oslili not detecting short license identifiers like \"MIT\" or \"Apache-2.0\" All extractors now format short license text (< 20 chars) as \"License: \" for better oslili tag detection Updated oslili subprocess to handle both JSON formats (scan_results and results) for compatibility Removed similarity threshold filtering to allow tag detection to work properly Fixed EnhancedLicenseDetector minimum text length check from 20 to 2 characters Ensures consistent license detection across all package formats using oslili tags","title":"Fixed"},{"location":"upmex/CHANGELOG/#155-2025-09-03","text":"","title":"[1.5.5] - 2025-09-03"},{"location":"upmex/CHANGELOG/#added_4","text":"Copyright Statement Extraction Extracts copyright statements from source files using oslili CLI Adds new copyright field to metadata schema Scans up to 100 files per package for copyright information Supports all package formats (NPM, Python, Java, Ruby, Go, Rust, NuGet) Author Unification with Copyright Holders Automatically merges copyright holders into the authors list Copyright holders are tagged with source: \"copyright\" for provenance Prevents duplicate entries when copyright holder already exists as author Recognizes that copyright holders and authors are often the same people","title":"Added"},{"location":"upmex/CHANGELOG/#changed_6","text":"License Detection Migration to oslili Replaced custom license detection with oslili library integration Uses oslili CLI via subprocess for maximum compatibility Improved accuracy with 0.95 confidence threshold Filters known false positives (e.g., Pixar license confusion)","title":"Changed"},{"location":"upmex/CHANGELOG/#fixed_6","text":"oslili JSON Parsing Fixed parsing of oslili CLI output that includes non-JSON header lines Properly handles both license and copyright detection results Improved error handling for subprocess calls","title":"Fixed"},{"location":"upmex/CHANGELOG/#151-2025-09-02","text":"","title":"[1.5.1] - 2025-09-02"},{"location":"upmex/CHANGELOG/#fixed_7","text":"Java License Detection Enhancement Java extractor now scans for license files within JAR archives (e.g., META-INF/LICENSE) Previously relied only on POM metadata for license detection Improves license detection coverage for packages like Guava that include license files but don't declare them in POM Merges detected licenses with existing POM-declared licenses while avoiding duplicates","title":"Fixed"},{"location":"upmex/CHANGELOG/#150-2025-08-11","text":"","title":"[1.5.0] - 2025-08-11"},{"location":"upmex/CHANGELOG/#added_5","text":"Enhanced License Detection with SPDX Support Full SPDX license database integration with 400+ official license texts Fuzzy hash (LSH) matching against normalized license texts Improved Dice-S\u00f8rensen similarity with trigram analysis Full text similarity comparison using SequenceMatcher License alias resolution (GPL-3.0, GPLv3, GPL v3 all map correctly) Text normalization removing copyright notices, dates, and variables Detection method tracking for provenance and attestation Support for detecting dual/multiple licensing scenarios Automatic extraction of LICENSE, COPYING, COPYRIGHT, NOTICE files from archives File Hashing Improvements SHA-1 hash for package files (industry standard) MD5 hash for legacy compatibility TLSH/LSH fuzzy hash for similarity detection All hashes included in file_info section Package URL (PURL) Generation Standard Package URL generation for all supported package types Follows PURL specification for cross-ecosystem compatibility JSON Output Reorganization Structured sections: package, metadata, people, licensing, dependencies, file_info, extraction_info, provenance Clear separation of concerns for better parsing Provenance tracking showing data sources for each field API Improvements Fixed ClearlyDefined API URL format (removed /v1, added provider) Better online mode data enrichment without overwriting existing data Improved maintainer extraction from Ecosyste.ms API Developer Experience Templates directory removed (unused) License manager for SPDX data caching and management Enhanced detector with fallback chain for maximum detection rate","title":"Added"},{"location":"upmex/CHANGELOG/#changed_7","text":"License detection now uses multiple methods in priority order: SPDX-License-Identifier exact matching Fuzzy hash matching against SPDX texts Dice-S\u00f8rensen similarity comparison Full text similarity matching Regex pattern matching (fallback) Description fields now normalized to remove extra whitespace Online mode only enriches missing data instead of overwriting Parent POM extraction includes description field Developer extraction handles id/organization when name/email missing","title":"Changed"},{"location":"upmex/CHANGELOG/#fixed_8","text":"ClearlyDefined API now working correctly with proper URL format JSON output provenance tracking for data attestation Author extraction from Maven POMs with only organization field Description extraction from parent POMs Maintainer information properly extracted from all sources","title":"Fixed"},{"location":"upmex/CHANGELOG/#performance","text":"SPDX license texts cached locally for offline operation Pre-computed fuzzy hashes for all license texts Efficient fallback chain minimizes processing time","title":"Performance"},{"location":"upmex/CHANGELOG/#testing_2","text":"All 11 test packages now correctly detect licenses Enhanced detection achieves 100% success rate on test suite Multiple detection methods provide validation and higher confidence","title":"Testing"},{"location":"upmex/CHANGELOG/#113-2025-08-10","text":"","title":"[1.1.3] - 2025-08-10"},{"location":"upmex/CHANGELOG/#changed_8","text":"Major Code Refactoring - Eliminated significant code duplication across all extractors Enhanced BaseExtractor with common functionality for license detection, author parsing, and archive extraction Created reusable utility modules: author_parser.py for consistent author string parsing Created archive_utils.py for common archive extraction operations All 11 extractors now use consistent patterns and share common functionality Reduced codebase size by approximately 30-40% while maintaining full functionality Improved maintainability and consistency across all package format extractors","title":"Changed"},{"location":"upmex/CHANGELOG/#fixed_9","text":"Fixed indentation issues in Rust extractor that prevented proper parsing Updated all extractors to correctly handle list returns from detect_licenses_from_text method Fixed Java extractor missing maven_central_url attribute for online mode Corrected test assertions to match current version numbering","title":"Fixed"},{"location":"upmex/CHANGELOG/#112-2025-08-10","text":"","title":"[1.1.2] - 2025-08-10"},{"location":"upmex/CHANGELOG/#added_6","text":"Perl/CPAN Package Support (Issue #21) Full support for .tar.gz and .zip Perl packages Parse META.json and META.yml metadata files Support for MYMETA.json and MYMETA.yml (build-time metadata) Extract dependencies with phase (runtime, test, configure) and relationship info Map Perl license strings to SPDX identifiers Author parsing with email extraction License file detection (LICENSE, COPYING, ARTISTIC, GPL) Conan C/C++ Package Support (Issue #22) Support for conanfile.py (Python-based recipes) and conanfile.txt (INI-style) Parse conaninfo.txt for package metadata Extract from .tgz package archives AST-based and regex-based parsing for Python files Dependencies with version constraints and tool_requires Multi-license support with comma-separated values Topics extraction as keywords Conda Package Support (Issue #23) Full support for .conda (new zip-based format) and .tar.bz2 (traditional format) packages Parse info/index.json for core package metadata Parse info/recipe/meta.yaml or info/recipe.json for detailed build information Metadata extraction: name, version, build string, build number Dependency parsing: runtime, build, host dependencies with version constraints License detection from package metadata Author/maintainer extraction from recipe maintainers Platform and architecture information (subdir) Channel and feature tracking Homepage and repository URL extraction Support for both conda-forge and Anaconda repository packages CocoaPods Support (Issue #24) Full support for .podspec (Ruby DSL) and .podspec.json files Support for both Ruby DSL and JSON podspec formats Metadata extraction: name, version, summary, description Platform requirements parsing (iOS, macOS, tvOS, watchOS, visionOS) Dependency parsing with version requirements License detection from podspec configuration and external files Author and maintainer extraction from podspec metadata Repository URL extraction from source configuration Homepage URL extraction from podspec Framework and library dependencies Keywords extraction from platforms and frameworks Compatible with all CocoaPods project types Gradle Build File Support (Issue #20) Full support for build.gradle and build.gradle.kts files Support for both Groovy DSL and Kotlin DSL syntax Metadata extraction: name, version, group, description Dependency parsing for implementation, api, runtime, and test scopes License detection from publishing/pom configuration blocks Author/developer extraction from publishing metadata Repository URL extraction from SCM configuration Homepage URL extraction from publishing configuration Keywords extraction from project metadata Compatible with Gradle projects and multi-module builds Ruby Gem Support (Issue #3) Full .gem package extraction support Custom YAML loader for Ruby-specific metadata format Extraction from both metadata.gz and data.tar.gz Dependency parsing for runtime and development dependencies Author and email extraction from gemspec License detection from gemspec and LICENSE files Repository URL extraction from metadata URIs Platform and Ruby version requirement extraction Rust Crate Support (Issue #4) Full .crate package extraction support Cargo.toml parsing with TOML library Support for Cargo.toml.orig when available Dependency extraction (normal, dev, build dependencies) Target-specific dependency parsing with platform annotations Author email parsing from \"Name \" format Keywords and categories extraction Rust edition detection License detection from Cargo.toml and LICENSE files Go Module Support (Issue #17) Full Go module package extraction support Support for .zip archives from proxy.golang.org Parse go.mod files for module metadata Extract require, indirect, and replace dependencies Infer repository URLs from module paths (GitHub, GitLab, etc.) Go version requirement extraction License detection from LICENSE files in archives Description extraction from README files NuGet Package Support (Issue #16) Full .nupkg package extraction support XML-based .nuspec metadata parsing with namespace handling Dependency extraction with target framework annotations Support for grouped and flat dependency formats License extraction from expressions, files, and URLs Framework assembly dependency tracking Author and owner (maintainer) extraction Tags (keywords) and release notes parsing Repository URL extraction from multiple sources Modern and legacy NuGet format compatibility Package detector enhancements: Ruby gem detection by .gem extension and tar structure Rust crate detection by .crate extension and Cargo.toml presence Go module detection by .mod files and .zip archives with go.mod NuGet package detection by .nupkg extension and .nuspec presence API integration for new package types: ClearlyDefined support for gem, crate, go, and nuget packages Ecosyste.ms support via rubygems.org, crates.io, proxy.golang.org, and nuget.org registries Successfully tested with real packages: Perl: Moose 2.2207 (177 dependencies extracted) Conan: zlib example with full metadata Conda: numpy 1.21.5, pandas 1.5.3 (from Anaconda repository) CocoaPods: Alamofire 5.10.2, SDWebImage 5.21.1, FirebaseCore 12.2.0 Ruby: Rails 7.1.5 Rust: serde 1.0.210, tokio 1.41.0 Go: gin v1.10.0, cobra v1.8.1 NuGet: Newtonsoft.Json 13.0.3, Serilog 3.1.1","title":"Added"},{"location":"upmex/CHANGELOG/#fixed_10","text":"urllib3 LibreSSL warning suppression on macOS systems Added warning filters at module initialization Prevents NotOpenSSLWarning from appearing in CLI output Ensures clean user experience on systems with LibreSSL","title":"Fixed"},{"location":"upmex/CHANGELOG/#changed_9","text":"Version updated to 1.1.2 Updated development status to stable","title":"Changed"},{"location":"upmex/CHANGELOG/#020-2025-08-09","text":"","title":"[0.2.0] - 2025-08-09"},{"location":"upmex/CHANGELOG/#added_7","text":"License Detection System (Issues #1, #2) Regex-based license detection for 24+ SPDX identifiers Dice-S\u00f8rensen coefficient for fuzzy license matching Confidence scoring and detection method tracking Multi-license detection support Integration with all package extractors License Detection Module ( src/upmex/utils/license_detector.py ) Pattern matching for metadata fields SPDX normalization License file detection Dice-S\u00f8rensen Implementation ( src/upmex/utils/dice_sorensen.py ) N-gram based text similarity Bigram and unigram matching strategies Pre-computed license snippet database Comprehensive Test Suite 95+ tests covering all functionality Unit tests for license detection algorithms Integration tests for package extraction End-to-end tests for CLI commands Online mode (--online flag) for enhanced metadata extraction Maven parent POM fetching from Maven Central ClearlyDefined API integration for license information Ecosyste.ms API integration for metadata enrichment POM header comment parsing for license and author data NO-ASSERTION constant for fields where data cannot be determined Standardized metadata output across all package types Improved author parsing with consistent name/email separation Repository URL extraction for Python packages Developer extraction from Maven POMs","title":"Added"},{"location":"upmex/CHANGELOG/#changed_10","text":"Standardized author format across all extractors (dict with name/email) Maven extractor now fetches parent POMs in online mode Python extractor now extracts repository from Project-URL metadata Default mode is offline (no external API calls)","title":"Changed"},{"location":"upmex/CHANGELOG/#fixed_11","text":"Maven package name extraction now uses parent groupId when needed Author email parsing for combined \"Name \" format Repository URL extraction for all package types","title":"Fixed"},{"location":"upmex/CHANGELOG/#removed_1","text":"YAML output format (was broken due to missing PyYAML dependency)","title":"Removed"},{"location":"upmex/CHANGELOG/#010-2025-08-09","text":"","title":"[0.1.0] - 2025-08-09"},{"location":"upmex/CHANGELOG/#added_8","text":"Initial project setup and structure Core package extraction framework Multi-ecosystem package support: Python packages (wheel, sdist) NPM packages (tgz) Java/Maven packages (JAR) Package type auto-detection CLI interface with commands: extract : Extract metadata from packages detect : Detect package type license : Extract license information info : Show tool information Output format support (JSON, YAML, text) Configuration system with environment variable support Comprehensive test suite","title":"Added"},{"location":"upmex/CHANGELOG/#tested","text":"Successfully tested extraction against real packages: Python: requests-2.32.4 (wheel) - full metadata extraction NPM: express-5.1.0 (tgz) - complete package.json parsing Maven: guava-33.4.0-jre (JAR) - POM metadata extraction Verified all core metadata fields are properly extracted: Package name, version, description Authors, maintainers, homepage Dependencies (runtime and dev) Keywords, classifiers, repository info","title":"Tested"},{"location":"upmex/CHANGELOG/#changed_11","text":"Renamed project from package-metadata-extractor to upmex Renamed CLI command from package-metadata-extractor to upmex Simplified source structure from package_metadata_extractor to upmex Changed license from Apache 2.0 to MIT","title":"Changed"},{"location":"upmex/CHANGELOG/#removed_2","text":"Batch processing functionality (focus on single package extraction) CSV and JSONL output formats Batch command from CLI","title":"Removed"},{"location":"upmex/CHANGELOG/#security","text":"Path validation for safe extraction Resource limits for large packages","title":"Security"},{"location":"upmex/CHANGELOG/#001-2025-08-09","text":"","title":"[0.0.1] - 2025-08-09"},{"location":"upmex/CHANGELOG/#added_9","text":"Initial repository creation Basic project structure README and LICENSE files","title":"Added"},{"location":"upmex/CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Contributor Covenant Code of Conduct"},{"location":"upmex/CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"upmex/CODE_OF_CONDUCT/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"upmex/CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"upmex/CODE_OF_CONDUCT/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"upmex/CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"upmex/CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"upmex/CODE_OF_CONDUCT/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"upmex/CODE_OF_CONDUCT/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"upmex/CODE_OF_CONDUCT/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"upmex/CODE_OF_CONDUCT/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"upmex/CODE_OF_CONDUCT/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"upmex/CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Attribution"},{"location":"upmex/CONTRIBUTING/","text":"Contributing to upmex First off, thank you for considering contributing to upmex! It's people like you that make upmex such a great tool. Code of Conduct This project and everyone participating in it is governed by the Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to conduct@semcl.one . How Can I Contribute? Reporting Bugs Before creating bug reports, please check existing issues as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one. How Do I Submit A Good Bug Report? Bugs are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem. If the problem wasn't triggered by a specific action , describe what you were doing before the problem happened and share more information using the guidelines below. Suggesting Enhancements Enhancement suggestions are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps . Include copy/pasteable snippets which you use in those examples. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users. List some other projects where this enhancement exists. Your First Code Contribution Unsure where to begin contributing? You can start by looking through these beginner and help-wanted issues: [Beginner issues][beginner] - issues which should only require a few lines of code, and a test or two. [Help wanted issues][help-wanted] - issues which should be a bit more involved than beginner issues. Pull Requests The process described here has several goals: Maintain code quality Fix problems that are important to users Engage the community in working toward the best possible product Enable a sustainable system for maintainers to review contributions Please follow these steps to have your contribution considered by the maintainers: Follow all instructions in the template Follow the styleguides After you submit your pull request, verify that all status checks are passing While the prerequisites above must be satisfied prior to having your pull request reviewed, the reviewer(s) may ask you to complete additional design work, tests, or other changes before your pull request can be ultimately accepted. Styleguides Git Commit Messages Use the present tense (\"Add feature\" not \"Added feature\") Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit the first line to 72 characters or less Reference issues and pull requests liberally after the first line When only changing documentation, include [ci skip] in the commit title Python Styleguide All Python code must adhere to PEP 8 . Use type hints where appropriate Include docstrings for all public functions, classes, and modules Prefer explicit over implicit Write tests for new functionality Documentation Styleguide Use Markdown . Reference functions and classes in backticks: `function_name()`. Include code examples where appropriate. Development Process Fork the repo and create your branch from main . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request! Development Setup # Clone your fork git clone https://github.com/your-username/upmex.git cd upmex # Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # Install dependencies pip install -e .[dev] # Run tests pytest # Run linting ruff check . black --check . Running Tests # Run all tests pytest # Run with coverage pytest --cov=upmex # Run specific test file pytest tests/test_specific.py Community You can chat with the community on: - GitHub Discussions - Issues Recognition Contributors who have made significant contributions will be recognized in our AUTHORS file. Thank you for contributing!","title":"Contributing to upmex"},{"location":"upmex/CONTRIBUTING/#contributing-to-upmex","text":"First off, thank you for considering contributing to upmex! It's people like you that make upmex such a great tool.","title":"Contributing to upmex"},{"location":"upmex/CONTRIBUTING/#code-of-conduct","text":"This project and everyone participating in it is governed by the Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to conduct@semcl.one .","title":"Code of Conduct"},{"location":"upmex/CONTRIBUTING/#how-can-i-contribute","text":"","title":"How Can I Contribute?"},{"location":"upmex/CONTRIBUTING/#reporting-bugs","text":"Before creating bug reports, please check existing issues as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one.","title":"Reporting Bugs"},{"location":"upmex/CONTRIBUTING/#how-do-i-submit-a-good-bug-report","text":"Bugs are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem. If the problem wasn't triggered by a specific action , describe what you were doing before the problem happened and share more information using the guidelines below.","title":"How Do I Submit A Good Bug Report?"},{"location":"upmex/CONTRIBUTING/#suggesting-enhancements","text":"Enhancement suggestions are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps . Include copy/pasteable snippets which you use in those examples. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users. List some other projects where this enhancement exists.","title":"Suggesting Enhancements"},{"location":"upmex/CONTRIBUTING/#your-first-code-contribution","text":"Unsure where to begin contributing? You can start by looking through these beginner and help-wanted issues: [Beginner issues][beginner] - issues which should only require a few lines of code, and a test or two. [Help wanted issues][help-wanted] - issues which should be a bit more involved than beginner issues.","title":"Your First Code Contribution"},{"location":"upmex/CONTRIBUTING/#pull-requests","text":"The process described here has several goals: Maintain code quality Fix problems that are important to users Engage the community in working toward the best possible product Enable a sustainable system for maintainers to review contributions Please follow these steps to have your contribution considered by the maintainers: Follow all instructions in the template Follow the styleguides After you submit your pull request, verify that all status checks are passing While the prerequisites above must be satisfied prior to having your pull request reviewed, the reviewer(s) may ask you to complete additional design work, tests, or other changes before your pull request can be ultimately accepted.","title":"Pull Requests"},{"location":"upmex/CONTRIBUTING/#styleguides","text":"","title":"Styleguides"},{"location":"upmex/CONTRIBUTING/#git-commit-messages","text":"Use the present tense (\"Add feature\" not \"Added feature\") Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit the first line to 72 characters or less Reference issues and pull requests liberally after the first line When only changing documentation, include [ci skip] in the commit title","title":"Git Commit Messages"},{"location":"upmex/CONTRIBUTING/#python-styleguide","text":"All Python code must adhere to PEP 8 . Use type hints where appropriate Include docstrings for all public functions, classes, and modules Prefer explicit over implicit Write tests for new functionality","title":"Python Styleguide"},{"location":"upmex/CONTRIBUTING/#documentation-styleguide","text":"Use Markdown . Reference functions and classes in backticks: `function_name()`. Include code examples where appropriate.","title":"Documentation Styleguide"},{"location":"upmex/CONTRIBUTING/#development-process","text":"Fork the repo and create your branch from main . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request!","title":"Development Process"},{"location":"upmex/CONTRIBUTING/#development-setup","text":"# Clone your fork git clone https://github.com/your-username/upmex.git cd upmex # Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # Install dependencies pip install -e .[dev] # Run tests pytest # Run linting ruff check . black --check .","title":"Development Setup"},{"location":"upmex/CONTRIBUTING/#running-tests","text":"# Run all tests pytest # Run with coverage pytest --cov=upmex # Run specific test file pytest tests/test_specific.py","title":"Running Tests"},{"location":"upmex/CONTRIBUTING/#community","text":"You can chat with the community on: - GitHub Discussions - Issues","title":"Community"},{"location":"upmex/CONTRIBUTING/#recognition","text":"Contributors who have made significant contributions will be recognized in our AUTHORS file. Thank you for contributing!","title":"Recognition"},{"location":"upmex/SECURITY/","text":"Security Policy Supported Versions We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release Reporting a Vulnerability Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. Preferred Languages We prefer all communications to be in English. Policy We follow the principle of Coordinated Vulnerability Disclosure.","title":"Security Policy"},{"location":"upmex/SECURITY/#security-policy","text":"","title":"Security Policy"},{"location":"upmex/SECURITY/#supported-versions","text":"We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release","title":"Supported Versions"},{"location":"upmex/SECURITY/#reporting-a-vulnerability","text":"Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly.","title":"Reporting a Vulnerability"},{"location":"upmex/SECURITY/#preferred-languages","text":"We prefer all communications to be in English.","title":"Preferred Languages"},{"location":"upmex/SECURITY/#policy","text":"We follow the principle of Coordinated Vulnerability Disclosure.","title":"Policy"},{"location":"upmex/SUPPORT/","text":"Support How to Get Help Thank you for using this project! Here are the best ways to get help: Documentation Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available) Getting Answers Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly Reporting Issues If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue Feature Requests We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project Security Issues For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines. Community Guidelines Please review our Code of Conduct before participating in discussions. Response Times This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours Additional Resources Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Support"},{"location":"upmex/SUPPORT/#support","text":"","title":"Support"},{"location":"upmex/SUPPORT/#how-to-get-help","text":"Thank you for using this project! Here are the best ways to get help:","title":"How to Get Help"},{"location":"upmex/SUPPORT/#documentation","text":"Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available)","title":"Documentation"},{"location":"upmex/SUPPORT/#getting-answers","text":"Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly","title":"Getting Answers"},{"location":"upmex/SUPPORT/#reporting-issues","text":"If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue","title":"Reporting Issues"},{"location":"upmex/SUPPORT/#feature-requests","text":"We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project","title":"Feature Requests"},{"location":"upmex/SUPPORT/#security-issues","text":"For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines.","title":"Security Issues"},{"location":"upmex/SUPPORT/#community-guidelines","text":"Please review our Code of Conduct before participating in discussions.","title":"Community Guidelines"},{"location":"upmex/SUPPORT/#response-times","text":"This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours","title":"Response Times"},{"location":"upmex/SUPPORT/#additional-resources","text":"Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Additional Resources"},{"location":"binarysniffer/","text":"BinarySniffer - Binary Component Detection and Security Analysis A high-performance CLI tool and Python library for detecting open source components and security threats in binaries through semantic signature matching. Specialized for analyzing mobile apps (APK/IPA), Java archives, ML models, and source code to identify OSS components, their licenses, and potential security risks. Features Binary Component Detection : Identify 188+ OSS components in compiled binaries using semantic signatures ML Model Security Analysis : Comprehensive security scanning with MITRE ATT&CK mapping Multi-Format Support : APK/IPA, JAR/WAR, ELF/PE/Mach-O, ML models (pickle, ONNX, SafeTensors) SEMCL.ONE Integration : Works seamlessly with osslili, purl2notices, and other ecosystem tools Installation pip install binarysniffer For development: git clone https://github.com/SemClone/binarysniffer.git cd binarysniffer pip install -e . With performance extras: pip install binarysniffer[fast] Quick Start # Analyze a binary file binarysniffer analyze /path/to/binary # ML model security scan binarysniffer ml-scan model.pkl --deep # Generate SBOM binarysniffer analyze app.apk --format cyclonedx -o sbom.json Usage CLI Usage # Basic analysis binarysniffer analyze app.apk # ML model security analysis binarysniffer ml-scan model.pkl --risk-threshold 0.5 # Directory scanning with recursion binarysniffer analyze /path/to/project -r # Generate CycloneDX SBOM binarysniffer analyze app.jar --format sbom -o app-sbom.json # Extract package inventory binarysniffer inventory app.apk --with-hashes -o inventory.json Python API from binarysniffer import EnhancedBinarySniffer # Initialize analyzer sniffer = EnhancedBinarySniffer() # Analyze a file result = sniffer.analyze_file(\"app.apk\") for match in result.matches: print(f\"{match.component} - {match.confidence:.2%}\") print(f\"License: {match.license}\") # ML security analysis from binarysniffer.ml_security import MLSecurityAnalyzer analyzer = MLSecurityAnalyzer() risks = analyzer.analyze_model(\"model.pkl\") Core Capabilities Binary Analysis Advanced format support (ELF, PE, Mach-O) via LIEF Android DEX bytecode analysis Static library (.a) support Symbol and import extraction Archive Support Mobile apps (APK, IPA) Java archives (JAR, WAR) Python packages (wheel, egg) Linux packages (DEB, RPM) Extended formats (7z, RAR, Zstandard) ML Model Security (v1.10.0+) Safe pickle file analysis ONNX and SafeTensors validation PyTorch/TensorFlow native formats 100% detection rate on known exploits SARIF output for CI/CD integration Signature Database 188 OSS components covered 1,400+ high-quality signatures Automatic license detection Security severity classification Integration with SEMCL.ONE BinarySniffer is a core component of the SEMCL.ONE ecosystem: Complements osslili for source code license detection Works with purl2notices for comprehensive attribution Integrates with ospac for policy evaluation Supports upmex for package metadata extraction Configuration # ~/.binarysniffer/config.json { \"signature_sources\": [ \"https://signatures.binarysniffer.io/core.xmdb\" ], \"min_confidence\": 0.5, \"parallel_workers\": 4, \"auto_update\": true } Documentation User Guide - Comprehensive usage examples API Reference - Python API documentation ML Security - ML model security analysis Signature Management - Creating and managing signatures Architecture - System design and internals Advanced Topics TLSH Fuzzy Matching - Detecting modified components Creating Signatures - Contributing new signatures Installation Guide - Platform-specific setup Package Verification - Archive analysis Contributing We welcome contributions! Please see CONTRIBUTING.md for details on: - Code of conduct - Development setup - Submitting pull requests - Signature contributions Support For support and questions: - GitHub Issues - Bug reports and feature requests - Documentation - Complete project documentation - SEMCL.ONE Community - Ecosystem support and discussions License Apache License 2.0 - see LICENSE file for details. Authors See AUTHORS.md for a list of contributors. Part of the SEMCL.ONE ecosystem for comprehensive OSS compliance and code analysis.","title":"binarysniffer"},{"location":"binarysniffer/#binarysniffer-binary-component-detection-and-security-analysis","text":"A high-performance CLI tool and Python library for detecting open source components and security threats in binaries through semantic signature matching. Specialized for analyzing mobile apps (APK/IPA), Java archives, ML models, and source code to identify OSS components, their licenses, and potential security risks.","title":"BinarySniffer - Binary Component Detection and Security Analysis"},{"location":"binarysniffer/#features","text":"Binary Component Detection : Identify 188+ OSS components in compiled binaries using semantic signatures ML Model Security Analysis : Comprehensive security scanning with MITRE ATT&CK mapping Multi-Format Support : APK/IPA, JAR/WAR, ELF/PE/Mach-O, ML models (pickle, ONNX, SafeTensors) SEMCL.ONE Integration : Works seamlessly with osslili, purl2notices, and other ecosystem tools","title":"Features"},{"location":"binarysniffer/#installation","text":"pip install binarysniffer For development: git clone https://github.com/SemClone/binarysniffer.git cd binarysniffer pip install -e . With performance extras: pip install binarysniffer[fast]","title":"Installation"},{"location":"binarysniffer/#quick-start","text":"# Analyze a binary file binarysniffer analyze /path/to/binary # ML model security scan binarysniffer ml-scan model.pkl --deep # Generate SBOM binarysniffer analyze app.apk --format cyclonedx -o sbom.json","title":"Quick Start"},{"location":"binarysniffer/#usage","text":"","title":"Usage"},{"location":"binarysniffer/#cli-usage","text":"# Basic analysis binarysniffer analyze app.apk # ML model security analysis binarysniffer ml-scan model.pkl --risk-threshold 0.5 # Directory scanning with recursion binarysniffer analyze /path/to/project -r # Generate CycloneDX SBOM binarysniffer analyze app.jar --format sbom -o app-sbom.json # Extract package inventory binarysniffer inventory app.apk --with-hashes -o inventory.json","title":"CLI Usage"},{"location":"binarysniffer/#python-api","text":"from binarysniffer import EnhancedBinarySniffer # Initialize analyzer sniffer = EnhancedBinarySniffer() # Analyze a file result = sniffer.analyze_file(\"app.apk\") for match in result.matches: print(f\"{match.component} - {match.confidence:.2%}\") print(f\"License: {match.license}\") # ML security analysis from binarysniffer.ml_security import MLSecurityAnalyzer analyzer = MLSecurityAnalyzer() risks = analyzer.analyze_model(\"model.pkl\")","title":"Python API"},{"location":"binarysniffer/#core-capabilities","text":"","title":"Core Capabilities"},{"location":"binarysniffer/#binary-analysis","text":"Advanced format support (ELF, PE, Mach-O) via LIEF Android DEX bytecode analysis Static library (.a) support Symbol and import extraction","title":"Binary Analysis"},{"location":"binarysniffer/#archive-support","text":"Mobile apps (APK, IPA) Java archives (JAR, WAR) Python packages (wheel, egg) Linux packages (DEB, RPM) Extended formats (7z, RAR, Zstandard)","title":"Archive Support"},{"location":"binarysniffer/#ml-model-security-v1100","text":"Safe pickle file analysis ONNX and SafeTensors validation PyTorch/TensorFlow native formats 100% detection rate on known exploits SARIF output for CI/CD integration","title":"ML Model Security (v1.10.0+)"},{"location":"binarysniffer/#signature-database","text":"188 OSS components covered 1,400+ high-quality signatures Automatic license detection Security severity classification","title":"Signature Database"},{"location":"binarysniffer/#integration-with-semclone","text":"BinarySniffer is a core component of the SEMCL.ONE ecosystem: Complements osslili for source code license detection Works with purl2notices for comprehensive attribution Integrates with ospac for policy evaluation Supports upmex for package metadata extraction","title":"Integration with SEMCL.ONE"},{"location":"binarysniffer/#configuration","text":"# ~/.binarysniffer/config.json { \"signature_sources\": [ \"https://signatures.binarysniffer.io/core.xmdb\" ], \"min_confidence\": 0.5, \"parallel_workers\": 4, \"auto_update\": true }","title":"Configuration"},{"location":"binarysniffer/#documentation","text":"User Guide - Comprehensive usage examples API Reference - Python API documentation ML Security - ML model security analysis Signature Management - Creating and managing signatures Architecture - System design and internals","title":"Documentation"},{"location":"binarysniffer/#advanced-topics","text":"TLSH Fuzzy Matching - Detecting modified components Creating Signatures - Contributing new signatures Installation Guide - Platform-specific setup Package Verification - Archive analysis","title":"Advanced Topics"},{"location":"binarysniffer/#contributing","text":"We welcome contributions! Please see CONTRIBUTING.md for details on: - Code of conduct - Development setup - Submitting pull requests - Signature contributions","title":"Contributing"},{"location":"binarysniffer/#support","text":"For support and questions: - GitHub Issues - Bug reports and feature requests - Documentation - Complete project documentation - SEMCL.ONE Community - Ecosystem support and discussions","title":"Support"},{"location":"binarysniffer/#license","text":"Apache License 2.0 - see LICENSE file for details.","title":"License"},{"location":"binarysniffer/#authors","text":"See AUTHORS.md for a list of contributors. Part of the SEMCL.ONE ecosystem for comprehensive OSS compliance and code analysis.","title":"Authors"},{"location":"binarysniffer/AUTHORS/","text":"Authors Project Lead Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Authors"},{"location":"binarysniffer/AUTHORS/#authors","text":"","title":"Authors"},{"location":"binarysniffer/AUTHORS/#project-lead","text":"Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Project Lead"},{"location":"binarysniffer/CHANGELOG/","text":"Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [1.11.2] - 2025-10-27 Fixed Dependency Resolution - Fixed dependency compatibility issues with renamed packages Ensured clean migration from semantic-copycat-oslili to osslili>=1.5.6 Ensured clean migration from semantic-copycat-upmex to upmex>=1.6.7 Removed conflicting legacy package installations that caused version mismatches All integrations now properly import from updated package namespaces [1.11.1] - 2025-10-27 Changed Dependencies Updated - Migrated from legacy semantic-copycat packages to renamed versions Updated semantic-copycat-oslili>=1.5.0 \u2192 osslili>=1.5.6 for license detection Updated semantic-copycat-upmex>=1.6.2 \u2192 upmex>=1.6.7 for package metadata extraction Updated import statements and error messages to use new package names All functionality maintained with improved dependency management Fixed Progress Display - Fixed progress bar stuck at 0% for directory analysis Progress callbacks now properly track file processing Consolidated summary table for directory scans instead of individual file results File Processing - Resolved hanging issues with problematic files Added configurable timeout system (60s default) with --timeout option Automatic detection and exclusion of XML/plist metadata files Fixed processing of large files (>50MB excluded by default, use --include-large to analyze) Added CLI Enhancements - New options for better control and visibility --timeout - Configure per-file timeout (default: 60 seconds) --include-large / -l - Include files larger than 50MB in analysis --debug / -v - Show files being processed in real-time --skip-metadata - Skip XML/plist metadata files entirely --with-hashes - Now properly displays file hash values Improved Performance - Optimized file processing for large directories Sequential processing for large directories (>100 files) to prevent resource exhaustion Smart file filtering to skip problematic formats early Reduced timeout for metadata files (3 seconds) Documentation - Updated user guide with all new CLI options Comprehensive option descriptions and usage examples Fixed outdated references to deprecated flags License Detection - Verified OSLiLi integration functionality Successfully detects BSD, ISC, Python-2.0 licenses with high confidence (85-97%) Proper oslili_detection type matching in evidence display TLSH Fuzzy Matching - Enabled and documented TLSH support Created example TLSH signature database Comprehensive setup guide in docs/TLSH_SETUP_GUIDE.md 100% confidence matching for system binaries Removed Deprecated Options - Cleaned up obsolete CLI flags Removed --enhanced flag (enhanced mode is now always enabled) Fixed partially wired options to be fully functional [1.10.5] - 2025-10-19 Fixed Test Suite - Achieved 100% test success rate (205/205 tests passing) Fixed ONNX extractor file type detection to properly handle .pb files Fixed pickle extractor missing security methods ( validate_safe_unpickle() ) Fixed PyTorch native extractor functionality: State dict detection ( has_state_dict ) Optimizer detection ( has_optimizer ) Architecture detection (ResNet, Transformer, etc.) Suspicious operations detection via STACK_GLOBAL handling Layer counting functionality Fixed static library BSD extended names parsing bug (double subtraction issue) Improved Code Quality - Cleaned up dead code and duplicated imports Removed unused import struct from hashing utilities Consolidated duplicate import zipfile statements in UPMEX adapter Moved imports to module level for better organization Enhanced code maintainability with zero orphaned files Changed Dependencies - Updated multiple outdated dependencies to more recent versions Improved compatibility and security with latest package versions Maintained backward compatibility while upgrading core dependencies [1.10.1] - 2025-08-30 Added OSLiLi Integration - Enhanced license detection using osslili Automatic license detection from package metadata (package.json, pom.xml, etc.) SPDX-compliant license identifiers ML-based license matching with higher accuracy Support for license categorization (declared, detected, referenced) Integrated into archive extraction pipeline Improved License Detection Accuracy - Better detection rates Correctly identifies licenses from LICENSE files in archives Reduced false positives through ML-based matching TLSH fuzzy matching for license text similarity Proper detection of Apache-2.0, MIT, BSD, GPL, and other common licenses Fixed Code Quality - Removed dead code and fixed potential bugs Fixed potential None reference in analyze_licenses method Removed duplicate license detection implementations Cleaned up unused methods in integrations module Improved error handling when OSLiLi is unavailable Changed Dependencies - Added osslili as required dependency osslili >= 1.5.6 now required for license detection LicenseMatcher retained as fallback for compatibility [1.10.0] - 2025-08-15 Added ML Model Security Analysis System - Comprehensive security module for ML models (Issues #25, #26) New ml-scan CLI command for dedicated ML security analysis MITRE ATT&CK framework integration for threat categorization Multi-level risk assessment (SAFE, LOW, MEDIUM, HIGH, CRITICAL) Deep pickle opcode analysis without code execution Obfuscation detection using entropy analysis and pattern matching Model integrity validation with hash verification Support for multiple output formats: JSON, SARIF, Markdown, CycloneDX SBOM Malicious Pattern Detection - Extensive database of threat patterns Code execution patterns (os.system, subprocess.Popen, eval, exec) Network operation detection (socket, requests, urllib) Shell command indicators (/bin/bash, cmd.exe, reverse shells) Obfuscation techniques (base64, zlib, marshal encoding) 50+ critical threat patterns mapped to MITRE techniques Security-Enhanced SBOM - CycloneDX format with ML security metadata Risk assessment metadata in SBOM components Security indicators and recommendations ML framework detection integrated with security analysis Threat pattern evidence in component properties SARIF Output Format - CI/CD integration support Static Analysis Results Interchange Format for security tools GitHub Actions and IDE integration ready Detailed security findings with line-level precision Actionable remediation suggestions Improved Pickle Analysis - Enhanced detection capabilities Fixed entropy calculation for better obfuscation detection Improved STACK_GLOBAL opcode resolution Better handling of malformed pickle files Risk level assessment integrated into standard analysis ML Framework Detection - Better accuracy XGBoost detection improved to 77.3% confidence PyTorch detection at 96% confidence scikit-learn detection at 94% confidence Proper license attribution for all ML frameworks Fixed Entropy calculation error in PickleSecurityAnalyzer (float.bit_length() issue) Missing TaskProgressColumn import in CLI module Malicious pickle files now properly flagged as CRITICAL risk [1.9.9] - 2025-08-14 Added XGBoost Detection - New signature file for XGBoost gradient boosting framework Detects xgboost.sklearn, XGBClassifier, XGBRegressor patterns Identifies gradient boosting specific parameters (max_depth, n_estimators, learning_rate) Successfully detects XGBoost in mixed ML model files Apache-2.0 license attribution for XGBoost components Malformed File Detection - Enhanced handling of corrupted and invalid files New signature set for detecting malformed pickle files Categorizes errors: invalid opcodes, truncated files, unknown errors Provides clear WARNING classification for problematic files Tracks risk levels in metadata (malformed, error, dangerous, safe) Improved Enhanced Pickle Extractor - Better error handling and user feedback Distinguishes between different types of file corruption Adds specific error features for signature matching Provides suspicious_items metadata for detailed diagnostics Improved risk assessment with new \"malformed\" and \"error\" categories CLI User Experience - Clearer warnings and feedback for problematic files Table components can display warning titles and captions Special formatting for malformed file detection Risk level indicators shown before component tables Better visual distinction between normal detections and warnings Fixed Mixed ML model files (e.g., XGBoost models) now properly detected instead of showing \"No components\" Malformed pickle files now show clear WARNING instead of generic error messages Classification column properly handles both licenses and security warnings [1.9.8] - 2025-08-14 Added SafeTensors Format Parser - New extractor for secure tensor storage format Validates SafeTensors format integrity and detects tampering Identifies format violations that could indicate file manipulation Detects injection attempts via unexpected metadata keys Flags oversized tensors (>1B elements) as potential data exfiltration risks Identifies suspicious tensor names (backdoor, trigger, hidden, etc.) Detects base64-like names that might indicate obfuscation Extracts framework metadata (PyTorch, TensorFlow, JAX, Transformers) Recognizes model architectures (BERT, LLaMA, ResNet, ViT, CLIP, etc.) Provides comprehensive security assessment for supply chain verification SafeTensors Security Signatures - New signature sets for SafeTensors validation safetensors-format.json: Core SafeTensors format signatures safetensors-pytorch.json: PyTorch model patterns safetensors-transformers.json: Hugging Face Transformers patterns safetensors-security.json: Security and tampering detection patterns [1.9.8] - 2025-08-14 Added ONNX Model Parser - New extractor for ONNX (Open Neural Network Exchange) format models (addresses #22) Works with or without onnx library (pattern-based fallback) Detects source frameworks (PyTorch, TensorFlow, sklearn, XGBoost, etc.) Identifies model architectures (ResNet, BERT, YOLO, EfficientNet, etc.) Extracts and analyzes ONNX operators (Conv, Attention, LSTM, etc.) Detects suspicious custom operators and malicious patterns Provides security risk assessment (safe, suspicious, dangerous) Extracts model metadata (producer, version, parameters, size) 100% detection rate on suspicious ONNX models ONNX Security Signatures - New signature sets for ONNX model analysis onnx-security.json: Patterns for detecting security risks onnx-pytorch.json: PyTorch-exported ONNX models onnx-tensorflow.json: TensorFlow-exported ONNX models onnx-architectures.json: Common model architectures [1.9.7] - 2025-08-14 Added Pickle File Parser - New extractor for ML model security analysis (closes #21) Detects malicious pickle operations without executing code Identifies dangerous imports (os.system, subprocess, eval, exec, socket, etc.) Recognizes ML frameworks (sklearn, PyTorch, TensorFlow, XGBoost, LightGBM, etc.) Provides risk assessment levels (safe, suspicious, dangerous) Handles all pickle protocol versions (0-5) Detects REDUCE, BUILD, INST, OBJ, and other code execution opcodes Handles both GLOBAL and STACK_GLOBAL opcodes for import detection Normalizes platform-specific imports (posix.system \u2192 os.system) 100% detection rate on real-world malicious pickle attacks ML Security Signatures - New signature sets for ML model analysis pickle-malicious.json: Patterns for detecting malicious pickle operations sklearn.json: Signatures for scikit-learn models pytorch.json: Signatures for PyTorch models Safe Unpickle Validation - New method to check if pickle files are safe to load Changed Documentation - Clarified that automated signature extraction from package managers is out of scope for the CLI tool Updated CONTRIBUTING.md to note this feature will be implemented in a separate scanning orchestrator Updated docs/SIGNATURE_MANAGEMENT.md with similar clarification about scope limitations Security ML Model Security - Can now detect NullifyAI-style attacks and other malicious ML model backdoors Comprehensive Threat Detection - Detects reverse shells, data exfiltration, code execution, and obfuscated payloads in pickle files [1.9.6] - 2025-08-13 Added Signature Collision Detection - New system to identify and resolve pattern conflicts between components Implemented SignatureCollisionDetector for cross-signature pattern analysis Added --check-collisions flag to analyze pattern overlaps Added --interactive mode for guided collision resolution Added --collision-threshold to control sensitivity (default: 2 patterns) Smart severity levels: critical (5+ components), high (3-4), medium (2 unrelated), low (2 related) Recognizes related component families (FFmpeg, OpenSSL, Qt, etc.) Automatic Generic Word Filtering - Filters 100+ common programming terms to prevent false positives Automatically removes generic patterns like \"error\", \"debug\", \"init\", \"handler\", etc. Preserves library-specific prefixes (av_, ssl_, qt_, etc.) Signature Deduplication - All signatures are now automatically deduplicated during generation Enhanced Test Coverage - Added comprehensive test suite for signature validation Improved Signature Quality - Significantly reduced false positives through automatic filtering Documentation - Updated signature management docs with collision detection features [1.9.5] - 2025-08-11 Fixed Signature Status Command - Fixed pattern counting to handle both \"signatures\" and \"patterns\" keys in verification OpenSSL Signatures - Merged openssl.json and openssl-specific.json into single file with 135 patterns Improved Signature Organization - Eliminated redundant signature files for cleaner structure Status Display - No more false mismatch warnings for properly imported signatures [1.9.4] - 2025-08-11 Fixed Codec Signature Import - Fixed critical bug where codec signatures (H.264, AAC, Dolby, etc.) were not being imported JSON Pattern Support - SignatureManager now handles both \"signatures\" and \"patterns\" keys in JSON files Multimedia Detection - Now properly detects GStreamer, GLib, and all video/audio codecs in packages Improved Signature Count - Increased from 1,193 to 1,324 signatures with proper codec imports Detection Accuracy - Significantly improved detection of multimedia components in vpkg and archive files README - Simplified Features section and removed version annotations [1.9.3] - 2025-08-11 Fixed Signature Database Corruption - Fixed JSON signature file validation issues Database Rebuild - Improved signature database rebuild process for corrupted installations Signature Consistency - Ensured consistent signature counts across installations Improved Error Handling - Better error messages for malformed signature JSON files Database Management - More robust signature import and validation process [1.9.2] - 2025-08-08 Added Extended Archive Format Support - Implemented support for additional archive formats (closes #12): 7z archives using py7zr library RAR archives using rarfile library DEB packages (Debian/Ubuntu) with python-debian or ar command RPM packages (Red Hat/Fedora) with rpm2cpio or 7-Zip fallback Optional Archive Dependencies - New [archives] install option for extended format support Intelligent Format Detection - Automatic detection of required tools for each format Fallback Extraction - Uses 7-Zip as fallback when Python libraries unavailable Improved Archive Extractor - Modular extraction methods for each archive type Error Handling - Graceful degradation when optional tools not available Documentation - Updated README with new format support and installation options [1.9.1] - 2025-08-08 Added KISS BOM Export Format - New simplified SBOM export format for easy integration (Issue #5) Codec Detection Signatures - Added comprehensive multimedia codec detection: H.264/AVC video codec (14 signatures) H.265/HEVC video codec (11 signatures) AAC audio codec (15 signatures) Dolby Audio/Video (AC3/EAC3/DD+) (18 signatures) AV1 video codec (13 signatures) Library Signatures - Added GLib (30 signatures) and updated GStreamer (30 signatures) Androguard APK Extractor - Optional advanced APK analysis using Androguard library Universal Archive Support - Improved extraction for vpkg, embedded systems, and custom archives Recursive Archive Extraction - Deep inspection of nested archives with intelligent prioritization Fixed Androguard Optional Dependency - Removed warning messages when Androguard not installed Codec Pattern Matching - Fixed MIME type and codec string extraction in binary analyzer Direct Matcher Improvements - Made pattern matching more permissive for codec identifiers Archive Extractor - Fixed recursive extraction and intelligent file prioritization Improved vpkg File Support - Now correctly detects GStreamer, codecs, and plugins in vpkg packages Binary String Extraction - Preserves MIME types and codec-related strings for better detection Component Detection - Multimedia files now show accurate codec and library components [1.9.0] - 2025-08-08 Added Comprehensive Library Signatures - Added detection support for 5 new system libraries: libcap (POSIX capabilities library) - 14 signatures Expat XML Parser - 26 signatures LZ4 compression library - 25 signatures XZ Utils/LZMA compression - 13 signatures WebP image compression - 26 signatures Signature Database Expansion - Increased to 1,197 total signatures covering 173 components Missing Component Signatures - Created signatures for cURL (30), Cairo (30), and Opus (30) audio codec Fixed Major False Positive Fixes : Removed PCoIP SDK false positives in unrelated libraries Removed Foxit PDF SDK false positives in Linux libraries Fixed Qt5 Framework incorrectly detected in libcrypto.so (cryptographic pattern conflicts) Removed Microsoft OLE Automation false positives in FreeType and FFmpeg OpenSSL False Positive - Fixed libcom_err.so (Kerberos library) incorrectly detecting as OpenSSL Signature Quality Improvements : Replaced generic Qt5 cryptographic patterns (SHA3, Keccak) with Qt-specific class patterns Removed overly generic patterns causing cross-library false positives Cleaned up empty signature files that were causing import issues Improved Detection Accuracy - Overall accuracy improved to ~85% across test libraries Library Self-Detection - All major libraries now correctly detect themselves with 100% confidence Cross-SSL Library Detection - Acceptable cross-detection between SSL libraries (OpenSSL, wolfSSL) as they implement similar cryptographic functions Signature Verification - Added verification mechanism to ensure signature files match database entries Changed Signature Format Consistency - Converted old format signature files to new component-based format Database Rebuild Process - Improved to handle format conversions and skip non-signature files [1.8.9] - 2025-08-08 Added License Detection System - Comprehensive license detection using pattern matching for MIT, Apache-2.0, GPL, BSD, LGPL, and ISC licenses New license Command - Dedicated command for license analysis with compatibility checking and multiple output formats SPDX Identifier Support - Automatic detection of SPDX license identifiers with 100% confidence License Compatibility Checking - Identifies incompatible license combinations (e.g., GPL-2.0 vs GPL-3.0) Integrated License Detection - Added --license-focus and --license-only flags to the analyze command Multiple Output Formats - License reports in Table, JSON, CSV, and Markdown formats License File Recognition - Automatic detection of LICENSE, COPYING, and similar files Embedded License Detection - Finds licenses in source code comments and headers Features Pattern-based detection for 7 major open-source licenses License categorization (copyleft, weak copyleft, permissive) Compatibility warnings for mixed license scenarios Works on single files, directories, and archives Python API support for programmatic license analysis [1.8.8] - 2025-08-08 Added Static Library Support - Full AR archive parsing and analysis for .a and .lib files with per-object file tracking Source Attribution - Track which symbols come from which object files within static libraries (e.g., _CRYPTO_malloc@libcrypto-lib-pvkfmt.o ) BSD AR Format Support - Handle both standard and BSD-style extended names in AR archives OpenSSL-Specific Signatures - 35 highly specific patterns for accurate OpenSSL detection without false positives Signature Optimization Script - Tool for removing generic patterns that cause false positives between similar libraries Fixed OpenSSL False Positives - Eliminated incorrect FFmpeg (was 85.6%) and wolfSSL (was 84%) detections in OpenSSL libraries JSON/CSV Console Output - Fixed mixing of summary text with JSON/CSV output when not saving to file Improved OpenSSL Detection - Increased accuracy from 78% to 92.8% confidence with optimized signatures Static Library Analysis - Can now analyze individual object files within archives (e.g., 62 objects in libcrypto.a) Component Attribution - Better understanding of which parts of a library contribute which symbols [1.8.7] - 2025-08-07 Added Zstandard Archive Support - Full support for .zst , .tar.zst , and .vpkg compressed archives for analysis and inventory extraction System zstd Fallback - Automatic fallback to system zstd command when Python library can't handle certain frame formats GStreamer Signatures - Added 17 high-quality signatures for GStreamer multimedia framework detection Hermes React Native Signatures - Added 25 signatures for Hermes JavaScript engine including bytecode magic detection Native Hermes Bytecode Inspector - Pure Python implementation for analyzing Hermes bytecode files without external dependencies Hermes Decompiler Script - Basic decompilation and analysis tool for React Native Hermes bundles Fixed Signature Creation from Binaries - Fixed component name matching to handle \"lib\" prefix variations (e.g., libcap vs cap) Inventory Extraction Tests - Fixed all 11 tests by adding missing total_directories field and correcting function references API Consistency - Fixed analyze_directory to return BatchAnalysisResult consistently across all analyzers CLI Tests - Fixed all 12 CLI tests by properly handling BatchAnalysisResult in single and batch file analysis Microsoft OLE False Positives - Removed 16 overly generic patterns (24.6% reduction) that caused false detections Qt5 False Positives - Removed 28 generic patterns (28% reduction) that could cause legal issues PCoIP SDK False Positives - Removed 519 generic patterns (73.6% reduction) eliminating widespread false detections Improved Code Organization - Eliminated 400+ lines of duplicate code through BaseAnalyzer refactoring Binary String Extraction - Centralized binary string extraction logic in shared utility module Test Coverage - Added comprehensive tests for Zstandard support (5 new tests) Detection Accuracy - Dramatically reduced false positives across Microsoft OLE, Qt5, and PCoIP SDK components Signature Quality - Cleaned up over 563 problematic patterns across multiple components Technical New Module - binarysniffer.core.base_analyzer for shared analyzer functionality New Module - binarysniffer.utils.binary_strings for centralized binary string extraction New Module - binarysniffer.extractors.hermes for native Hermes bytecode extraction New Tests - tests/test_zstandard_support.py for Zstandard archive validation Archive Extensions - Added .zst , .tar.zst , .tzst , and .vpkg to supported formats New Signatures - signatures/gstreamer.json with multimedia framework patterns New Signatures - signatures/hermes.json with React Native JavaScript engine patterns Cleanup Scripts - Added scripts for removing generic patterns from Microsoft OLE, Qt5, and PCoIP SDK Analysis Tools - scripts/hermes_decompiler.py for Hermes bytecode inspection and basic decompilation Hermes Support - Native parsing of Hermes header, string table extraction, and framework detection [1.8.6] - 2025-08-07 Added CycloneDX SBOM Export - Generate industry-standard SBOMs for security and compliance toolchains Package Inventory Extraction - New inventory command for comprehensive package analysis File Path Tracking - Evidence now includes file paths for component location tracking File Metadata Export - Extract MIME types, compression ratios, file sizes, timestamps from archives Hash Calculation - Generate MD5, SHA1, SHA256 hashes for all files in packages Fuzzy Hash Support - Calculate TLSH and ssdeep hashes for similarity analysis Component Detection in Archives - Run OSS detection on individual files within packages Multiple Export Formats - JSON, CSV, CycloneDX, tree visualization, and summary reports Enhanced CSV Export - Rich CSV output with hashes, MIME types, and component detection results Feature Extraction Export - Save extracted features for signature recreation with --save-features API Feature Parity - All CLI inventory features available via Python API Improved File Analysis API - Added include_hashes and include_fuzzy_hashes parameters to analyze_file() Inventory Performance - Selective analysis options to balance speed vs comprehensiveness Archive Metadata - Relative paths, compression ratios, and CRC checksums for all files Fixed Test Suite - Fixed 7 failing tests for better stability Archive Extractor Test - Corrected APK native library detection expectations Directory Analysis - Properly excludes .binarysniffer directory from recursive scans Technical New Module - binarysniffer.output.cyclonedx_formatter for SBOM generation New Module - binarysniffer.utils.inventory for package enumeration Enhanced Module - binarysniffer.utils.file_metadata for hash calculations Evidence Enhancement - ComponentMatch evidence now includes file paths API Methods - extract_package_inventory() with full parameter control CLI Formats - Added cyclonedx and cdx output formats CLI Flags - --analyze , --include-hashes , --include-fuzzy-hashes , --detect-components , --save-features [1.8.4] - 2025-08-06 Fixed Eliminated .NET Core false positives - Removed 59 overly generic patterns (90.8% reduction) Reduced wolfSSL false detections - Removed 32 generic crypto patterns that appear in many libraries No more type name collisions - Removed generic patterns like int32, float64, libc that match everywhere Added Ultra-aggressive signature cleaning - New script scripts/ultra_aggressive_clean.py for deep pattern cleaning Better pattern validation - Filters out basic types, generic prefixes, and common C library functions Improved .NET Core signatures - Reduced from 65 to 6 highly specific patterns wolfSSL signatures - Kept only wolfSSL-specific patterns (159 remaining from 191) Detection accuracy - FFmpeg and other binaries no longer show incorrect .NET or wolfSSL detections Technical Pattern filtering - Removes int/float types, generic prefixes (prefix1-7), macOS standard symbols Signature quality - Only truly component-specific patterns remain in signatures Testing verified - No false positives in FFmpeg, libcap, and other test binaries [1.8.3] - 2025-08-06 Added Git hooks for problematic word detection - Prevent commits with AI references and other problematic content Comprehensive pattern checking - Detect AI/assistant references, hardcoded secrets, TODOs, inappropriate language Pre-commit and commit-msg hooks - Check both staged files and commit messages before allowing commits Customizable word patterns - Easy to add/remove patterns in .githooks/check-problematic-words.sh Security Automated secret detection - Hooks now check for hardcoded passwords, API keys, and tokens Confidential content blocking - Prevent accidental commit of internal/confidential markers Technical Git hooks directory - .githooks/ directory with reusable hook scripts Automatic hook configuration - Repository configured to use .githooks/ via core.hooksPath Documentation - Added .githooks/README.md with installation and usage instructions [1.8.2] - 2025-08-06 Added ALSA signature - Comprehensive Advanced Linux Sound Architecture detection with 48 specific patterns Aggressive signature cleaning - New script to remove overly generic patterns causing false positives Verbose evidence tracking - Enhanced -ve flag now shows which files within archives triggered matches Fixed Major false positive reduction - Removed 16,090 generic patterns from signatures that caused incorrect detections Archive content tracking - Verbose mode now properly displays which files in archives contain matches Signature quality - Eliminated problematic patterns like \"copy\", \"exit\", \"path\", \"bool\" that match everywhere Improved Detection accuracy - Dramatically reduced false positives (e.g., .NET Core no longer incorrectly detected in FFmpeg) PCoIP SDK - Removed 4,312 generic patterns wolfSSL - Removed 3,143 generic patterns .NET Core - Removed 2,064 generic patterns FFmpeg - Removed 3,503 generic patterns from BSA signature Qt5 - Cleaned to only 13 high-quality patterns Technical New tool - scripts/aggressive_clean_signatures.py for comprehensive pattern filtering Pattern validation - Filters patterns <4 chars, common C functions, generic programming terms Safe prefix preservation - Keeps library-specific prefixes like snd_ , av_ , ff_ , png_ [1.8.1] - 2025-08-06 Fixed Database initialization on clean install - Fixed critical issue preventing tool from working on new systems Directory creation - Database parent directory is now created automatically before initialization Signature import method - Fixed enhanced analyzer calling non-existent auto_import() method Improved Installation reliability - Tool now works correctly on first install without manual intervention Error handling - Better error messages when database cannot be created Documentation - Added comprehensive TLSH fuzzy matching examples to README [1.8.0] - 2025-08-06 Added TLSH Fuzzy Matching - Detect similar/modified OSS components using locality-sensitive hashing Enhanced FFmpeg signature - 2,000 high-quality patterns covering versions 4.4 to 6.0 with TLSH hash CLI options for fuzzy matching - New --use-tlsh and --tlsh-threshold parameters for similarity detection TLSH signature store - Manage and query TLSH hashes for fuzzy component matching Optional TLSH addition script - Tool to add TLSH hashes to existing signatures ( scripts/add_tlsh_to_signatures.py ) Improved Detection accuracy - Find modified, recompiled, or patched OSS components that pattern matching might miss Signature generation - Automatically generates TLSH hashes for new signatures Version detection - Better identification of different versions of the same library Component matching - Merged fuzzy and pattern matching for comprehensive detection Technical New dependency - Added python-tlsh as optional dependency ( pip install binarysniffer[fuzzy] ) New module - binarysniffer.hashing.tlsh_hasher for TLSH operations Documentation - Comprehensive TLSH guide in docs/TLSH_FUZZY_MATCHING.md [1.7.0] - 2025-08-06 Added MSI installer support - Extract and analyze Windows Installer packages (.msi files) with 7-Zip PKG installer support - Extract and analyze macOS installer packages (.pkg files) with 7-Zip DMG support - Extract and analyze macOS disk images (.dmg files) with 7-Zip New signatures - Added Qt5 Framework, OpenCV, Foxit PDF SDK, wolfSSL, PCoIP SDK, and .NET Core Runtime Logging improvements - Clean logging output and debug features from GitHub issues #6 and #3 Version display - Show version in main help output for better user experience Improved Installer analysis - Significantly improved detection rates for Windows and macOS installers Archive extraction - Enhanced extraction capabilities for various installer formats Documentation - Updated README with comprehensive optional tools section Fixed Signature cleanup - Removed unnecessary vendor-specific signatures [1.6.6] - 2025-08-06 Improved Pipeline and tests - Improved pipeline and rebuilt tests [1.6.5] - 2025-08-06 Added New component signatures - Added multiple new signatures for improved detection coverage Script improvements - Enhanced signature import and management scripts Improved Signature cleanup - Refined and optimized existing signatures for better accuracy LIEF and DEX parsers - Enhanced binary analysis with LIEF library and Android DEX support Detection accuracy - Continued improvements to component detection algorithms Fixed Script cleanup - Fixed and optimized signature processing scripts [1.6.4] - 2025-08-06 Changed Signature metadata optimization - Removed proprietary references from signature source descriptions Cleaner attribution - Updated signature metadata to use generic \"APK analysis\" instead of specific app references Improved Professional metadata - All signature files now have cleaner, more professional source attributions Signature consistency - Standardized metadata format across all signature files [1.6.3] - 2025-08-06 Added Deterministic mode by default - Tool now runs with PYTHONHASHSEED=0 automatically for consistent results Non-deterministic flag - Added --non-deterministic flag to disable deterministic mode when needed Duplicate log prevention - Added DuplicateFilter to prevent the same log messages from appearing twice Changed Default confidence threshold - Changed from 0.8 to 0.5 to detect more components like Opus codec Removed bloom filter tier - Disabled probabilistic bloom filters for fully deterministic results Optimized direct matching - Improved performance from 5.3s to 1.0s (5x faster) using pre-computed indices Fixed SQL query ordering - Added ORDER BY clauses to ensure consistent database query results Non-deterministic iterations - Fixed all dictionary and set iterations to use sorted order Configuration loading - Prevented multiple Config instances from setting up duplicate loggers Performance 5x faster analysis - Direct matcher optimization reduces analysis time from 5.3s to 1.0s Memory efficient - Removed bloom filter memory overhead while maintaining fast lookups Deterministic results - Consistent component detection across multiple runs [1.6.2] - 2025-08-05 Investigated Root cause of non-determinism - Identified that Python's hash randomization (PYTHONHASHSEED) causes inconsistent results across CLI invocations Bloom filter probabilistic behavior - Bloom filters inherently have false positives that vary with different hash seeds Fixed Sorted dictionary iterations - Made component_scores iteration deterministic in DirectMatcher Sorted set conversions - Fixed non-deterministic list creation from sets in multiple places Deterministic final sorting - Added component name as secondary sort key for consistent ordering Deterministic feature ordering - Sort unique features before processing in ProgressiveMatcher Added Deterministic bloom filter implementation - Created new implementation using SHA-256 instead of Python's hash() Known Issues Component detection still shows some inconsistency due to bloom filter's probabilistic nature Running with PYTHONHASHSEED=0 provides consistent results Consider making bloom filter tier optional or removing it for fully deterministic behavior [1.6.1] - 2025-08-05 Fixed Progress bar removed - Removed tqdm progress bar from DirectMatcher that was causing display issues Matcher initialization order - Fixed issue where DirectMatcher was initialized before database was populated Deterministic file ordering - Archive extraction now uses sorted file lists for consistent results Order-preserving deduplication - Replaced set() with dict.fromkeys() to maintain consistent string order Known Issues Component detection still shows some inconsistency across runs (under investigation) Duplicate log messages appear in CLI output [1.6.0] - 2025-08-05 Added LIEF-based extractors - Enhanced binary analysis using LIEF library for ELF/PE/Mach-O formats DEX file extractor - Specialized extractor for Android DEX bytecode analysis New component signatures - Added signatures for OkHttp, OpenSSL, SQLite, ICU, FreeType, and WebKit Progress indication - Added tqdm progress bars for long analysis operations Substring matching - Direct matcher now supports partial string matching for better detection Improved APK analysis - Dramatically improved component detection in Android APKs (from 1 to 25+ components) Feature extraction - Increased from 6,741 to 152,640 features for complex archives like APKs Bloom filter capacity - Increased limit from 1,000 to 100,000 features for better coverage Component name display - Fixed \"@unknown\" suffix when version is not available Matching performance - Optimized substring matching with early termination and pre-filtering Fixed Archive processing - DEX files and native libraries within APKs are now properly analyzed Feature counting - Analyzer now correctly reports total features extracted Substring matching logic - Fixed reversed logic (pattern in string, not string in pattern) Progressive matcher - Component names no longer show \"@unknown\" for unknown versions [1.5.1] - 2025-08-05 Fixed Major signature cleanup - Removed 479 generic patterns causing false positives Apache HTTP Core false positives - Removed generic HTTP patterns that matched FFmpeg Signature quality improvement - Filtered patterns shorter than 6 characters Cross-component contamination - Removed patterns appearing in 5+ components Improved Signature validation - More strict criteria for keeping patterns Library-specific prefixes - Preserved valid prefixes like av_ , x264_ , png_ Reduced false positive rate - 5.4% reduction in total signatures Statistics Total signatures before: 8,916 Total signatures after: 8,437 Apache HTTP Core: 31/65 patterns removed (47.7%) FFmpeg: Only 15/6,660 patterns removed (0.2%) SKIA: 77/268 patterns removed (28.7%) [1.5.0] - 2025-08-05 Added Integrated signature creation - New binarysniffer signatures create command Binary symbol extraction - Extract symbols using readelf, nm, and strings Smart signature generation - Automatically identifies library prefixes and functions Source code analysis - Create signatures from source code repositories Auto-detection - Automatically detects binary vs source code input Improved CLI integration - Signature creation is now part of the main tool Symbol-based signatures - Uses actual binary symbols instead of arbitrary strings Better validation - Accepts library prefixes like av_ , x264_ , png_ Usage # Create signatures from binary binarysniffer signatures create /path/to/ffmpeg --name FFmpeg --version 4.4.1 # Create from source code binarysniffer signatures create /path/to/source --name MyLib --license MIT # With full metadata binarysniffer signatures create binary --name Component \\\\ --version 1.0 --license GPL-3.0 --publisher \"Company\" \\\\ --description \"Component description\" --output custom.json [1.4.9] - 2025-08-05 Added Signature quality validation - New SignatureValidator class filters out generic patterns Automatic filtering - DirectMatcher now rejects overly generic signatures like \"react\", \"log\", \"test\" Quality metrics - 1,153 problematic patterns identified and filtered from signature database Improved Drastically reduced false positives - No more React Native detection in C++ projects Better precision - Filters short patterns (<6 chars) and common programming terms Smarter matching - Accepts specific patterns with special characters, mixed case, or namespaces Fixed Generic signature problem - Signatures like \"React\", \"apache\", \"get\", \"set\" no longer cause false matches Cross-technology false positives - C++ projects no longer show JavaScript/mobile components [1.4.8] - 2025-08-05 Improved Higher default threshold - Increased from 0.5 to 0.7 for better precision ZIP file filtering - Added technology filtering for ZIP files containing binaries Mobile component filtering - React Native, Firebase, and other mobile components now filtered from ZIP files Fixed False positives in ZIP files - ZIP files with native binaries no longer show mobile-specific components [1.4.7] - 2025-08-05 Improved Reduced false positives - Increased default threshold from 0.3 to 0.5 for better accuracy Technology filtering - Automatically filters incompatible components (e.g., no Android/iOS components in native binaries) Archive extraction - Fixed single-file archive extraction to use all features instead of limiting to 100 strings Context validation - Binary type now influences component detection to prevent impossible matches Fixed ZIP file analysis - Single-file archives like ffmpeg-4.4.1-linux-64.zip now properly analyzed with full feature extraction False positive filtering - Removed mobile-specific components (Firebase, React Native, etc.) from native binary results [1.4.6] - 2025-08-05 Improved Enhanced mode is now default - All analysis now uses dual matching strategy (ProgressiveMatcher + DirectMatcher) for superior detection accuracy Lower default threshold - Reduced from 0.5 to 0.3 for better component detection without requiring manual threshold adjustment Simplified CLI interface - Removed --enhanced flag as enhanced detection is always active Multi-language regex patterns - Enhanced SourceCodeExtractor with comprehensive language support Pattern coverage - Achieved 100% test coverage across all 9 supported programming languages Language-specific parsing - Added support for Ruby methods without parentheses, C/C++ macros, Rust const syntax, Go imports and structs, C# using statements, C++ method declarations, and Kotlin functions Detection accuracy - Improved success rate from 85.4% to 100% for source code symbol extraction Added Enhanced function patterns - 6 regex patterns covering Python, JavaScript, Go, Rust, Kotlin, Java/C#/C++ Comprehensive class patterns - 5 patterns for class, struct, interface, Go types, and enums Extended import patterns - 8 patterns supporting Python, JS, Rust, C/C++, Go, C#, Kotlin imports Robust constant patterns - 5 patterns for general constants, assignments, C macros, Rust, and Kotlin Breaking Changes Enhanced mode always enabled - The --enhanced flag has been removed as enhanced detection is now the default behavior [1.4.5] - 2025-08-05 Fixed Release pipeline - Fixed automated release and deployment pipeline issues [1.4.0] - 2025-08-05 Fixed Complete repository reset - Fresh git history with single clean commit Professional contributor attribution - All commits properly attributed to Oscar Valenzuela B Clean release process - New major version with proper identity management Features License extraction from database - DirectMatcher properly queries license column Evidence formatting - Clear display of pattern counts in evidence column License information display - All detected components show their proper licenses Enhanced detection mode - Improved component detection accuracy (42x improvement on APK analysis) Comprehensive signature database - 8,852+ signatures from 129+ components Updated Project metadata - Updated author information and repository URLs Documentation links - Fixed project URLs to point to correct GitHub repository 1.3.0 - 2025-08-04 Fixed License extraction from database - DirectMatcher now properly queries license column Component name display - No more \"@unknown\" suffix for components without versions Evidence formatting - Clear display of pattern counts in evidence column Enhanced License information display - All detected components now show their proper licenses Database queries - Optimized to fetch all component metadata including licenses Output clarity - Better formatted evidence showing number of matched patterns Technical Fixes Fixed DirectMatcher SQL query to include license column Updated component mapping to extract license from correct database column Improved component name formatting to exclude redundant version info 1.2.0 - 2025-08-04 Added Enhanced Detection Mode New --enhanced CLI flag for improved component detection accuracy ImprovedBinaryExtractor with more permissive string extraction (min_length=4, max_strings=50000) DirectMatcher implementation bypassing bloom filters for exhaustive string matching EnhancedBinarySniffer analyzer combining progressive and direct matching strategies Symbol extraction patterns for common library prefixes and function names Comprehensive User Guide at docs/USER_GUIDE.md with examples and troubleshooting Enhanced Signatures Expanded libpng signatures from 10 to 20 patterns for better detection New libjpeg-enhanced.json with 25 comprehensive patterns Enhanced signature metadata with confidence thresholds and contexts Enhanced APK analysis accuracy improved from 1 to 42 components detected (42x improvement) String extraction with reduced filtering for better signature preservation Confidence scoring with adjusted thresholds (0.3 default for enhanced mode) Component detection for libraries like libpng, libxml2, FFMPEG, Firebase Crashlytics, SKIA Evidence reporting with signature counts and match methods in output Fixed Binary extractor filtering removing potential signatures Bloom filter false negatives preventing component detection Import issues between analyzer modules Component lookup in DirectMatcher using proper database queries Technical Improvements Dual matching strategy for better accuracy vs performance tradeoff Configurable extraction parameters for different analysis needs Merged match results keeping highest confidence scores Better error handling in enhanced analyzer Documentation Comprehensive User Guide covering installation, usage, examples, and troubleshooting Enhanced detection mode explanation and performance impact Output format documentation for table, JSON, and CSV formats Performance optimization tips for large-scale analysis Known Issues Code duplication between binary.py and binary_improved.py (~90% similar) Analyzer duplication between analyzer.py and analyzer_enhanced.py Unused imports in several modules (shutil, os, Set) Inconsistent error handling between analyzers 1.1.0 - 2025-08-04 Added Archive Support Complete archive file support for ZIP, JAR, APK, IPA, TAR, and other formats Android APK analysis with AndroidManifest.xml parsing, DEX file detection, and native library extraction iOS IPA analysis with Info.plist parsing, framework detection, and executable identification Java archive support with MANIFEST.MF parsing and package structure analysis Python package support for wheels (.whl) and eggs (.egg) with metadata extraction Nested archive processing for archives containing other archives Archive-specific metadata extraction including package names, versions, and dependencies CTags Integration Universal CTags support for enhanced source code analysis when available Graceful fallback to regex-based extraction when CTags is not installed Multi-language support including C/C++, Python, Java, JavaScript, Go, Rust, and more Semantic symbol extraction including functions, classes, structs, and constants Optional integration via ExtractorFactory configuration Signature Migration BSA signature database migration supporting 90+ open source components Real-world signature database with thousands of component signatures Automated migration scripts for converting legacy signature formats Component metadata preservation including licenses, publishers, and versions Efficient signature indexing with trigram support for fast substring matching Enhanced Testing Comprehensive test suite for archive extraction (10/10 tests passing) Integration tests for end-to-end APK/IPA/JAR analysis CTags integration testing with fallback verification Migration verification ensuring signature database functionality Enhanced ExtractorFactory improvements with configurable extractor selection Source code extraction with improved regex patterns and error handling Error handling throughout archive processing with graceful degradation Performance optimizations for large archive processing with file limits Logging improvements with detailed debug information for troubleshooting Fixed Circular import issues in archive extractor factory integration Regex pattern corrections for JavaScript require statements Metadata handling ensuring proper initialization across all extractors TAR file type detection with proper compound extension handling Technical Improvements Plugin architecture for extractors with easy extensibility Memory management for large archive processing with limits and cleanup Type safety improvements with proper dataclass usage Test coverage expansion with comprehensive edge case handling Documentation Archive format support documentation CTags installation and usage guidelines Migration script usage examples API documentation for new extractor interfaces 1.0.0 - 2025-08-03 Added Initial release with core functionality Three-tier progressive matching system SQLite-based signature storage with ZSTD compression MinHash LSH indexing for fast similarity detection Bloom filter pre-filtering for performance CLI and Python library interfaces Basic file type support (binaries, source code) Trigram indexing for substring matching Component detection and confidence scoring Features Fast local analysis with <100MB memory usage Multi-format binary analysis Source code feature extraction License and component identification Batch processing capabilities JSON output format Configurable confidence thresholds","title":"Changelog"},{"location":"binarysniffer/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"binarysniffer/CHANGELOG/#1112-2025-10-27","text":"","title":"[1.11.2] - 2025-10-27"},{"location":"binarysniffer/CHANGELOG/#fixed","text":"Dependency Resolution - Fixed dependency compatibility issues with renamed packages Ensured clean migration from semantic-copycat-oslili to osslili>=1.5.6 Ensured clean migration from semantic-copycat-upmex to upmex>=1.6.7 Removed conflicting legacy package installations that caused version mismatches All integrations now properly import from updated package namespaces","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#1111-2025-10-27","text":"","title":"[1.11.1] - 2025-10-27"},{"location":"binarysniffer/CHANGELOG/#changed","text":"Dependencies Updated - Migrated from legacy semantic-copycat packages to renamed versions Updated semantic-copycat-oslili>=1.5.0 \u2192 osslili>=1.5.6 for license detection Updated semantic-copycat-upmex>=1.6.2 \u2192 upmex>=1.6.7 for package metadata extraction Updated import statements and error messages to use new package names All functionality maintained with improved dependency management","title":"Changed"},{"location":"binarysniffer/CHANGELOG/#fixed_1","text":"Progress Display - Fixed progress bar stuck at 0% for directory analysis Progress callbacks now properly track file processing Consolidated summary table for directory scans instead of individual file results File Processing - Resolved hanging issues with problematic files Added configurable timeout system (60s default) with --timeout option Automatic detection and exclusion of XML/plist metadata files Fixed processing of large files (>50MB excluded by default, use --include-large to analyze)","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#added","text":"CLI Enhancements - New options for better control and visibility --timeout - Configure per-file timeout (default: 60 seconds) --include-large / -l - Include files larger than 50MB in analysis --debug / -v - Show files being processed in real-time --skip-metadata - Skip XML/plist metadata files entirely --with-hashes - Now properly displays file hash values","title":"Added"},{"location":"binarysniffer/CHANGELOG/#improved","text":"Performance - Optimized file processing for large directories Sequential processing for large directories (>100 files) to prevent resource exhaustion Smart file filtering to skip problematic formats early Reduced timeout for metadata files (3 seconds) Documentation - Updated user guide with all new CLI options Comprehensive option descriptions and usage examples Fixed outdated references to deprecated flags License Detection - Verified OSLiLi integration functionality Successfully detects BSD, ISC, Python-2.0 licenses with high confidence (85-97%) Proper oslili_detection type matching in evidence display TLSH Fuzzy Matching - Enabled and documented TLSH support Created example TLSH signature database Comprehensive setup guide in docs/TLSH_SETUP_GUIDE.md 100% confidence matching for system binaries","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#removed","text":"Deprecated Options - Cleaned up obsolete CLI flags Removed --enhanced flag (enhanced mode is now always enabled) Fixed partially wired options to be fully functional","title":"Removed"},{"location":"binarysniffer/CHANGELOG/#1105-2025-10-19","text":"","title":"[1.10.5] - 2025-10-19"},{"location":"binarysniffer/CHANGELOG/#fixed_2","text":"Test Suite - Achieved 100% test success rate (205/205 tests passing) Fixed ONNX extractor file type detection to properly handle .pb files Fixed pickle extractor missing security methods ( validate_safe_unpickle() ) Fixed PyTorch native extractor functionality: State dict detection ( has_state_dict ) Optimizer detection ( has_optimizer ) Architecture detection (ResNet, Transformer, etc.) Suspicious operations detection via STACK_GLOBAL handling Layer counting functionality Fixed static library BSD extended names parsing bug (double subtraction issue)","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#improved_1","text":"Code Quality - Cleaned up dead code and duplicated imports Removed unused import struct from hashing utilities Consolidated duplicate import zipfile statements in UPMEX adapter Moved imports to module level for better organization Enhanced code maintainability with zero orphaned files","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#changed_1","text":"Dependencies - Updated multiple outdated dependencies to more recent versions Improved compatibility and security with latest package versions Maintained backward compatibility while upgrading core dependencies","title":"Changed"},{"location":"binarysniffer/CHANGELOG/#1101-2025-08-30","text":"","title":"[1.10.1] - 2025-08-30"},{"location":"binarysniffer/CHANGELOG/#added_1","text":"OSLiLi Integration - Enhanced license detection using osslili Automatic license detection from package metadata (package.json, pom.xml, etc.) SPDX-compliant license identifiers ML-based license matching with higher accuracy Support for license categorization (declared, detected, referenced) Integrated into archive extraction pipeline","title":"Added"},{"location":"binarysniffer/CHANGELOG/#improved_2","text":"License Detection Accuracy - Better detection rates Correctly identifies licenses from LICENSE files in archives Reduced false positives through ML-based matching TLSH fuzzy matching for license text similarity Proper detection of Apache-2.0, MIT, BSD, GPL, and other common licenses","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#fixed_3","text":"Code Quality - Removed dead code and fixed potential bugs Fixed potential None reference in analyze_licenses method Removed duplicate license detection implementations Cleaned up unused methods in integrations module Improved error handling when OSLiLi is unavailable","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#changed_2","text":"Dependencies - Added osslili as required dependency osslili >= 1.5.6 now required for license detection LicenseMatcher retained as fallback for compatibility","title":"Changed"},{"location":"binarysniffer/CHANGELOG/#1100-2025-08-15","text":"","title":"[1.10.0] - 2025-08-15"},{"location":"binarysniffer/CHANGELOG/#added_2","text":"ML Model Security Analysis System - Comprehensive security module for ML models (Issues #25, #26) New ml-scan CLI command for dedicated ML security analysis MITRE ATT&CK framework integration for threat categorization Multi-level risk assessment (SAFE, LOW, MEDIUM, HIGH, CRITICAL) Deep pickle opcode analysis without code execution Obfuscation detection using entropy analysis and pattern matching Model integrity validation with hash verification Support for multiple output formats: JSON, SARIF, Markdown, CycloneDX SBOM Malicious Pattern Detection - Extensive database of threat patterns Code execution patterns (os.system, subprocess.Popen, eval, exec) Network operation detection (socket, requests, urllib) Shell command indicators (/bin/bash, cmd.exe, reverse shells) Obfuscation techniques (base64, zlib, marshal encoding) 50+ critical threat patterns mapped to MITRE techniques Security-Enhanced SBOM - CycloneDX format with ML security metadata Risk assessment metadata in SBOM components Security indicators and recommendations ML framework detection integrated with security analysis Threat pattern evidence in component properties SARIF Output Format - CI/CD integration support Static Analysis Results Interchange Format for security tools GitHub Actions and IDE integration ready Detailed security findings with line-level precision Actionable remediation suggestions","title":"Added"},{"location":"binarysniffer/CHANGELOG/#improved_3","text":"Pickle Analysis - Enhanced detection capabilities Fixed entropy calculation for better obfuscation detection Improved STACK_GLOBAL opcode resolution Better handling of malformed pickle files Risk level assessment integrated into standard analysis ML Framework Detection - Better accuracy XGBoost detection improved to 77.3% confidence PyTorch detection at 96% confidence scikit-learn detection at 94% confidence Proper license attribution for all ML frameworks","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#fixed_4","text":"Entropy calculation error in PickleSecurityAnalyzer (float.bit_length() issue) Missing TaskProgressColumn import in CLI module Malicious pickle files now properly flagged as CRITICAL risk","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#199-2025-08-14","text":"","title":"[1.9.9] - 2025-08-14"},{"location":"binarysniffer/CHANGELOG/#added_3","text":"XGBoost Detection - New signature file for XGBoost gradient boosting framework Detects xgboost.sklearn, XGBClassifier, XGBRegressor patterns Identifies gradient boosting specific parameters (max_depth, n_estimators, learning_rate) Successfully detects XGBoost in mixed ML model files Apache-2.0 license attribution for XGBoost components Malformed File Detection - Enhanced handling of corrupted and invalid files New signature set for detecting malformed pickle files Categorizes errors: invalid opcodes, truncated files, unknown errors Provides clear WARNING classification for problematic files Tracks risk levels in metadata (malformed, error, dangerous, safe)","title":"Added"},{"location":"binarysniffer/CHANGELOG/#improved_4","text":"Enhanced Pickle Extractor - Better error handling and user feedback Distinguishes between different types of file corruption Adds specific error features for signature matching Provides suspicious_items metadata for detailed diagnostics Improved risk assessment with new \"malformed\" and \"error\" categories CLI User Experience - Clearer warnings and feedback for problematic files Table components can display warning titles and captions Special formatting for malformed file detection Risk level indicators shown before component tables Better visual distinction between normal detections and warnings","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#fixed_5","text":"Mixed ML model files (e.g., XGBoost models) now properly detected instead of showing \"No components\" Malformed pickle files now show clear WARNING instead of generic error messages Classification column properly handles both licenses and security warnings","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#198-2025-08-14","text":"","title":"[1.9.8] - 2025-08-14"},{"location":"binarysniffer/CHANGELOG/#added_4","text":"SafeTensors Format Parser - New extractor for secure tensor storage format Validates SafeTensors format integrity and detects tampering Identifies format violations that could indicate file manipulation Detects injection attempts via unexpected metadata keys Flags oversized tensors (>1B elements) as potential data exfiltration risks Identifies suspicious tensor names (backdoor, trigger, hidden, etc.) Detects base64-like names that might indicate obfuscation Extracts framework metadata (PyTorch, TensorFlow, JAX, Transformers) Recognizes model architectures (BERT, LLaMA, ResNet, ViT, CLIP, etc.) Provides comprehensive security assessment for supply chain verification SafeTensors Security Signatures - New signature sets for SafeTensors validation safetensors-format.json: Core SafeTensors format signatures safetensors-pytorch.json: PyTorch model patterns safetensors-transformers.json: Hugging Face Transformers patterns safetensors-security.json: Security and tampering detection patterns","title":"Added"},{"location":"binarysniffer/CHANGELOG/#198-2025-08-14_1","text":"","title":"[1.9.8] - 2025-08-14"},{"location":"binarysniffer/CHANGELOG/#added_5","text":"ONNX Model Parser - New extractor for ONNX (Open Neural Network Exchange) format models (addresses #22) Works with or without onnx library (pattern-based fallback) Detects source frameworks (PyTorch, TensorFlow, sklearn, XGBoost, etc.) Identifies model architectures (ResNet, BERT, YOLO, EfficientNet, etc.) Extracts and analyzes ONNX operators (Conv, Attention, LSTM, etc.) Detects suspicious custom operators and malicious patterns Provides security risk assessment (safe, suspicious, dangerous) Extracts model metadata (producer, version, parameters, size) 100% detection rate on suspicious ONNX models ONNX Security Signatures - New signature sets for ONNX model analysis onnx-security.json: Patterns for detecting security risks onnx-pytorch.json: PyTorch-exported ONNX models onnx-tensorflow.json: TensorFlow-exported ONNX models onnx-architectures.json: Common model architectures","title":"Added"},{"location":"binarysniffer/CHANGELOG/#197-2025-08-14","text":"","title":"[1.9.7] - 2025-08-14"},{"location":"binarysniffer/CHANGELOG/#added_6","text":"Pickle File Parser - New extractor for ML model security analysis (closes #21) Detects malicious pickle operations without executing code Identifies dangerous imports (os.system, subprocess, eval, exec, socket, etc.) Recognizes ML frameworks (sklearn, PyTorch, TensorFlow, XGBoost, LightGBM, etc.) Provides risk assessment levels (safe, suspicious, dangerous) Handles all pickle protocol versions (0-5) Detects REDUCE, BUILD, INST, OBJ, and other code execution opcodes Handles both GLOBAL and STACK_GLOBAL opcodes for import detection Normalizes platform-specific imports (posix.system \u2192 os.system) 100% detection rate on real-world malicious pickle attacks ML Security Signatures - New signature sets for ML model analysis pickle-malicious.json: Patterns for detecting malicious pickle operations sklearn.json: Signatures for scikit-learn models pytorch.json: Signatures for PyTorch models Safe Unpickle Validation - New method to check if pickle files are safe to load","title":"Added"},{"location":"binarysniffer/CHANGELOG/#changed_3","text":"Documentation - Clarified that automated signature extraction from package managers is out of scope for the CLI tool Updated CONTRIBUTING.md to note this feature will be implemented in a separate scanning orchestrator Updated docs/SIGNATURE_MANAGEMENT.md with similar clarification about scope limitations","title":"Changed"},{"location":"binarysniffer/CHANGELOG/#security","text":"ML Model Security - Can now detect NullifyAI-style attacks and other malicious ML model backdoors Comprehensive Threat Detection - Detects reverse shells, data exfiltration, code execution, and obfuscated payloads in pickle files","title":"Security"},{"location":"binarysniffer/CHANGELOG/#196-2025-08-13","text":"","title":"[1.9.6] - 2025-08-13"},{"location":"binarysniffer/CHANGELOG/#added_7","text":"Signature Collision Detection - New system to identify and resolve pattern conflicts between components Implemented SignatureCollisionDetector for cross-signature pattern analysis Added --check-collisions flag to analyze pattern overlaps Added --interactive mode for guided collision resolution Added --collision-threshold to control sensitivity (default: 2 patterns) Smart severity levels: critical (5+ components), high (3-4), medium (2 unrelated), low (2 related) Recognizes related component families (FFmpeg, OpenSSL, Qt, etc.) Automatic Generic Word Filtering - Filters 100+ common programming terms to prevent false positives Automatically removes generic patterns like \"error\", \"debug\", \"init\", \"handler\", etc. Preserves library-specific prefixes (av_, ssl_, qt_, etc.) Signature Deduplication - All signatures are now automatically deduplicated during generation Enhanced Test Coverage - Added comprehensive test suite for signature validation","title":"Added"},{"location":"binarysniffer/CHANGELOG/#improved_5","text":"Signature Quality - Significantly reduced false positives through automatic filtering Documentation - Updated signature management docs with collision detection features","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#195-2025-08-11","text":"","title":"[1.9.5] - 2025-08-11"},{"location":"binarysniffer/CHANGELOG/#fixed_6","text":"Signature Status Command - Fixed pattern counting to handle both \"signatures\" and \"patterns\" keys in verification OpenSSL Signatures - Merged openssl.json and openssl-specific.json into single file with 135 patterns","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#improved_6","text":"Signature Organization - Eliminated redundant signature files for cleaner structure Status Display - No more false mismatch warnings for properly imported signatures","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#194-2025-08-11","text":"","title":"[1.9.4] - 2025-08-11"},{"location":"binarysniffer/CHANGELOG/#fixed_7","text":"Codec Signature Import - Fixed critical bug where codec signatures (H.264, AAC, Dolby, etc.) were not being imported JSON Pattern Support - SignatureManager now handles both \"signatures\" and \"patterns\" keys in JSON files Multimedia Detection - Now properly detects GStreamer, GLib, and all video/audio codecs in packages","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#improved_7","text":"Signature Count - Increased from 1,193 to 1,324 signatures with proper codec imports Detection Accuracy - Significantly improved detection of multimedia components in vpkg and archive files README - Simplified Features section and removed version annotations","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#193-2025-08-11","text":"","title":"[1.9.3] - 2025-08-11"},{"location":"binarysniffer/CHANGELOG/#fixed_8","text":"Signature Database Corruption - Fixed JSON signature file validation issues Database Rebuild - Improved signature database rebuild process for corrupted installations Signature Consistency - Ensured consistent signature counts across installations","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#improved_8","text":"Error Handling - Better error messages for malformed signature JSON files Database Management - More robust signature import and validation process","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#192-2025-08-08","text":"","title":"[1.9.2] - 2025-08-08"},{"location":"binarysniffer/CHANGELOG/#added_8","text":"Extended Archive Format Support - Implemented support for additional archive formats (closes #12): 7z archives using py7zr library RAR archives using rarfile library DEB packages (Debian/Ubuntu) with python-debian or ar command RPM packages (Red Hat/Fedora) with rpm2cpio or 7-Zip fallback Optional Archive Dependencies - New [archives] install option for extended format support Intelligent Format Detection - Automatic detection of required tools for each format Fallback Extraction - Uses 7-Zip as fallback when Python libraries unavailable","title":"Added"},{"location":"binarysniffer/CHANGELOG/#improved_9","text":"Archive Extractor - Modular extraction methods for each archive type Error Handling - Graceful degradation when optional tools not available Documentation - Updated README with new format support and installation options","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#191-2025-08-08","text":"","title":"[1.9.1] - 2025-08-08"},{"location":"binarysniffer/CHANGELOG/#added_9","text":"KISS BOM Export Format - New simplified SBOM export format for easy integration (Issue #5) Codec Detection Signatures - Added comprehensive multimedia codec detection: H.264/AVC video codec (14 signatures) H.265/HEVC video codec (11 signatures) AAC audio codec (15 signatures) Dolby Audio/Video (AC3/EAC3/DD+) (18 signatures) AV1 video codec (13 signatures) Library Signatures - Added GLib (30 signatures) and updated GStreamer (30 signatures) Androguard APK Extractor - Optional advanced APK analysis using Androguard library Universal Archive Support - Improved extraction for vpkg, embedded systems, and custom archives Recursive Archive Extraction - Deep inspection of nested archives with intelligent prioritization","title":"Added"},{"location":"binarysniffer/CHANGELOG/#fixed_9","text":"Androguard Optional Dependency - Removed warning messages when Androguard not installed Codec Pattern Matching - Fixed MIME type and codec string extraction in binary analyzer Direct Matcher Improvements - Made pattern matching more permissive for codec identifiers Archive Extractor - Fixed recursive extraction and intelligent file prioritization","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#improved_10","text":"vpkg File Support - Now correctly detects GStreamer, codecs, and plugins in vpkg packages Binary String Extraction - Preserves MIME types and codec-related strings for better detection Component Detection - Multimedia files now show accurate codec and library components","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#190-2025-08-08","text":"","title":"[1.9.0] - 2025-08-08"},{"location":"binarysniffer/CHANGELOG/#added_10","text":"Comprehensive Library Signatures - Added detection support for 5 new system libraries: libcap (POSIX capabilities library) - 14 signatures Expat XML Parser - 26 signatures LZ4 compression library - 25 signatures XZ Utils/LZMA compression - 13 signatures WebP image compression - 26 signatures Signature Database Expansion - Increased to 1,197 total signatures covering 173 components Missing Component Signatures - Created signatures for cURL (30), Cairo (30), and Opus (30) audio codec","title":"Added"},{"location":"binarysniffer/CHANGELOG/#fixed_10","text":"Major False Positive Fixes : Removed PCoIP SDK false positives in unrelated libraries Removed Foxit PDF SDK false positives in Linux libraries Fixed Qt5 Framework incorrectly detected in libcrypto.so (cryptographic pattern conflicts) Removed Microsoft OLE Automation false positives in FreeType and FFmpeg OpenSSL False Positive - Fixed libcom_err.so (Kerberos library) incorrectly detecting as OpenSSL Signature Quality Improvements : Replaced generic Qt5 cryptographic patterns (SHA3, Keccak) with Qt-specific class patterns Removed overly generic patterns causing cross-library false positives Cleaned up empty signature files that were causing import issues","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#improved_11","text":"Detection Accuracy - Overall accuracy improved to ~85% across test libraries Library Self-Detection - All major libraries now correctly detect themselves with 100% confidence Cross-SSL Library Detection - Acceptable cross-detection between SSL libraries (OpenSSL, wolfSSL) as they implement similar cryptographic functions Signature Verification - Added verification mechanism to ensure signature files match database entries","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#changed_4","text":"Signature Format Consistency - Converted old format signature files to new component-based format Database Rebuild Process - Improved to handle format conversions and skip non-signature files","title":"Changed"},{"location":"binarysniffer/CHANGELOG/#189-2025-08-08","text":"","title":"[1.8.9] - 2025-08-08"},{"location":"binarysniffer/CHANGELOG/#added_11","text":"License Detection System - Comprehensive license detection using pattern matching for MIT, Apache-2.0, GPL, BSD, LGPL, and ISC licenses New license Command - Dedicated command for license analysis with compatibility checking and multiple output formats SPDX Identifier Support - Automatic detection of SPDX license identifiers with 100% confidence License Compatibility Checking - Identifies incompatible license combinations (e.g., GPL-2.0 vs GPL-3.0) Integrated License Detection - Added --license-focus and --license-only flags to the analyze command Multiple Output Formats - License reports in Table, JSON, CSV, and Markdown formats License File Recognition - Automatic detection of LICENSE, COPYING, and similar files Embedded License Detection - Finds licenses in source code comments and headers","title":"Added"},{"location":"binarysniffer/CHANGELOG/#features","text":"Pattern-based detection for 7 major open-source licenses License categorization (copyleft, weak copyleft, permissive) Compatibility warnings for mixed license scenarios Works on single files, directories, and archives Python API support for programmatic license analysis","title":"Features"},{"location":"binarysniffer/CHANGELOG/#188-2025-08-08","text":"","title":"[1.8.8] - 2025-08-08"},{"location":"binarysniffer/CHANGELOG/#added_12","text":"Static Library Support - Full AR archive parsing and analysis for .a and .lib files with per-object file tracking Source Attribution - Track which symbols come from which object files within static libraries (e.g., _CRYPTO_malloc@libcrypto-lib-pvkfmt.o ) BSD AR Format Support - Handle both standard and BSD-style extended names in AR archives OpenSSL-Specific Signatures - 35 highly specific patterns for accurate OpenSSL detection without false positives Signature Optimization Script - Tool for removing generic patterns that cause false positives between similar libraries","title":"Added"},{"location":"binarysniffer/CHANGELOG/#fixed_11","text":"OpenSSL False Positives - Eliminated incorrect FFmpeg (was 85.6%) and wolfSSL (was 84%) detections in OpenSSL libraries JSON/CSV Console Output - Fixed mixing of summary text with JSON/CSV output when not saving to file","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#improved_12","text":"OpenSSL Detection - Increased accuracy from 78% to 92.8% confidence with optimized signatures Static Library Analysis - Can now analyze individual object files within archives (e.g., 62 objects in libcrypto.a) Component Attribution - Better understanding of which parts of a library contribute which symbols","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#187-2025-08-07","text":"","title":"[1.8.7] - 2025-08-07"},{"location":"binarysniffer/CHANGELOG/#added_13","text":"Zstandard Archive Support - Full support for .zst , .tar.zst , and .vpkg compressed archives for analysis and inventory extraction System zstd Fallback - Automatic fallback to system zstd command when Python library can't handle certain frame formats GStreamer Signatures - Added 17 high-quality signatures for GStreamer multimedia framework detection Hermes React Native Signatures - Added 25 signatures for Hermes JavaScript engine including bytecode magic detection Native Hermes Bytecode Inspector - Pure Python implementation for analyzing Hermes bytecode files without external dependencies Hermes Decompiler Script - Basic decompilation and analysis tool for React Native Hermes bundles","title":"Added"},{"location":"binarysniffer/CHANGELOG/#fixed_12","text":"Signature Creation from Binaries - Fixed component name matching to handle \"lib\" prefix variations (e.g., libcap vs cap) Inventory Extraction Tests - Fixed all 11 tests by adding missing total_directories field and correcting function references API Consistency - Fixed analyze_directory to return BatchAnalysisResult consistently across all analyzers CLI Tests - Fixed all 12 CLI tests by properly handling BatchAnalysisResult in single and batch file analysis Microsoft OLE False Positives - Removed 16 overly generic patterns (24.6% reduction) that caused false detections Qt5 False Positives - Removed 28 generic patterns (28% reduction) that could cause legal issues PCoIP SDK False Positives - Removed 519 generic patterns (73.6% reduction) eliminating widespread false detections","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#improved_13","text":"Code Organization - Eliminated 400+ lines of duplicate code through BaseAnalyzer refactoring Binary String Extraction - Centralized binary string extraction logic in shared utility module Test Coverage - Added comprehensive tests for Zstandard support (5 new tests) Detection Accuracy - Dramatically reduced false positives across Microsoft OLE, Qt5, and PCoIP SDK components Signature Quality - Cleaned up over 563 problematic patterns across multiple components","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#technical","text":"New Module - binarysniffer.core.base_analyzer for shared analyzer functionality New Module - binarysniffer.utils.binary_strings for centralized binary string extraction New Module - binarysniffer.extractors.hermes for native Hermes bytecode extraction New Tests - tests/test_zstandard_support.py for Zstandard archive validation Archive Extensions - Added .zst , .tar.zst , .tzst , and .vpkg to supported formats New Signatures - signatures/gstreamer.json with multimedia framework patterns New Signatures - signatures/hermes.json with React Native JavaScript engine patterns Cleanup Scripts - Added scripts for removing generic patterns from Microsoft OLE, Qt5, and PCoIP SDK Analysis Tools - scripts/hermes_decompiler.py for Hermes bytecode inspection and basic decompilation Hermes Support - Native parsing of Hermes header, string table extraction, and framework detection","title":"Technical"},{"location":"binarysniffer/CHANGELOG/#186-2025-08-07","text":"","title":"[1.8.6] - 2025-08-07"},{"location":"binarysniffer/CHANGELOG/#added_14","text":"CycloneDX SBOM Export - Generate industry-standard SBOMs for security and compliance toolchains Package Inventory Extraction - New inventory command for comprehensive package analysis File Path Tracking - Evidence now includes file paths for component location tracking File Metadata Export - Extract MIME types, compression ratios, file sizes, timestamps from archives Hash Calculation - Generate MD5, SHA1, SHA256 hashes for all files in packages Fuzzy Hash Support - Calculate TLSH and ssdeep hashes for similarity analysis Component Detection in Archives - Run OSS detection on individual files within packages Multiple Export Formats - JSON, CSV, CycloneDX, tree visualization, and summary reports Enhanced CSV Export - Rich CSV output with hashes, MIME types, and component detection results Feature Extraction Export - Save extracted features for signature recreation with --save-features API Feature Parity - All CLI inventory features available via Python API","title":"Added"},{"location":"binarysniffer/CHANGELOG/#improved_14","text":"File Analysis API - Added include_hashes and include_fuzzy_hashes parameters to analyze_file() Inventory Performance - Selective analysis options to balance speed vs comprehensiveness Archive Metadata - Relative paths, compression ratios, and CRC checksums for all files","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#fixed_13","text":"Test Suite - Fixed 7 failing tests for better stability Archive Extractor Test - Corrected APK native library detection expectations Directory Analysis - Properly excludes .binarysniffer directory from recursive scans","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#technical_1","text":"New Module - binarysniffer.output.cyclonedx_formatter for SBOM generation New Module - binarysniffer.utils.inventory for package enumeration Enhanced Module - binarysniffer.utils.file_metadata for hash calculations Evidence Enhancement - ComponentMatch evidence now includes file paths API Methods - extract_package_inventory() with full parameter control CLI Formats - Added cyclonedx and cdx output formats CLI Flags - --analyze , --include-hashes , --include-fuzzy-hashes , --detect-components , --save-features","title":"Technical"},{"location":"binarysniffer/CHANGELOG/#184-2025-08-06","text":"","title":"[1.8.4] - 2025-08-06"},{"location":"binarysniffer/CHANGELOG/#fixed_14","text":"Eliminated .NET Core false positives - Removed 59 overly generic patterns (90.8% reduction) Reduced wolfSSL false detections - Removed 32 generic crypto patterns that appear in many libraries No more type name collisions - Removed generic patterns like int32, float64, libc that match everywhere","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#added_15","text":"Ultra-aggressive signature cleaning - New script scripts/ultra_aggressive_clean.py for deep pattern cleaning Better pattern validation - Filters out basic types, generic prefixes, and common C library functions","title":"Added"},{"location":"binarysniffer/CHANGELOG/#improved_15","text":".NET Core signatures - Reduced from 65 to 6 highly specific patterns wolfSSL signatures - Kept only wolfSSL-specific patterns (159 remaining from 191) Detection accuracy - FFmpeg and other binaries no longer show incorrect .NET or wolfSSL detections","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#technical_2","text":"Pattern filtering - Removes int/float types, generic prefixes (prefix1-7), macOS standard symbols Signature quality - Only truly component-specific patterns remain in signatures Testing verified - No false positives in FFmpeg, libcap, and other test binaries","title":"Technical"},{"location":"binarysniffer/CHANGELOG/#183-2025-08-06","text":"","title":"[1.8.3] - 2025-08-06"},{"location":"binarysniffer/CHANGELOG/#added_16","text":"Git hooks for problematic word detection - Prevent commits with AI references and other problematic content Comprehensive pattern checking - Detect AI/assistant references, hardcoded secrets, TODOs, inappropriate language Pre-commit and commit-msg hooks - Check both staged files and commit messages before allowing commits Customizable word patterns - Easy to add/remove patterns in .githooks/check-problematic-words.sh","title":"Added"},{"location":"binarysniffer/CHANGELOG/#security_1","text":"Automated secret detection - Hooks now check for hardcoded passwords, API keys, and tokens Confidential content blocking - Prevent accidental commit of internal/confidential markers","title":"Security"},{"location":"binarysniffer/CHANGELOG/#technical_3","text":"Git hooks directory - .githooks/ directory with reusable hook scripts Automatic hook configuration - Repository configured to use .githooks/ via core.hooksPath Documentation - Added .githooks/README.md with installation and usage instructions","title":"Technical"},{"location":"binarysniffer/CHANGELOG/#182-2025-08-06","text":"","title":"[1.8.2] - 2025-08-06"},{"location":"binarysniffer/CHANGELOG/#added_17","text":"ALSA signature - Comprehensive Advanced Linux Sound Architecture detection with 48 specific patterns Aggressive signature cleaning - New script to remove overly generic patterns causing false positives Verbose evidence tracking - Enhanced -ve flag now shows which files within archives triggered matches","title":"Added"},{"location":"binarysniffer/CHANGELOG/#fixed_15","text":"Major false positive reduction - Removed 16,090 generic patterns from signatures that caused incorrect detections Archive content tracking - Verbose mode now properly displays which files in archives contain matches Signature quality - Eliminated problematic patterns like \"copy\", \"exit\", \"path\", \"bool\" that match everywhere","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#improved_16","text":"Detection accuracy - Dramatically reduced false positives (e.g., .NET Core no longer incorrectly detected in FFmpeg) PCoIP SDK - Removed 4,312 generic patterns wolfSSL - Removed 3,143 generic patterns .NET Core - Removed 2,064 generic patterns FFmpeg - Removed 3,503 generic patterns from BSA signature Qt5 - Cleaned to only 13 high-quality patterns","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#technical_4","text":"New tool - scripts/aggressive_clean_signatures.py for comprehensive pattern filtering Pattern validation - Filters patterns <4 chars, common C functions, generic programming terms Safe prefix preservation - Keeps library-specific prefixes like snd_ , av_ , ff_ , png_","title":"Technical"},{"location":"binarysniffer/CHANGELOG/#181-2025-08-06","text":"","title":"[1.8.1] - 2025-08-06"},{"location":"binarysniffer/CHANGELOG/#fixed_16","text":"Database initialization on clean install - Fixed critical issue preventing tool from working on new systems Directory creation - Database parent directory is now created automatically before initialization Signature import method - Fixed enhanced analyzer calling non-existent auto_import() method","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#improved_17","text":"Installation reliability - Tool now works correctly on first install without manual intervention Error handling - Better error messages when database cannot be created Documentation - Added comprehensive TLSH fuzzy matching examples to README","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#180-2025-08-06","text":"","title":"[1.8.0] - 2025-08-06"},{"location":"binarysniffer/CHANGELOG/#added_18","text":"TLSH Fuzzy Matching - Detect similar/modified OSS components using locality-sensitive hashing Enhanced FFmpeg signature - 2,000 high-quality patterns covering versions 4.4 to 6.0 with TLSH hash CLI options for fuzzy matching - New --use-tlsh and --tlsh-threshold parameters for similarity detection TLSH signature store - Manage and query TLSH hashes for fuzzy component matching Optional TLSH addition script - Tool to add TLSH hashes to existing signatures ( scripts/add_tlsh_to_signatures.py )","title":"Added"},{"location":"binarysniffer/CHANGELOG/#improved_18","text":"Detection accuracy - Find modified, recompiled, or patched OSS components that pattern matching might miss Signature generation - Automatically generates TLSH hashes for new signatures Version detection - Better identification of different versions of the same library Component matching - Merged fuzzy and pattern matching for comprehensive detection","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#technical_5","text":"New dependency - Added python-tlsh as optional dependency ( pip install binarysniffer[fuzzy] ) New module - binarysniffer.hashing.tlsh_hasher for TLSH operations Documentation - Comprehensive TLSH guide in docs/TLSH_FUZZY_MATCHING.md","title":"Technical"},{"location":"binarysniffer/CHANGELOG/#170-2025-08-06","text":"","title":"[1.7.0] - 2025-08-06"},{"location":"binarysniffer/CHANGELOG/#added_19","text":"MSI installer support - Extract and analyze Windows Installer packages (.msi files) with 7-Zip PKG installer support - Extract and analyze macOS installer packages (.pkg files) with 7-Zip DMG support - Extract and analyze macOS disk images (.dmg files) with 7-Zip New signatures - Added Qt5 Framework, OpenCV, Foxit PDF SDK, wolfSSL, PCoIP SDK, and .NET Core Runtime Logging improvements - Clean logging output and debug features from GitHub issues #6 and #3 Version display - Show version in main help output for better user experience","title":"Added"},{"location":"binarysniffer/CHANGELOG/#improved_19","text":"Installer analysis - Significantly improved detection rates for Windows and macOS installers Archive extraction - Enhanced extraction capabilities for various installer formats Documentation - Updated README with comprehensive optional tools section","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#fixed_17","text":"Signature cleanup - Removed unnecessary vendor-specific signatures","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#166-2025-08-06","text":"","title":"[1.6.6] - 2025-08-06"},{"location":"binarysniffer/CHANGELOG/#improved_20","text":"Pipeline and tests - Improved pipeline and rebuilt tests","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#165-2025-08-06","text":"","title":"[1.6.5] - 2025-08-06"},{"location":"binarysniffer/CHANGELOG/#added_20","text":"New component signatures - Added multiple new signatures for improved detection coverage Script improvements - Enhanced signature import and management scripts","title":"Added"},{"location":"binarysniffer/CHANGELOG/#improved_21","text":"Signature cleanup - Refined and optimized existing signatures for better accuracy LIEF and DEX parsers - Enhanced binary analysis with LIEF library and Android DEX support Detection accuracy - Continued improvements to component detection algorithms","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#fixed_18","text":"Script cleanup - Fixed and optimized signature processing scripts","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#164-2025-08-06","text":"","title":"[1.6.4] - 2025-08-06"},{"location":"binarysniffer/CHANGELOG/#changed_5","text":"Signature metadata optimization - Removed proprietary references from signature source descriptions Cleaner attribution - Updated signature metadata to use generic \"APK analysis\" instead of specific app references","title":"Changed"},{"location":"binarysniffer/CHANGELOG/#improved_22","text":"Professional metadata - All signature files now have cleaner, more professional source attributions Signature consistency - Standardized metadata format across all signature files","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#163-2025-08-06","text":"","title":"[1.6.3] - 2025-08-06"},{"location":"binarysniffer/CHANGELOG/#added_21","text":"Deterministic mode by default - Tool now runs with PYTHONHASHSEED=0 automatically for consistent results Non-deterministic flag - Added --non-deterministic flag to disable deterministic mode when needed Duplicate log prevention - Added DuplicateFilter to prevent the same log messages from appearing twice","title":"Added"},{"location":"binarysniffer/CHANGELOG/#changed_6","text":"Default confidence threshold - Changed from 0.8 to 0.5 to detect more components like Opus codec Removed bloom filter tier - Disabled probabilistic bloom filters for fully deterministic results Optimized direct matching - Improved performance from 5.3s to 1.0s (5x faster) using pre-computed indices","title":"Changed"},{"location":"binarysniffer/CHANGELOG/#fixed_19","text":"SQL query ordering - Added ORDER BY clauses to ensure consistent database query results Non-deterministic iterations - Fixed all dictionary and set iterations to use sorted order Configuration loading - Prevented multiple Config instances from setting up duplicate loggers","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#performance","text":"5x faster analysis - Direct matcher optimization reduces analysis time from 5.3s to 1.0s Memory efficient - Removed bloom filter memory overhead while maintaining fast lookups Deterministic results - Consistent component detection across multiple runs","title":"Performance"},{"location":"binarysniffer/CHANGELOG/#162-2025-08-05","text":"","title":"[1.6.2] - 2025-08-05"},{"location":"binarysniffer/CHANGELOG/#investigated","text":"Root cause of non-determinism - Identified that Python's hash randomization (PYTHONHASHSEED) causes inconsistent results across CLI invocations Bloom filter probabilistic behavior - Bloom filters inherently have false positives that vary with different hash seeds","title":"Investigated"},{"location":"binarysniffer/CHANGELOG/#fixed_20","text":"Sorted dictionary iterations - Made component_scores iteration deterministic in DirectMatcher Sorted set conversions - Fixed non-deterministic list creation from sets in multiple places Deterministic final sorting - Added component name as secondary sort key for consistent ordering Deterministic feature ordering - Sort unique features before processing in ProgressiveMatcher","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#added_22","text":"Deterministic bloom filter implementation - Created new implementation using SHA-256 instead of Python's hash()","title":"Added"},{"location":"binarysniffer/CHANGELOG/#known-issues","text":"Component detection still shows some inconsistency due to bloom filter's probabilistic nature Running with PYTHONHASHSEED=0 provides consistent results Consider making bloom filter tier optional or removing it for fully deterministic behavior","title":"Known Issues"},{"location":"binarysniffer/CHANGELOG/#161-2025-08-05","text":"","title":"[1.6.1] - 2025-08-05"},{"location":"binarysniffer/CHANGELOG/#fixed_21","text":"Progress bar removed - Removed tqdm progress bar from DirectMatcher that was causing display issues Matcher initialization order - Fixed issue where DirectMatcher was initialized before database was populated Deterministic file ordering - Archive extraction now uses sorted file lists for consistent results Order-preserving deduplication - Replaced set() with dict.fromkeys() to maintain consistent string order","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#known-issues_1","text":"Component detection still shows some inconsistency across runs (under investigation) Duplicate log messages appear in CLI output","title":"Known Issues"},{"location":"binarysniffer/CHANGELOG/#160-2025-08-05","text":"","title":"[1.6.0] - 2025-08-05"},{"location":"binarysniffer/CHANGELOG/#added_23","text":"LIEF-based extractors - Enhanced binary analysis using LIEF library for ELF/PE/Mach-O formats DEX file extractor - Specialized extractor for Android DEX bytecode analysis New component signatures - Added signatures for OkHttp, OpenSSL, SQLite, ICU, FreeType, and WebKit Progress indication - Added tqdm progress bars for long analysis operations Substring matching - Direct matcher now supports partial string matching for better detection","title":"Added"},{"location":"binarysniffer/CHANGELOG/#improved_23","text":"APK analysis - Dramatically improved component detection in Android APKs (from 1 to 25+ components) Feature extraction - Increased from 6,741 to 152,640 features for complex archives like APKs Bloom filter capacity - Increased limit from 1,000 to 100,000 features for better coverage Component name display - Fixed \"@unknown\" suffix when version is not available Matching performance - Optimized substring matching with early termination and pre-filtering","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#fixed_22","text":"Archive processing - DEX files and native libraries within APKs are now properly analyzed Feature counting - Analyzer now correctly reports total features extracted Substring matching logic - Fixed reversed logic (pattern in string, not string in pattern) Progressive matcher - Component names no longer show \"@unknown\" for unknown versions","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#151-2025-08-05","text":"","title":"[1.5.1] - 2025-08-05"},{"location":"binarysniffer/CHANGELOG/#fixed_23","text":"Major signature cleanup - Removed 479 generic patterns causing false positives Apache HTTP Core false positives - Removed generic HTTP patterns that matched FFmpeg Signature quality improvement - Filtered patterns shorter than 6 characters Cross-component contamination - Removed patterns appearing in 5+ components","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#improved_24","text":"Signature validation - More strict criteria for keeping patterns Library-specific prefixes - Preserved valid prefixes like av_ , x264_ , png_ Reduced false positive rate - 5.4% reduction in total signatures","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#statistics","text":"Total signatures before: 8,916 Total signatures after: 8,437 Apache HTTP Core: 31/65 patterns removed (47.7%) FFmpeg: Only 15/6,660 patterns removed (0.2%) SKIA: 77/268 patterns removed (28.7%)","title":"Statistics"},{"location":"binarysniffer/CHANGELOG/#150-2025-08-05","text":"","title":"[1.5.0] - 2025-08-05"},{"location":"binarysniffer/CHANGELOG/#added_24","text":"Integrated signature creation - New binarysniffer signatures create command Binary symbol extraction - Extract symbols using readelf, nm, and strings Smart signature generation - Automatically identifies library prefixes and functions Source code analysis - Create signatures from source code repositories Auto-detection - Automatically detects binary vs source code input","title":"Added"},{"location":"binarysniffer/CHANGELOG/#improved_25","text":"CLI integration - Signature creation is now part of the main tool Symbol-based signatures - Uses actual binary symbols instead of arbitrary strings Better validation - Accepts library prefixes like av_ , x264_ , png_","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#usage","text":"# Create signatures from binary binarysniffer signatures create /path/to/ffmpeg --name FFmpeg --version 4.4.1 # Create from source code binarysniffer signatures create /path/to/source --name MyLib --license MIT # With full metadata binarysniffer signatures create binary --name Component \\\\ --version 1.0 --license GPL-3.0 --publisher \"Company\" \\\\ --description \"Component description\" --output custom.json","title":"Usage"},{"location":"binarysniffer/CHANGELOG/#149-2025-08-05","text":"","title":"[1.4.9] - 2025-08-05"},{"location":"binarysniffer/CHANGELOG/#added_25","text":"Signature quality validation - New SignatureValidator class filters out generic patterns Automatic filtering - DirectMatcher now rejects overly generic signatures like \"react\", \"log\", \"test\" Quality metrics - 1,153 problematic patterns identified and filtered from signature database","title":"Added"},{"location":"binarysniffer/CHANGELOG/#improved_26","text":"Drastically reduced false positives - No more React Native detection in C++ projects Better precision - Filters short patterns (<6 chars) and common programming terms Smarter matching - Accepts specific patterns with special characters, mixed case, or namespaces","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#fixed_24","text":"Generic signature problem - Signatures like \"React\", \"apache\", \"get\", \"set\" no longer cause false matches Cross-technology false positives - C++ projects no longer show JavaScript/mobile components","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#148-2025-08-05","text":"","title":"[1.4.8] - 2025-08-05"},{"location":"binarysniffer/CHANGELOG/#improved_27","text":"Higher default threshold - Increased from 0.5 to 0.7 for better precision ZIP file filtering - Added technology filtering for ZIP files containing binaries Mobile component filtering - React Native, Firebase, and other mobile components now filtered from ZIP files","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#fixed_25","text":"False positives in ZIP files - ZIP files with native binaries no longer show mobile-specific components","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#147-2025-08-05","text":"","title":"[1.4.7] - 2025-08-05"},{"location":"binarysniffer/CHANGELOG/#improved_28","text":"Reduced false positives - Increased default threshold from 0.3 to 0.5 for better accuracy Technology filtering - Automatically filters incompatible components (e.g., no Android/iOS components in native binaries) Archive extraction - Fixed single-file archive extraction to use all features instead of limiting to 100 strings Context validation - Binary type now influences component detection to prevent impossible matches","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#fixed_26","text":"ZIP file analysis - Single-file archives like ffmpeg-4.4.1-linux-64.zip now properly analyzed with full feature extraction False positive filtering - Removed mobile-specific components (Firebase, React Native, etc.) from native binary results","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#146-2025-08-05","text":"","title":"[1.4.6] - 2025-08-05"},{"location":"binarysniffer/CHANGELOG/#improved_29","text":"Enhanced mode is now default - All analysis now uses dual matching strategy (ProgressiveMatcher + DirectMatcher) for superior detection accuracy Lower default threshold - Reduced from 0.5 to 0.3 for better component detection without requiring manual threshold adjustment Simplified CLI interface - Removed --enhanced flag as enhanced detection is always active Multi-language regex patterns - Enhanced SourceCodeExtractor with comprehensive language support Pattern coverage - Achieved 100% test coverage across all 9 supported programming languages Language-specific parsing - Added support for Ruby methods without parentheses, C/C++ macros, Rust const syntax, Go imports and structs, C# using statements, C++ method declarations, and Kotlin functions Detection accuracy - Improved success rate from 85.4% to 100% for source code symbol extraction","title":"Improved"},{"location":"binarysniffer/CHANGELOG/#added_26","text":"Enhanced function patterns - 6 regex patterns covering Python, JavaScript, Go, Rust, Kotlin, Java/C#/C++ Comprehensive class patterns - 5 patterns for class, struct, interface, Go types, and enums Extended import patterns - 8 patterns supporting Python, JS, Rust, C/C++, Go, C#, Kotlin imports Robust constant patterns - 5 patterns for general constants, assignments, C macros, Rust, and Kotlin","title":"Added"},{"location":"binarysniffer/CHANGELOG/#breaking-changes","text":"Enhanced mode always enabled - The --enhanced flag has been removed as enhanced detection is now the default behavior","title":"Breaking Changes"},{"location":"binarysniffer/CHANGELOG/#145-2025-08-05","text":"","title":"[1.4.5] - 2025-08-05"},{"location":"binarysniffer/CHANGELOG/#fixed_27","text":"Release pipeline - Fixed automated release and deployment pipeline issues","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#140-2025-08-05","text":"","title":"[1.4.0] - 2025-08-05"},{"location":"binarysniffer/CHANGELOG/#fixed_28","text":"Complete repository reset - Fresh git history with single clean commit Professional contributor attribution - All commits properly attributed to Oscar Valenzuela B Clean release process - New major version with proper identity management","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#features_1","text":"License extraction from database - DirectMatcher properly queries license column Evidence formatting - Clear display of pattern counts in evidence column License information display - All detected components show their proper licenses Enhanced detection mode - Improved component detection accuracy (42x improvement on APK analysis) Comprehensive signature database - 8,852+ signatures from 129+ components","title":"Features"},{"location":"binarysniffer/CHANGELOG/#updated","text":"Project metadata - Updated author information and repository URLs Documentation links - Fixed project URLs to point to correct GitHub repository","title":"Updated"},{"location":"binarysniffer/CHANGELOG/#130-2025-08-04","text":"","title":"1.3.0 - 2025-08-04"},{"location":"binarysniffer/CHANGELOG/#fixed_29","text":"License extraction from database - DirectMatcher now properly queries license column Component name display - No more \"@unknown\" suffix for components without versions Evidence formatting - Clear display of pattern counts in evidence column","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#enhanced","text":"License information display - All detected components now show their proper licenses Database queries - Optimized to fetch all component metadata including licenses Output clarity - Better formatted evidence showing number of matched patterns","title":"Enhanced"},{"location":"binarysniffer/CHANGELOG/#technical-fixes","text":"Fixed DirectMatcher SQL query to include license column Updated component mapping to extract license from correct database column Improved component name formatting to exclude redundant version info","title":"Technical Fixes"},{"location":"binarysniffer/CHANGELOG/#120-2025-08-04","text":"","title":"1.2.0 - 2025-08-04"},{"location":"binarysniffer/CHANGELOG/#added_27","text":"","title":"Added"},{"location":"binarysniffer/CHANGELOG/#enhanced-detection-mode","text":"New --enhanced CLI flag for improved component detection accuracy ImprovedBinaryExtractor with more permissive string extraction (min_length=4, max_strings=50000) DirectMatcher implementation bypassing bloom filters for exhaustive string matching EnhancedBinarySniffer analyzer combining progressive and direct matching strategies Symbol extraction patterns for common library prefixes and function names Comprehensive User Guide at docs/USER_GUIDE.md with examples and troubleshooting","title":"Enhanced Detection Mode"},{"location":"binarysniffer/CHANGELOG/#enhanced-signatures","text":"Expanded libpng signatures from 10 to 20 patterns for better detection New libjpeg-enhanced.json with 25 comprehensive patterns Enhanced signature metadata with confidence thresholds and contexts","title":"Enhanced Signatures"},{"location":"binarysniffer/CHANGELOG/#enhanced_1","text":"APK analysis accuracy improved from 1 to 42 components detected (42x improvement) String extraction with reduced filtering for better signature preservation Confidence scoring with adjusted thresholds (0.3 default for enhanced mode) Component detection for libraries like libpng, libxml2, FFMPEG, Firebase Crashlytics, SKIA Evidence reporting with signature counts and match methods in output","title":"Enhanced"},{"location":"binarysniffer/CHANGELOG/#fixed_30","text":"Binary extractor filtering removing potential signatures Bloom filter false negatives preventing component detection Import issues between analyzer modules Component lookup in DirectMatcher using proper database queries","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#technical-improvements","text":"Dual matching strategy for better accuracy vs performance tradeoff Configurable extraction parameters for different analysis needs Merged match results keeping highest confidence scores Better error handling in enhanced analyzer","title":"Technical Improvements"},{"location":"binarysniffer/CHANGELOG/#documentation","text":"Comprehensive User Guide covering installation, usage, examples, and troubleshooting Enhanced detection mode explanation and performance impact Output format documentation for table, JSON, and CSV formats Performance optimization tips for large-scale analysis","title":"Documentation"},{"location":"binarysniffer/CHANGELOG/#known-issues_2","text":"Code duplication between binary.py and binary_improved.py (~90% similar) Analyzer duplication between analyzer.py and analyzer_enhanced.py Unused imports in several modules (shutil, os, Set) Inconsistent error handling between analyzers","title":"Known Issues"},{"location":"binarysniffer/CHANGELOG/#110-2025-08-04","text":"","title":"1.1.0 - 2025-08-04"},{"location":"binarysniffer/CHANGELOG/#added_28","text":"","title":"Added"},{"location":"binarysniffer/CHANGELOG/#archive-support","text":"Complete archive file support for ZIP, JAR, APK, IPA, TAR, and other formats Android APK analysis with AndroidManifest.xml parsing, DEX file detection, and native library extraction iOS IPA analysis with Info.plist parsing, framework detection, and executable identification Java archive support with MANIFEST.MF parsing and package structure analysis Python package support for wheels (.whl) and eggs (.egg) with metadata extraction Nested archive processing for archives containing other archives Archive-specific metadata extraction including package names, versions, and dependencies","title":"Archive Support"},{"location":"binarysniffer/CHANGELOG/#ctags-integration","text":"Universal CTags support for enhanced source code analysis when available Graceful fallback to regex-based extraction when CTags is not installed Multi-language support including C/C++, Python, Java, JavaScript, Go, Rust, and more Semantic symbol extraction including functions, classes, structs, and constants Optional integration via ExtractorFactory configuration","title":"CTags Integration"},{"location":"binarysniffer/CHANGELOG/#signature-migration","text":"BSA signature database migration supporting 90+ open source components Real-world signature database with thousands of component signatures Automated migration scripts for converting legacy signature formats Component metadata preservation including licenses, publishers, and versions Efficient signature indexing with trigram support for fast substring matching","title":"Signature Migration"},{"location":"binarysniffer/CHANGELOG/#enhanced-testing","text":"Comprehensive test suite for archive extraction (10/10 tests passing) Integration tests for end-to-end APK/IPA/JAR analysis CTags integration testing with fallback verification Migration verification ensuring signature database functionality","title":"Enhanced Testing"},{"location":"binarysniffer/CHANGELOG/#enhanced_2","text":"ExtractorFactory improvements with configurable extractor selection Source code extraction with improved regex patterns and error handling Error handling throughout archive processing with graceful degradation Performance optimizations for large archive processing with file limits Logging improvements with detailed debug information for troubleshooting","title":"Enhanced"},{"location":"binarysniffer/CHANGELOG/#fixed_31","text":"Circular import issues in archive extractor factory integration Regex pattern corrections for JavaScript require statements Metadata handling ensuring proper initialization across all extractors TAR file type detection with proper compound extension handling","title":"Fixed"},{"location":"binarysniffer/CHANGELOG/#technical-improvements_1","text":"Plugin architecture for extractors with easy extensibility Memory management for large archive processing with limits and cleanup Type safety improvements with proper dataclass usage Test coverage expansion with comprehensive edge case handling","title":"Technical Improvements"},{"location":"binarysniffer/CHANGELOG/#documentation_1","text":"Archive format support documentation CTags installation and usage guidelines Migration script usage examples API documentation for new extractor interfaces","title":"Documentation"},{"location":"binarysniffer/CHANGELOG/#100-2025-08-03","text":"","title":"1.0.0 - 2025-08-03"},{"location":"binarysniffer/CHANGELOG/#added_29","text":"Initial release with core functionality Three-tier progressive matching system SQLite-based signature storage with ZSTD compression MinHash LSH indexing for fast similarity detection Bloom filter pre-filtering for performance CLI and Python library interfaces Basic file type support (binaries, source code) Trigram indexing for substring matching Component detection and confidence scoring","title":"Added"},{"location":"binarysniffer/CHANGELOG/#features_2","text":"Fast local analysis with <100MB memory usage Multi-format binary analysis Source code feature extraction License and component identification Batch processing capabilities JSON output format Configurable confidence thresholds","title":"Features"},{"location":"binarysniffer/CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Contributor Covenant Code of Conduct"},{"location":"binarysniffer/CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"binarysniffer/CODE_OF_CONDUCT/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"binarysniffer/CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"binarysniffer/CODE_OF_CONDUCT/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"binarysniffer/CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"binarysniffer/CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"binarysniffer/CODE_OF_CONDUCT/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"binarysniffer/CODE_OF_CONDUCT/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"binarysniffer/CODE_OF_CONDUCT/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"binarysniffer/CODE_OF_CONDUCT/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"binarysniffer/CODE_OF_CONDUCT/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"binarysniffer/CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Attribution"},{"location":"binarysniffer/CONTRIBUTING/","text":"Contributing to Semantic Copycat BinarySniffer Thank you for your interest in contributing to BinarySniffer! This guide will help you contribute new component signatures to help the community detect OSS components in binaries. \ud83c\udfaf How to Contribute Signatures We welcome signature contributions from the community! Here's how you can help: Option 1: Using BinarySniffer Tool (Recommended) The easiest way to contribute is by using BinarySniffer itself to extract signatures from binaries containing your target component. Step 1: Extract Signatures from a Binary # Install BinarySniffer pip install binarysniffer # Analyze a binary containing your target component binarysniffer analyze path/to/binary.so --detailed --format json -o analysis.json # Look for string patterns unique to your component grep -i \"your_component_name\" analysis.json Step 2: Manual Signature Creation Create a signature file using our template: # Copy the template cp signatures/EXAMPLE_template.json signatures/my-new-component.json # Edit with your component's information Step 3: Test Your Signature # Test your signature locally binarysniffer signatures import --force binarysniffer analyze test_binary_with_component.so Option 2: Manual Signature Extraction If you have access to the component's source code or documentation: Step 1: Identify Unique Strings Look for unique identifiers in the component: - Function names (e.g., av_codec_init , MyLibraryFunction ) - Class names (e.g., FacebookSDK , JacksonParser ) - Resource identifiers (e.g., com_facebook_button , libavcodec ) - Version strings (e.g., MyLib version 2.1.0 ) - Error messages (e.g., MyLib: Failed to initialize ) - Configuration keys (e.g., my_lib_config , MYLIB_DEBUG ) Step 2: Verify Uniqueness Ensure your strings are unique to avoid false positives: - Search GitHub/Google to see if strings appear in other projects - Avoid generic terms like \"error\", \"init\", \"config\" - Prefer longer, specific strings over short ones \ud83d\udcdd Signature File Format Create a JSON file following this structure: { \"component\": { \"name\": \"Your Component Name\", \"version\": \"1.2.3\", \"category\": \"choose-from-categories-below\", \"platforms\": [\"android\", \"ios\", \"linux\", \"windows\", \"macos\", \"web\", \"all\"], \"languages\": [\"java\", \"kotlin\", \"swift\", \"c\", \"c++\", \"python\", \"javascript\", \"go\"], \"description\": \"Brief description of what this component does\", \"license\": \"MIT/Apache-2.0/GPL-3.0/etc\", \"publisher\": \"Component Publisher/Author\", \"homepage\": \"https://github.com/author/component\" }, \"signature_metadata\": { \"version\": \"1.0.0\", \"created\": \"2025-08-04T00:00:00Z\", \"signature_count\": 5, \"confidence_threshold\": 0.8, \"contributor\": \"Your Name <email@example.com>\", \"extraction_method\": \"manual/automated/hybrid\" }, \"signatures\": [ { \"id\": \"unique_signature_id\", \"type\": \"string_pattern\", \"pattern\": \"YourLibraryInit\", \"confidence\": 0.9, \"context\": \"initialization\", \"platforms\": [\"all\"], \"description\": \"Library initialization function\" } ] } Categories Choose the most appropriate category: - mobile-sdk : Mobile development SDKs (Facebook SDK, Firebase, etc.) - enterprise-library : Enterprise Java/business libraries (Apache, Google, etc.) - media-processing : Audio/video codecs and processing (FFmpeg, x264, etc.) - networking : HTTP clients, networking libraries (OkHttp, Retrofit, etc.) - data-processing : JSON, XML parsers and data libraries (Jackson, GSON, etc.) - crypto : Cryptographic libraries (BouncyCastle, OpenSSL, etc.) - ui-framework : UI and graphics libraries (React Native, Skia, etc.) - testing : Testing frameworks and tools - logging : Logging libraries (Log4j, SLF4J, etc.) - imported : Legacy or uncategorized imports Confidence Levels Set appropriate confidence levels: - 0.95-1.0 : Extremely unique strings (version strings, unique function names) - 0.85-0.94 : Highly specific (component-specific class names, API calls) - 0.75-0.84 : Moderately specific (prefixed identifiers, resource names) - 0.65-0.74 : Less specific but still meaningful (common function names with context) Context Types Categorize your signatures by context: - initialization : Library/SDK initialization - api_calls : Function calls and method invocations - user_interface : UI elements, buttons, dialogs - networking : HTTP requests, URL handling - data_processing : Parsing, serialization, data handling - error_handling : Error messages, exception handling - configuration : Config keys, settings, parameters - resource_identifier : Android resources, asset names - library_function : Core library functions - logging : Log messages, debug output \ud83d\udd04 Submission Process Step 1: Fork the Repository git clone https://github.com/YOUR_USERNAME/binarysniffer.git cd binarysniffer Step 2: Create Your Signature Create a new file in signatures/ directory Name it descriptively: component-name.json (use kebab-case) Follow the JSON format above Include 5-20 high-quality signatures Step 3: Test Your Signature # Install in development mode pip install -e . # Test your signature binarysniffer signatures import --force binarysniffer signatures status # Test against known binaries containing your component binarysniffer analyze test_binary.so Step 4: Submit Pull Request git add signatures/your-component.json git commit -m \"Add signatures for Your Component Name - Added X signatures for Your Component - Covers initialization, API calls, and error handling - Tested against version X.Y.Z binaries\" git push origin main Create a pull request with: - Title : Add signatures for [Component Name] - Description : Brief description of the component and signature sources - Testing : Mention how you tested the signatures \u2705 Quality Guidelines DO: \u2705 Test signatures against real binaries \u2705 Use descriptive signature IDs \u2705 Include variety of contexts (init, API, errors) \u2705 Set appropriate confidence levels \u2705 Add meaningful descriptions \u2705 Verify component information (license, publisher) DON'T: \u274c Use overly generic strings (\"init\", \"error\", \"config\") \u274c Copy signatures from unrelated components \u274c Include too many low-confidence signatures \u274c Use extremely long patterns (>100 characters) \u274c Include personal/private information \u274c Submit without testing \ud83d\udee0 Advanced: Using the Signature Generator For automated signature extraction from binaries: # Extract all strings from a binary strings binary_file.so > strings.txt # Filter for component-specific patterns grep -i \"component_name\" strings.txt # Use BinarySniffer's generator (if available) binarysniffer generate-signatures binary_file.so --component \"Component Name\" \ud83d\udcca Signature Database Statistics Current signature database includes: - 120+ components from major software vendors - 8,700+ signatures covering popular OSS libraries - Categories : Mobile SDKs, Enterprise Java, Media Processing, Networking, etc. - Platforms : Android, iOS, Linux, Windows, macOS, Web \ud83c\udf89 Recognition Contributors will be: - Listed in release notes - Credited in signature metadata - Mentioned in project documentation - Invited to join the project maintainers (for significant contributions) \ud83d\udcde Support Need help contributing? - \ud83d\udce7 Create an issue with the contribution-help label - \ud83d\udcac Ask questions in pull request comments - \ud83d\udcd6 Check existing signatures for examples - \ud83d\udd0d Search the documentation \ud83d\ude80 Future Enhancements We're working on: - Automated signature extraction from popular package managers (Note: This feature assumes availability of source code alongside binaries, which is not always the case. As such, automated signature creation from package managers is considered out of scope for the CLI tool and will be implemented in a separate scanning orchestrator) - Binary analysis tools for signature discovery - Community signature validation system - Integration with vulnerability databases Thank you for helping make BinarySniffer better for everyone! \ud83d\ude4f","title":"Contributing to Semantic Copycat BinarySniffer"},{"location":"binarysniffer/CONTRIBUTING/#contributing-to-semantic-copycat-binarysniffer","text":"Thank you for your interest in contributing to BinarySniffer! This guide will help you contribute new component signatures to help the community detect OSS components in binaries.","title":"Contributing to Semantic Copycat BinarySniffer"},{"location":"binarysniffer/CONTRIBUTING/#how-to-contribute-signatures","text":"We welcome signature contributions from the community! Here's how you can help:","title":"\ud83c\udfaf How to Contribute Signatures"},{"location":"binarysniffer/CONTRIBUTING/#option-1-using-binarysniffer-tool-recommended","text":"The easiest way to contribute is by using BinarySniffer itself to extract signatures from binaries containing your target component.","title":"Option 1: Using BinarySniffer Tool (Recommended)"},{"location":"binarysniffer/CONTRIBUTING/#step-1-extract-signatures-from-a-binary","text":"# Install BinarySniffer pip install binarysniffer # Analyze a binary containing your target component binarysniffer analyze path/to/binary.so --detailed --format json -o analysis.json # Look for string patterns unique to your component grep -i \"your_component_name\" analysis.json","title":"Step 1: Extract Signatures from a Binary"},{"location":"binarysniffer/CONTRIBUTING/#step-2-manual-signature-creation","text":"Create a signature file using our template: # Copy the template cp signatures/EXAMPLE_template.json signatures/my-new-component.json # Edit with your component's information","title":"Step 2: Manual Signature Creation"},{"location":"binarysniffer/CONTRIBUTING/#step-3-test-your-signature","text":"# Test your signature locally binarysniffer signatures import --force binarysniffer analyze test_binary_with_component.so","title":"Step 3: Test Your Signature"},{"location":"binarysniffer/CONTRIBUTING/#option-2-manual-signature-extraction","text":"If you have access to the component's source code or documentation:","title":"Option 2: Manual Signature Extraction"},{"location":"binarysniffer/CONTRIBUTING/#step-1-identify-unique-strings","text":"Look for unique identifiers in the component: - Function names (e.g., av_codec_init , MyLibraryFunction ) - Class names (e.g., FacebookSDK , JacksonParser ) - Resource identifiers (e.g., com_facebook_button , libavcodec ) - Version strings (e.g., MyLib version 2.1.0 ) - Error messages (e.g., MyLib: Failed to initialize ) - Configuration keys (e.g., my_lib_config , MYLIB_DEBUG )","title":"Step 1: Identify Unique Strings"},{"location":"binarysniffer/CONTRIBUTING/#step-2-verify-uniqueness","text":"Ensure your strings are unique to avoid false positives: - Search GitHub/Google to see if strings appear in other projects - Avoid generic terms like \"error\", \"init\", \"config\" - Prefer longer, specific strings over short ones","title":"Step 2: Verify Uniqueness"},{"location":"binarysniffer/CONTRIBUTING/#signature-file-format","text":"Create a JSON file following this structure: { \"component\": { \"name\": \"Your Component Name\", \"version\": \"1.2.3\", \"category\": \"choose-from-categories-below\", \"platforms\": [\"android\", \"ios\", \"linux\", \"windows\", \"macos\", \"web\", \"all\"], \"languages\": [\"java\", \"kotlin\", \"swift\", \"c\", \"c++\", \"python\", \"javascript\", \"go\"], \"description\": \"Brief description of what this component does\", \"license\": \"MIT/Apache-2.0/GPL-3.0/etc\", \"publisher\": \"Component Publisher/Author\", \"homepage\": \"https://github.com/author/component\" }, \"signature_metadata\": { \"version\": \"1.0.0\", \"created\": \"2025-08-04T00:00:00Z\", \"signature_count\": 5, \"confidence_threshold\": 0.8, \"contributor\": \"Your Name <email@example.com>\", \"extraction_method\": \"manual/automated/hybrid\" }, \"signatures\": [ { \"id\": \"unique_signature_id\", \"type\": \"string_pattern\", \"pattern\": \"YourLibraryInit\", \"confidence\": 0.9, \"context\": \"initialization\", \"platforms\": [\"all\"], \"description\": \"Library initialization function\" } ] }","title":"\ud83d\udcdd Signature File Format"},{"location":"binarysniffer/CONTRIBUTING/#categories","text":"Choose the most appropriate category: - mobile-sdk : Mobile development SDKs (Facebook SDK, Firebase, etc.) - enterprise-library : Enterprise Java/business libraries (Apache, Google, etc.) - media-processing : Audio/video codecs and processing (FFmpeg, x264, etc.) - networking : HTTP clients, networking libraries (OkHttp, Retrofit, etc.) - data-processing : JSON, XML parsers and data libraries (Jackson, GSON, etc.) - crypto : Cryptographic libraries (BouncyCastle, OpenSSL, etc.) - ui-framework : UI and graphics libraries (React Native, Skia, etc.) - testing : Testing frameworks and tools - logging : Logging libraries (Log4j, SLF4J, etc.) - imported : Legacy or uncategorized imports","title":"Categories"},{"location":"binarysniffer/CONTRIBUTING/#confidence-levels","text":"Set appropriate confidence levels: - 0.95-1.0 : Extremely unique strings (version strings, unique function names) - 0.85-0.94 : Highly specific (component-specific class names, API calls) - 0.75-0.84 : Moderately specific (prefixed identifiers, resource names) - 0.65-0.74 : Less specific but still meaningful (common function names with context)","title":"Confidence Levels"},{"location":"binarysniffer/CONTRIBUTING/#context-types","text":"Categorize your signatures by context: - initialization : Library/SDK initialization - api_calls : Function calls and method invocations - user_interface : UI elements, buttons, dialogs - networking : HTTP requests, URL handling - data_processing : Parsing, serialization, data handling - error_handling : Error messages, exception handling - configuration : Config keys, settings, parameters - resource_identifier : Android resources, asset names - library_function : Core library functions - logging : Log messages, debug output","title":"Context Types"},{"location":"binarysniffer/CONTRIBUTING/#submission-process","text":"","title":"\ud83d\udd04 Submission Process"},{"location":"binarysniffer/CONTRIBUTING/#step-1-fork-the-repository","text":"git clone https://github.com/YOUR_USERNAME/binarysniffer.git cd binarysniffer","title":"Step 1: Fork the Repository"},{"location":"binarysniffer/CONTRIBUTING/#step-2-create-your-signature","text":"Create a new file in signatures/ directory Name it descriptively: component-name.json (use kebab-case) Follow the JSON format above Include 5-20 high-quality signatures","title":"Step 2: Create Your Signature"},{"location":"binarysniffer/CONTRIBUTING/#step-3-test-your-signature_1","text":"# Install in development mode pip install -e . # Test your signature binarysniffer signatures import --force binarysniffer signatures status # Test against known binaries containing your component binarysniffer analyze test_binary.so","title":"Step 3: Test Your Signature"},{"location":"binarysniffer/CONTRIBUTING/#step-4-submit-pull-request","text":"git add signatures/your-component.json git commit -m \"Add signatures for Your Component Name - Added X signatures for Your Component - Covers initialization, API calls, and error handling - Tested against version X.Y.Z binaries\" git push origin main Create a pull request with: - Title : Add signatures for [Component Name] - Description : Brief description of the component and signature sources - Testing : Mention how you tested the signatures","title":"Step 4: Submit Pull Request"},{"location":"binarysniffer/CONTRIBUTING/#quality-guidelines","text":"","title":"\u2705 Quality Guidelines"},{"location":"binarysniffer/CONTRIBUTING/#do","text":"\u2705 Test signatures against real binaries \u2705 Use descriptive signature IDs \u2705 Include variety of contexts (init, API, errors) \u2705 Set appropriate confidence levels \u2705 Add meaningful descriptions \u2705 Verify component information (license, publisher)","title":"DO:"},{"location":"binarysniffer/CONTRIBUTING/#dont","text":"\u274c Use overly generic strings (\"init\", \"error\", \"config\") \u274c Copy signatures from unrelated components \u274c Include too many low-confidence signatures \u274c Use extremely long patterns (>100 characters) \u274c Include personal/private information \u274c Submit without testing","title":"DON'T:"},{"location":"binarysniffer/CONTRIBUTING/#advanced-using-the-signature-generator","text":"For automated signature extraction from binaries: # Extract all strings from a binary strings binary_file.so > strings.txt # Filter for component-specific patterns grep -i \"component_name\" strings.txt # Use BinarySniffer's generator (if available) binarysniffer generate-signatures binary_file.so --component \"Component Name\"","title":"\ud83d\udee0 Advanced: Using the Signature Generator"},{"location":"binarysniffer/CONTRIBUTING/#signature-database-statistics","text":"Current signature database includes: - 120+ components from major software vendors - 8,700+ signatures covering popular OSS libraries - Categories : Mobile SDKs, Enterprise Java, Media Processing, Networking, etc. - Platforms : Android, iOS, Linux, Windows, macOS, Web","title":"\ud83d\udcca Signature Database Statistics"},{"location":"binarysniffer/CONTRIBUTING/#recognition","text":"Contributors will be: - Listed in release notes - Credited in signature metadata - Mentioned in project documentation - Invited to join the project maintainers (for significant contributions)","title":"\ud83c\udf89 Recognition"},{"location":"binarysniffer/CONTRIBUTING/#support","text":"Need help contributing? - \ud83d\udce7 Create an issue with the contribution-help label - \ud83d\udcac Ask questions in pull request comments - \ud83d\udcd6 Check existing signatures for examples - \ud83d\udd0d Search the documentation","title":"\ud83d\udcde Support"},{"location":"binarysniffer/CONTRIBUTING/#future-enhancements","text":"We're working on: - Automated signature extraction from popular package managers (Note: This feature assumes availability of source code alongside binaries, which is not always the case. As such, automated signature creation from package managers is considered out of scope for the CLI tool and will be implemented in a separate scanning orchestrator) - Binary analysis tools for signature discovery - Community signature validation system - Integration with vulnerability databases Thank you for helping make BinarySniffer better for everyone! \ud83d\ude4f","title":"\ud83d\ude80 Future Enhancements"},{"location":"binarysniffer/README_ORIGINAL/","text":"BinarySniffer - Binary Static Analyzer A high-performance CLI tool and Python library for detecting open source components and security threats in binaries through semantic signature matching. Specialized for analyzing mobile apps (APK/IPA), Java archives, ML models, and source code to identify OSS components, their licenses, and potential security risks. Features Core Analysis Fuzzy Matching : Detect modified, recompiled, or patched OSS components using TLSH Deterministic Results : Consistent analysis results across multiple runs Fast Local Analysis : SQLite-based signature storage with optimized direct matching Efficient Matching : MinHash LSH for similarity detection, trigram indexing for substring matching Dual Interface : Use as CLI tool or Python library Smart Compression : ZSTD-compressed signatures with ~90% size reduction Low Memory Footprint : Streaming analysis with <100MB memory usage SBOM Export Support CycloneDX Format : Industry-standard SBOM export for security and compliance toolchains File Path Tracking : Evidence includes file paths for component location tracking Feature Extraction : Optional feature dump for signature recreation Confidence Scores : All detections include confidence levels in SBOM Multi-file Support : Aggregate SBOM for entire projects Package Inventory Extraction Comprehensive File Enumeration : Extract complete file listings from archives Rich Metadata : MIME types, compression ratios, file sizes, timestamps Hash Calculation : MD5, SHA1, SHA256 for integrity verification Fuzzy Hashing : TLSH and ssdeep for similarity analysis Component Detection : Run OSS detection on individual files within packages Multiple Export Formats : JSON, CSV, tree visualization, summary reports Binary Analysis Advanced Format Support : ELF, PE, Mach-O analysis with symbol and import extraction via LIEF Static Library Support : Parse and analyze .a archives, examining each object file separately Android DEX Support : Specialized extractor for DEX bytecode files Improved Detection : 25+ components detected in APK files with 152K+ features extracted Substring Matching : Detects components even with partial pattern matches Progress Indication : Real-time progress bars for long analysis operations Archive Support Mobile Applications : Android APK and iOS IPA with manifest parsing and native library analysis Java Archives : JAR/WAR files with MANIFEST.MF parsing and package detection Python Packages : Wheels (.whl) and eggs (.egg) with metadata extraction Linux Packages : DEB (Debian/Ubuntu) and RPM (Red Hat/Fedora) packages Extended Formats : 7z, RAR, Zstandard (.zst, .tar.zst), CPIO Nested Archives : Handle archives containing other archives (up to 5 levels deep) Intelligent Extraction : Prioritizes binaries, bytecode, and source files for analysis Source Code Analysis CTags Integration : Advanced source code analysis when universal-ctags is available Multi-language Support : C/C++, Python, Java, JavaScript, Go, Rust, PHP, Swift, Kotlin Semantic Symbol Extraction : Functions, classes, structs, constants, and dependencies Graceful Fallback : Regex-based extraction when CTags is unavailable ML Model Security Analysis (v1.10.0+) Comprehensive Security Module : Deep analysis of ML models for security threats MITRE ATT&CK Integration : Maps threats to ATT&CK framework techniques Multi-Level Risk Assessment : SAFE, LOW, MEDIUM, HIGH, CRITICAL risk levels Pickle File Parser : Safe analysis of Python pickle files without code execution ONNX Model Parser : Comprehensive analysis of ONNX format models SafeTensors Parser : Validation of secure tensor storage format PyTorch/TensorFlow Native : Handles .pt, .pth, .pb, .h5 native formats Malicious Detection : 100% detection rate on real-world ML exploits Framework Detection : Identifies PyTorch (96%), TensorFlow, sklearn (94%), XGBoost (77%) origins Obfuscation Detection : Entropy analysis and pattern matching for hidden threats Model Integrity Validation : Hash verification and tampering detection Architecture Recognition : Detects ResNet, BERT, YOLO, LLaMA, ViT, etc. Format Validation : Detects tampering, injection attempts, and format violations Malformed File Detection : Identifies corrupted or invalid model files with clear warnings Data Exfiltration Detection : Flags oversized tensors and suspicious patterns Supply Chain Security : Verifies model provenance and integrity SARIF Output : CI/CD integration with GitHub Actions and security tools Security-Enhanced SBOM : CycloneDX format with ML security metadata Signature Database 188 OSS Components : Comprehensive coverage including libraries, frameworks, ML models, and multimedia codecs 1,400+ Total Signatures : High-quality patterns with improved accuracy and reduced false positives Multimedia Support : H.264/H.265, AAC, Dolby, AV1, GStreamer, GLib, FFmpeg components System Libraries : libcap, Expat XML, LZ4, XZ Utils, WebP, cURL, Cairo, Opus License Detection : Automatic license identification for detected components Security Analysis : Detection of malicious patterns with severity levels (CRITICAL, HIGH, MEDIUM, LOW) Rich Metadata : Publisher, version, and ecosystem information for each component Installation From PyPI pip install binarysniffer From Source git clone https://github.com/SemClone/binarysniffer cd binarysniffer pip install -e . With Performance Extras pip install binarysniffer[fast] With Fuzzy Matching Support # Includes TLSH for detecting modified/recompiled components pip install binarysniffer[fuzzy] With Extended Archive Support # Includes support for 7z, RAR, DEB, RPM formats pip install binarysniffer[archives] With Android APK Analysis # Includes Androguard for advanced APK analysis pip install binarysniffer[android] Optional Tools for Enhanced Format Support BinarySniffer can leverage external tools when available to provide enhanced analysis capabilities. These tools are optional - the core functionality works without them, but installing them unlocks additional features. Quick Reference: Archive Format Requirements Format Python Package System Tool (Alternative) Fallback 7z py7zr (included) 7-Zip - RAR rarfile (included) unrar 7-Zip DEB python-debian (included) ar 7-Zip RPM - rpm2cpio 7-Zip ZIP/JAR Built-in - - TAR/GZ Built-in - - 7-Zip (Recommended) Enables : Extraction and analysis of Windows installers, macOS packages, and additional compressed formats # macOS brew install p7zip # Ubuntu/Debian sudo apt-get install p7zip-full # Windows # Download from https://www.7-zip.org/ Benefits : - Analyze Windows installers (.exe, .msi) by extracting embedded components - Analyze macOS installers (.pkg, .dmg) to detect bundled frameworks - Support for NSIS, InnoSetup, and other installer formats - Extract and analyze self-extracting archives - Support for additional archive formats (RAR, CAB, ISO, etc.) Tools for Extended Archive Support (Optional) When using the [archives] installation option, these tools enhance format support: DEB Package Analysis # For DEB packages (Debian/Ubuntu) # Option 1: Install python-debian (included with [archives]) pip install binarysniffer[archives] # Option 2: Use system ar command (usually pre-installed) # Ubuntu/Debian which ar # Check if available # macOS # ar is included with Xcode Command Line Tools xcode-select --install # If not already installed RPM Package Analysis # For RPM packages (Red Hat/Fedora/CentOS) # Option 1: Install rpm2cpio # Ubuntu/Debian sudo apt-get install rpm2cpio # macOS brew install rpm2cpio # Fedora/RHEL/CentOS # rpm2cpio is usually pre-installed # Option 2: Falls back to 7-Zip if available Additional Archive Formats The [archives] option includes Python libraries for: - 7z files : py7zr (pure Python, no external tools needed) - RAR files : rarfile (requires unrar tool) ```bash # Install unrar for RAR support # Ubuntu/Debian sudo apt-get install unrar # macOS brew install unrar # Note: Falls back to 7-Zip if unrar not available ``` Universal CTags (Optional) Enables : Enhanced source code analysis with semantic understanding # macOS brew install universal-ctags # Ubuntu/Debian sudo apt-get install universal-ctags # Windows # Download from https://github.com/universal-ctags/ctags-win32/releases Benefits : - Better function/class/method detection in source code - Multi-language semantic analysis - More accurate symbol extraction - Improved signature matching for source code components Example: Analyzing Installers Without 7-Zip: $ binarysniffer analyze installer.exe # Analyzes as compressed binary - limited detection With 7-Zip installed: # Windows installers $ binarysniffer analyze installer.exe $ binarysniffer analyze setup.msi # Automatically extracts and analyzes contents # Detects: Qt5, OpenSSL, SQLite, ICU, libpng, etc. # macOS installers $ binarysniffer analyze app.pkg $ binarysniffer analyze app.dmg # Automatically extracts and analyzes contents # Detects: Qt5, WebKit, OpenCV, React Native, etc. Quick Start CLI Usage # Basic analysis binarysniffer analyze /path/to/binary binarysniffer analyze app.apk # Android APK binarysniffer analyze app.ipa # iOS IPA binarysniffer analyze library.jar # Java JAR # ML model component detection binarysniffer analyze model.pkl # Pickle files binarysniffer analyze model.onnx # ONNX models binarysniffer analyze model.safetensors # SafeTensors format binarysniffer analyze suspicious_model.pkl --show-features # Detailed analysis # ML model security scanning (v1.10.0+) binarysniffer ml-scan model.pkl # Security analysis of ML models binarysniffer ml-scan model.pkl --deep # Deep security analysis binarysniffer ml-scan models/ -r --format sarif # SARIF output for CI/CD binarysniffer ml-scan model.pkl -o report.md # Markdown security report binarysniffer ml-scan model.pkl --risk-threshold 0.5 # Custom risk threshold # Analyze directories recursively binarysniffer analyze /path/to/project -r # Output with auto-format detection binarysniffer analyze app.apk -o report.json # Auto-detects JSON format binarysniffer analyze app.apk -o report.csv # Auto-detects CSV format binarysniffer analyze app.apk -o app.sbom # Auto-detects SBOM format # Performance modes binarysniffer analyze large.bin --fast # Quick scan (no fuzzy matching) binarysniffer analyze app.apk --deep # Thorough analysis # Custom confidence threshold binarysniffer analyze file.exe -t 0.3 # More sensitive (30% confidence) binarysniffer analyze file.exe -t 0.8 # More conservative (80% confidence) # Include file hashes in output binarysniffer analyze file.exe --with-hashes -o report.json binarysniffer analyze file.exe --basic-hashes # Only MD5, SHA1, SHA256 # Filter by file patterns binarysniffer analyze project/ -r -p \"*.so\" -p \"*.dll\" # Export as CycloneDX SBOM binarysniffer analyze app.apk -f sbom -o app-sbom.json binarysniffer analyze app.apk --format cyclonedx -o sbom.json # Save features for signature creation binarysniffer analyze binary.exe --save-features features.json --show-features # Filter results binarysniffer analyze lib.so --min-matches 5 # Show components with 5+ matches binarysniffer analyze app.apk --show-evidence # Show detailed match evidence Understanding the Output The analysis results display a Classification column that shows either: - Software licenses (e.g., Apache-2.0, BSD-3-Clause, MIT) for legitimate OSS components - Security severity levels (CRITICAL, HIGH, MEDIUM, LOW) for detected threats Example output: \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Component \u2503 Confidence \u2503 Classification \u2503 Type \u2503 Evidence \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 PyTorch-Native \u2502 94.0% \u2502 BSD-3-Clause \u2502 library\u2502 2 patterns \u2502 \u2502 SafeTensors \u2502 90.0% \u2502 Apache-2.0 \u2502 library\u2502 3 patterns \u2502 \u2502 Pickle-Malicious \u2502 98.5% \u2502 CRITICAL \u2502 threat \u2502 RCE risk detected\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 Python Library Usage from binarysniffer import EnhancedBinarySniffer # Initialize analyzer (enhanced mode is default) sniffer = EnhancedBinarySniffer() # Analyze a single file result = sniffer.analyze_file(\"/path/to/binary\") for match in result.matches: print(f\"{match.component} - {match.confidence:.2%}\") print(f\"Classification: {match.license}\") # Shows license or severity level # Analyze mobile applications apk_result = sniffer.analyze_file(\"app.apk\") ipa_result = sniffer.analyze_file(\"app.ipa\") jar_result = sniffer.analyze_file(\"library.jar\") # Analyze with custom threshold (default is 0.5) result = sniffer.analyze_file(\"file.exe\", confidence_threshold=0.3) # More sensitive result = sniffer.analyze_file(\"file.exe\", confidence_threshold=0.8) # More conservative # Analyze with file hashes result = sniffer.analyze_file(\"file.exe\", include_hashes=True, include_fuzzy_hashes=True) # Directory analysis results = sniffer.analyze_directory(\"/path/to/project\", recursive=True) for file_path, result in results.items(): if result.matches: print(f\"{file_path}: {len(result.matches)} components detected\") # TLSH fuzzy matching for modified components result = sniffer.analyze_file( \"modified_binary.exe\", use_tlsh=True, # Enable TLSH fuzzy matching (default) tlsh_threshold=50 # Lower threshold = more similar required ) for match in result.matches: if match.match_type == 'tlsh_fuzzy': print(f\"Fuzzy match: {match.component} (similarity: {match.confidence:.0%})\") SBOM Export (v1.8.6+) Generate Software Bill of Materials in CycloneDX format for integration with security and compliance tools: # Export single file analysis as SBOM binarysniffer analyze app.apk --format cyclonedx -o app-sbom.json # Export directory analysis as aggregated SBOM binarysniffer analyze project/ -r --format cdx -o project-sbom.json # Include extracted features for signature recreation binarysniffer analyze binary.exe --format cyclonedx --show-features -o sbom-with-features.json The SBOM includes: - Component names, versions, and licenses - Confidence scores for each detection - File paths showing where components were found - Evidence details including matched patterns - Optional extracted features for signature recreation Package Inventory Extraction (v1.8.6+) Extract comprehensive file inventories from packages with metadata, hashes, and component detection: # Basic inventory summary binarysniffer inventory app.apk # Export full inventory with auto-format detection binarysniffer inventory app.apk -o inventory.json binarysniffer inventory app.jar -o files.csv # Include file hashes (MD5, SHA1, SHA256, TLSH, ssdeep) binarysniffer inventory app.jar --analyze --with-hashes -o files.csv # Full analysis with component detection binarysniffer inventory app.ipa \\ --analyze \\ --with-hashes \\ --with-components \\ -o full_inventory.json # Export as directory tree visualization binarysniffer inventory archive.zip --format tree -o structure.txt Python API for Inventory Extraction from binarysniffer import EnhancedBinarySniffer sniffer = EnhancedBinarySniffer() # Basic inventory extraction inventory = sniffer.extract_package_inventory(\"app.apk\") print(f\"Total files: {inventory['summary']['total_files']}\") print(f\"Package size: {inventory['package_size']:,} bytes\") # Full analysis with all features inventory = sniffer.extract_package_inventory( \"app.apk\", analyze_contents=True, # Extract and analyze file contents include_hashes=True, # Calculate MD5, SHA1, SHA256 include_fuzzy_hashes=True, # Calculate TLSH and ssdeep detect_components=True # Run OSS component detection ) # Access comprehensive file metadata for file_entry in inventory['files']: if not file_entry['is_directory']: print(f\"File: {file_entry['path']}\") print(f\" MIME: {file_entry['mime_type']}\") print(f\" Size: {file_entry['size']:,} bytes\") print(f\" Compression ratio: {file_entry['compression_ratio']:.1%}\") if 'hashes' in file_entry: print(f\" SHA256: {file_entry['hashes']['sha256']}\") if 'components' in file_entry: for comp in file_entry['components']: print(f\" Component: {comp['name']} ({comp['confidence']:.0%})\") Inventory Export Formats JSON : Complete structured data with all metadata CSV : Tabular format for data analysis (includes hashes, MIME types, components) Tree : Visual directory structure representation Summary : Quick overview with file type statistics License Detection (v1.8.9+) Detect and analyze software licenses using pattern matching and SPDX identifier recognition: # Analyze licenses in a file or directory binarysniffer license /path/to/project # Check license compatibility binarysniffer license . --check-compatibility # Show which files contain each license binarysniffer license src/ --show-files # Export license report binarysniffer license app.apk -o licenses.json binarysniffer license project/ -o report.md --format markdown Integrated License Detection with Analysis Combine component and license detection in a single analysis: # Add license detection to regular analysis binarysniffer analyze app.jar --license-focus # Perform only license detection (skip component analysis) binarysniffer analyze source/ --license-only Python API for License Detection from binarysniffer import EnhancedBinarySniffer sniffer = EnhancedBinarySniffer() # Analyze licenses in a project license_result = sniffer.analyze_licenses(\"/path/to/project\") print(f\"Detected licenses: {', '.join(license_result['licenses_detected'])}\") # Check compatibility compatibility = license_result['compatibility'] if not compatibility['compatible']: for warning in compatibility['warnings']: print(f\"Warning: {warning}\") Features Pattern-based detection for common licenses (MIT, Apache-2.0, GPL, BSD, LGPL, ISC) SPDX identifier support with 100% confidence License compatibility checking to identify conflicts Multiple output formats : Table, JSON, CSV, Markdown Works on : License files, source code with embedded licenses, archives Creating and Contributing Signatures Generate Signatures from Binaries or Source Code Create custom signatures for components you want to detect: # From binary files (recommended for compiled components) binarysniffer signatures create /usr/bin/ffmpeg --name FFmpeg --version 4.4.1 # From source code directories binarysniffer signatures create /path/to/source --name MyLibrary --license MIT # With complete metadata for better attribution binarysniffer signatures create binary.so \\ --name \"My Component\" \\ --version 2.0.0 \\ --license Apache-2.0 \\ --publisher \"My Company\" \\ --description \"Component description\" \\ --output signatures/my-component.json # Specify minimum signature requirements binarysniffer signatures create /path/to/library \\ --name \"LibraryName\" \\ --min-signatures 10 # Require at least 10 unique patterns Collision Detection for Signature Quality The signature generator includes automatic collision detection to identify patterns that appear in multiple existing components: # Check for collisions with existing signatures binarysniffer signatures create /usr/bin/myapp \\ --name \"MyApp\" \\ --check-collisions # Interactive review - decide on each collision binarysniffer signatures create /usr/bin/myapp \\ --name \"MyApp\" \\ --interactive # Auto-remove patterns with high collision severity binarysniffer signatures create /usr/bin/myapp \\ --name \"MyApp\" \\ --check-collisions \\ --collision-threshold high # Remove patterns in 3+ components Collision Severity Levels: - Critical : Pattern appears in 5+ unrelated components (likely generic) - High : Pattern appears in 3-4 components - Medium : Pattern appears in 2 unrelated components - Low : Pattern appears in 2 related components (e.g., ffmpeg/libav) Features: - Automatic generic word filtering (100+ common programming terms) - Smart deduplication - all signatures are unique - Cross-signature collision detection - Interactive and automatic filtering modes - Preserves library-specific prefixes (av_, curl_, SSL_, etc.) Contributing Signatures to the Community Help improve detection by contributing your signatures: Generate the signature file : bash binarysniffer signatures create /path/to/component \\ --name \"Component Name\" \\ --version \"1.0.0\" \\ --license \"MIT\" \\ --publisher \"Publisher Name\" \\ --output signatures/component-name.json Test your signature : ```bash # Import locally for testing binarysniffer signatures import signatures/component-name.json # Verify detection works binarysniffer analyze /path/to/test/binary ``` Submit via GitHub Pull Request : ```bash # Fork the repository on GitHub, then: git clone https://github.com/YOUR_USERNAME/binarysniffer cd binarysniffer # Add your signature file cp /path/to/component-name.json signatures/ # Commit and push git add signatures/component-name.json git commit -m \"Add signatures for Component Name v1.0.0\" git push origin main # Create a Pull Request on GitHub ``` For detailed contribution guidelines, see CONTRIBUTING.md . Architecture The tool uses a multi-tiered approach for efficient matching: Pattern Matching : Direct string/symbol matching against signature database MinHash LSH : Fast similarity search for near-duplicate detection (milliseconds) TLSH Fuzzy Matching : Locality-sensitive hashing to detect modified/recompiled components Detailed Verification : Precise signature verification with confidence scoring TLSH Fuzzy Matching (v1.8.0+) TLSH (Trend Micro Locality Sensitive Hash) enables detection of: - Modified Components : Components with patches or custom modifications - Recompiled Binaries : Same source code compiled with different options - Version Variants : Different versions of the same library - Obfuscated Code : Components with mild obfuscation or optimization The TLSH algorithm generates a compact hash that remains similar even when files are modified, making it ideal for detecting OSS components that have been customized or rebuilt. Performance Analysis Speed : ~1 second per binary file (5x faster in v1.6.3) Archive Processing : ~100-500ms for APK/IPA files (depends on contents) Signature Storage : ~3.5MB database with 5,136 signatures from 131 components Memory Usage : <100MB during analysis, <200MB for large archives Deterministic Results : Consistent detection across runs (NEW in v1.6.3) Configuration Configuration file location: ~/.binarysniffer/config.json { \"signature_sources\": [ \"https://signatures.binarysniffer.io/core.xmdb\" ], \"cache_size_mb\": 100, \"parallel_workers\": 4, \"min_confidence\": 0.5, \"auto_update\": true, \"update_check_interval_days\": 7 } Signature Database The tool includes a pre-built signature database with 131 OSS components including: - Mobile SDKs : Facebook Android SDK, Google Firebase, Google Ads - Java Libraries : Jackson, Apache Commons, Google Guava, Netty - Media Libraries : FFmpeg, x264, x265, Vorbis, Opus - Crypto Libraries : Bounty Castle, mbedTLS variants - Development Tools : Lombok, Dagger, RxJava, OkHttp Signature Management Maintaining an up-to-date signature database is critical for accurate detection. BinarySniffer provides comprehensive signature management commands: Viewing Signature Status # Check current signature database status binarysniffer signatures status # Shows: total signatures, components, last update, database location # View detailed statistics binarysniffer signatures stats # Shows: signatures per component, database size, index status Updating Signatures # Update signatures from GitHub repository (recommended) binarysniffer signatures update # Pulls latest community-contributed signatures # Alternative update command (backward compatible) binarysniffer update # Force update even if current binarysniffer signatures update --force Rebuilding Database # Rebuild database from packaged signatures binarysniffer signatures rebuild # Useful when database is corrupted or needs fresh start # Import specific signature files binarysniffer signatures import signatures/*.json # Import from custom directory binarysniffer signatures import /path/to/signatures --recursive Creating Custom Signatures # Create signature from binary binarysniffer signatures create /usr/bin/curl \\ --name \"curl\" \\ --version 7.81.0 \\ --license \"MIT\" \\ --output signatures/curl.json # Create from source code directory binarysniffer signatures create /path/to/source \\ --name \"MyLibrary\" \\ --version 1.0.0 \\ --license \"Apache-2.0\" \\ --min-length 8 # Minimum pattern length # Create with metadata binarysniffer signatures create binary.so \\ --name \"Custom Component\" \\ --publisher \"My Company\" \\ --description \"Custom implementation\" \\ --url \"https://github.com/mycompany/component\" Signature Validation # Validate signature quality before adding binarysniffer signatures validate signatures/new-component.json # Checks for: generic patterns, minimum length, uniqueness # Test signature against known files binarysniffer signatures test signatures/component.json /path/to/test/files Database Management # Export signatures to JSON (for backup or sharing) binarysniffer signatures export --output my-signatures/ # Creates one JSON file per component # Clear database (use with caution) binarysniffer signatures clear --confirm # Removes all signatures from database # Optimize database binarysniffer signatures optimize # Rebuilds indexes and vacuums database for better performance Automated Updates Configure automatic signature updates in ~/.binarysniffer/config.json : { \"auto_update\": true, \"update_check_interval_days\": 7, \"signature_sources\": [ \"https://github.com/oscarvalenzuelab/binarysniffer-signatures\" ] } Best Practices Regular Updates : Run binarysniffer signatures update weekly for latest detections Custom Signatures : Create signatures for proprietary components you want to track Validation : Always validate new signatures to avoid false positives Backup : Export signatures before major updates using signatures export Performance : Run signatures optimize monthly for best performance For detailed signature creation and management documentation, see docs/SIGNATURE_MANAGEMENT.md . License Apache License 2.0 - See LICENSE file for details. Contributing Contributions are welcome! Please read our Contributing Guide for details on our code of conduct and the process for submitting pull requests.","title":"BinarySniffer - Binary Static Analyzer"},{"location":"binarysniffer/README_ORIGINAL/#binarysniffer-binary-static-analyzer","text":"A high-performance CLI tool and Python library for detecting open source components and security threats in binaries through semantic signature matching. Specialized for analyzing mobile apps (APK/IPA), Java archives, ML models, and source code to identify OSS components, their licenses, and potential security risks.","title":"BinarySniffer - Binary Static Analyzer"},{"location":"binarysniffer/README_ORIGINAL/#features","text":"","title":"Features"},{"location":"binarysniffer/README_ORIGINAL/#core-analysis","text":"Fuzzy Matching : Detect modified, recompiled, or patched OSS components using TLSH Deterministic Results : Consistent analysis results across multiple runs Fast Local Analysis : SQLite-based signature storage with optimized direct matching Efficient Matching : MinHash LSH for similarity detection, trigram indexing for substring matching Dual Interface : Use as CLI tool or Python library Smart Compression : ZSTD-compressed signatures with ~90% size reduction Low Memory Footprint : Streaming analysis with <100MB memory usage","title":"Core Analysis"},{"location":"binarysniffer/README_ORIGINAL/#sbom-export-support","text":"CycloneDX Format : Industry-standard SBOM export for security and compliance toolchains File Path Tracking : Evidence includes file paths for component location tracking Feature Extraction : Optional feature dump for signature recreation Confidence Scores : All detections include confidence levels in SBOM Multi-file Support : Aggregate SBOM for entire projects","title":"SBOM Export Support"},{"location":"binarysniffer/README_ORIGINAL/#package-inventory-extraction","text":"Comprehensive File Enumeration : Extract complete file listings from archives Rich Metadata : MIME types, compression ratios, file sizes, timestamps Hash Calculation : MD5, SHA1, SHA256 for integrity verification Fuzzy Hashing : TLSH and ssdeep for similarity analysis Component Detection : Run OSS detection on individual files within packages Multiple Export Formats : JSON, CSV, tree visualization, summary reports","title":"Package Inventory Extraction"},{"location":"binarysniffer/README_ORIGINAL/#binary-analysis","text":"Advanced Format Support : ELF, PE, Mach-O analysis with symbol and import extraction via LIEF Static Library Support : Parse and analyze .a archives, examining each object file separately Android DEX Support : Specialized extractor for DEX bytecode files Improved Detection : 25+ components detected in APK files with 152K+ features extracted Substring Matching : Detects components even with partial pattern matches Progress Indication : Real-time progress bars for long analysis operations","title":"Binary Analysis"},{"location":"binarysniffer/README_ORIGINAL/#archive-support","text":"Mobile Applications : Android APK and iOS IPA with manifest parsing and native library analysis Java Archives : JAR/WAR files with MANIFEST.MF parsing and package detection Python Packages : Wheels (.whl) and eggs (.egg) with metadata extraction Linux Packages : DEB (Debian/Ubuntu) and RPM (Red Hat/Fedora) packages Extended Formats : 7z, RAR, Zstandard (.zst, .tar.zst), CPIO Nested Archives : Handle archives containing other archives (up to 5 levels deep) Intelligent Extraction : Prioritizes binaries, bytecode, and source files for analysis","title":"Archive Support"},{"location":"binarysniffer/README_ORIGINAL/#source-code-analysis","text":"CTags Integration : Advanced source code analysis when universal-ctags is available Multi-language Support : C/C++, Python, Java, JavaScript, Go, Rust, PHP, Swift, Kotlin Semantic Symbol Extraction : Functions, classes, structs, constants, and dependencies Graceful Fallback : Regex-based extraction when CTags is unavailable","title":"Source Code Analysis"},{"location":"binarysniffer/README_ORIGINAL/#ml-model-security-analysis-v1100","text":"Comprehensive Security Module : Deep analysis of ML models for security threats MITRE ATT&CK Integration : Maps threats to ATT&CK framework techniques Multi-Level Risk Assessment : SAFE, LOW, MEDIUM, HIGH, CRITICAL risk levels Pickle File Parser : Safe analysis of Python pickle files without code execution ONNX Model Parser : Comprehensive analysis of ONNX format models SafeTensors Parser : Validation of secure tensor storage format PyTorch/TensorFlow Native : Handles .pt, .pth, .pb, .h5 native formats Malicious Detection : 100% detection rate on real-world ML exploits Framework Detection : Identifies PyTorch (96%), TensorFlow, sklearn (94%), XGBoost (77%) origins Obfuscation Detection : Entropy analysis and pattern matching for hidden threats Model Integrity Validation : Hash verification and tampering detection Architecture Recognition : Detects ResNet, BERT, YOLO, LLaMA, ViT, etc. Format Validation : Detects tampering, injection attempts, and format violations Malformed File Detection : Identifies corrupted or invalid model files with clear warnings Data Exfiltration Detection : Flags oversized tensors and suspicious patterns Supply Chain Security : Verifies model provenance and integrity SARIF Output : CI/CD integration with GitHub Actions and security tools Security-Enhanced SBOM : CycloneDX format with ML security metadata","title":"ML Model Security Analysis (v1.10.0+)"},{"location":"binarysniffer/README_ORIGINAL/#signature-database","text":"188 OSS Components : Comprehensive coverage including libraries, frameworks, ML models, and multimedia codecs 1,400+ Total Signatures : High-quality patterns with improved accuracy and reduced false positives Multimedia Support : H.264/H.265, AAC, Dolby, AV1, GStreamer, GLib, FFmpeg components System Libraries : libcap, Expat XML, LZ4, XZ Utils, WebP, cURL, Cairo, Opus License Detection : Automatic license identification for detected components Security Analysis : Detection of malicious patterns with severity levels (CRITICAL, HIGH, MEDIUM, LOW) Rich Metadata : Publisher, version, and ecosystem information for each component","title":"Signature Database"},{"location":"binarysniffer/README_ORIGINAL/#installation","text":"","title":"Installation"},{"location":"binarysniffer/README_ORIGINAL/#from-pypi","text":"pip install binarysniffer","title":"From PyPI"},{"location":"binarysniffer/README_ORIGINAL/#from-source","text":"git clone https://github.com/SemClone/binarysniffer cd binarysniffer pip install -e .","title":"From Source"},{"location":"binarysniffer/README_ORIGINAL/#with-performance-extras","text":"pip install binarysniffer[fast]","title":"With Performance Extras"},{"location":"binarysniffer/README_ORIGINAL/#with-fuzzy-matching-support","text":"# Includes TLSH for detecting modified/recompiled components pip install binarysniffer[fuzzy]","title":"With Fuzzy Matching Support"},{"location":"binarysniffer/README_ORIGINAL/#with-extended-archive-support","text":"# Includes support for 7z, RAR, DEB, RPM formats pip install binarysniffer[archives]","title":"With Extended Archive Support"},{"location":"binarysniffer/README_ORIGINAL/#with-android-apk-analysis","text":"# Includes Androguard for advanced APK analysis pip install binarysniffer[android]","title":"With Android APK Analysis"},{"location":"binarysniffer/README_ORIGINAL/#optional-tools-for-enhanced-format-support","text":"BinarySniffer can leverage external tools when available to provide enhanced analysis capabilities. These tools are optional - the core functionality works without them, but installing them unlocks additional features.","title":"Optional Tools for Enhanced Format Support"},{"location":"binarysniffer/README_ORIGINAL/#quick-reference-archive-format-requirements","text":"Format Python Package System Tool (Alternative) Fallback 7z py7zr (included) 7-Zip - RAR rarfile (included) unrar 7-Zip DEB python-debian (included) ar 7-Zip RPM - rpm2cpio 7-Zip ZIP/JAR Built-in - - TAR/GZ Built-in - -","title":"Quick Reference: Archive Format Requirements"},{"location":"binarysniffer/README_ORIGINAL/#7-zip-recommended","text":"Enables : Extraction and analysis of Windows installers, macOS packages, and additional compressed formats # macOS brew install p7zip # Ubuntu/Debian sudo apt-get install p7zip-full # Windows # Download from https://www.7-zip.org/ Benefits : - Analyze Windows installers (.exe, .msi) by extracting embedded components - Analyze macOS installers (.pkg, .dmg) to detect bundled frameworks - Support for NSIS, InnoSetup, and other installer formats - Extract and analyze self-extracting archives - Support for additional archive formats (RAR, CAB, ISO, etc.)","title":"7-Zip (Recommended)"},{"location":"binarysniffer/README_ORIGINAL/#tools-for-extended-archive-support-optional","text":"When using the [archives] installation option, these tools enhance format support:","title":"Tools for Extended Archive Support (Optional)"},{"location":"binarysniffer/README_ORIGINAL/#deb-package-analysis","text":"# For DEB packages (Debian/Ubuntu) # Option 1: Install python-debian (included with [archives]) pip install binarysniffer[archives] # Option 2: Use system ar command (usually pre-installed) # Ubuntu/Debian which ar # Check if available # macOS # ar is included with Xcode Command Line Tools xcode-select --install # If not already installed","title":"DEB Package Analysis"},{"location":"binarysniffer/README_ORIGINAL/#rpm-package-analysis","text":"# For RPM packages (Red Hat/Fedora/CentOS) # Option 1: Install rpm2cpio # Ubuntu/Debian sudo apt-get install rpm2cpio # macOS brew install rpm2cpio # Fedora/RHEL/CentOS # rpm2cpio is usually pre-installed # Option 2: Falls back to 7-Zip if available","title":"RPM Package Analysis"},{"location":"binarysniffer/README_ORIGINAL/#additional-archive-formats","text":"The [archives] option includes Python libraries for: - 7z files : py7zr (pure Python, no external tools needed) - RAR files : rarfile (requires unrar tool) ```bash # Install unrar for RAR support # Ubuntu/Debian sudo apt-get install unrar # macOS brew install unrar # Note: Falls back to 7-Zip if unrar not available ```","title":"Additional Archive Formats"},{"location":"binarysniffer/README_ORIGINAL/#universal-ctags-optional","text":"Enables : Enhanced source code analysis with semantic understanding # macOS brew install universal-ctags # Ubuntu/Debian sudo apt-get install universal-ctags # Windows # Download from https://github.com/universal-ctags/ctags-win32/releases Benefits : - Better function/class/method detection in source code - Multi-language semantic analysis - More accurate symbol extraction - Improved signature matching for source code components","title":"Universal CTags (Optional)"},{"location":"binarysniffer/README_ORIGINAL/#example-analyzing-installers","text":"Without 7-Zip: $ binarysniffer analyze installer.exe # Analyzes as compressed binary - limited detection With 7-Zip installed: # Windows installers $ binarysniffer analyze installer.exe $ binarysniffer analyze setup.msi # Automatically extracts and analyzes contents # Detects: Qt5, OpenSSL, SQLite, ICU, libpng, etc. # macOS installers $ binarysniffer analyze app.pkg $ binarysniffer analyze app.dmg # Automatically extracts and analyzes contents # Detects: Qt5, WebKit, OpenCV, React Native, etc.","title":"Example: Analyzing Installers"},{"location":"binarysniffer/README_ORIGINAL/#quick-start","text":"","title":"Quick Start"},{"location":"binarysniffer/README_ORIGINAL/#cli-usage","text":"# Basic analysis binarysniffer analyze /path/to/binary binarysniffer analyze app.apk # Android APK binarysniffer analyze app.ipa # iOS IPA binarysniffer analyze library.jar # Java JAR # ML model component detection binarysniffer analyze model.pkl # Pickle files binarysniffer analyze model.onnx # ONNX models binarysniffer analyze model.safetensors # SafeTensors format binarysniffer analyze suspicious_model.pkl --show-features # Detailed analysis # ML model security scanning (v1.10.0+) binarysniffer ml-scan model.pkl # Security analysis of ML models binarysniffer ml-scan model.pkl --deep # Deep security analysis binarysniffer ml-scan models/ -r --format sarif # SARIF output for CI/CD binarysniffer ml-scan model.pkl -o report.md # Markdown security report binarysniffer ml-scan model.pkl --risk-threshold 0.5 # Custom risk threshold # Analyze directories recursively binarysniffer analyze /path/to/project -r # Output with auto-format detection binarysniffer analyze app.apk -o report.json # Auto-detects JSON format binarysniffer analyze app.apk -o report.csv # Auto-detects CSV format binarysniffer analyze app.apk -o app.sbom # Auto-detects SBOM format # Performance modes binarysniffer analyze large.bin --fast # Quick scan (no fuzzy matching) binarysniffer analyze app.apk --deep # Thorough analysis # Custom confidence threshold binarysniffer analyze file.exe -t 0.3 # More sensitive (30% confidence) binarysniffer analyze file.exe -t 0.8 # More conservative (80% confidence) # Include file hashes in output binarysniffer analyze file.exe --with-hashes -o report.json binarysniffer analyze file.exe --basic-hashes # Only MD5, SHA1, SHA256 # Filter by file patterns binarysniffer analyze project/ -r -p \"*.so\" -p \"*.dll\" # Export as CycloneDX SBOM binarysniffer analyze app.apk -f sbom -o app-sbom.json binarysniffer analyze app.apk --format cyclonedx -o sbom.json # Save features for signature creation binarysniffer analyze binary.exe --save-features features.json --show-features # Filter results binarysniffer analyze lib.so --min-matches 5 # Show components with 5+ matches binarysniffer analyze app.apk --show-evidence # Show detailed match evidence","title":"CLI Usage"},{"location":"binarysniffer/README_ORIGINAL/#understanding-the-output","text":"The analysis results display a Classification column that shows either: - Software licenses (e.g., Apache-2.0, BSD-3-Clause, MIT) for legitimate OSS components - Security severity levels (CRITICAL, HIGH, MEDIUM, LOW) for detected threats Example output: \u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513 \u2503 Component \u2503 Confidence \u2503 Classification \u2503 Type \u2503 Evidence \u2503 \u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529 \u2502 PyTorch-Native \u2502 94.0% \u2502 BSD-3-Clause \u2502 library\u2502 2 patterns \u2502 \u2502 SafeTensors \u2502 90.0% \u2502 Apache-2.0 \u2502 library\u2502 3 patterns \u2502 \u2502 Pickle-Malicious \u2502 98.5% \u2502 CRITICAL \u2502 threat \u2502 RCE risk detected\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Understanding the Output"},{"location":"binarysniffer/README_ORIGINAL/#python-library-usage","text":"from binarysniffer import EnhancedBinarySniffer # Initialize analyzer (enhanced mode is default) sniffer = EnhancedBinarySniffer() # Analyze a single file result = sniffer.analyze_file(\"/path/to/binary\") for match in result.matches: print(f\"{match.component} - {match.confidence:.2%}\") print(f\"Classification: {match.license}\") # Shows license or severity level # Analyze mobile applications apk_result = sniffer.analyze_file(\"app.apk\") ipa_result = sniffer.analyze_file(\"app.ipa\") jar_result = sniffer.analyze_file(\"library.jar\") # Analyze with custom threshold (default is 0.5) result = sniffer.analyze_file(\"file.exe\", confidence_threshold=0.3) # More sensitive result = sniffer.analyze_file(\"file.exe\", confidence_threshold=0.8) # More conservative # Analyze with file hashes result = sniffer.analyze_file(\"file.exe\", include_hashes=True, include_fuzzy_hashes=True) # Directory analysis results = sniffer.analyze_directory(\"/path/to/project\", recursive=True) for file_path, result in results.items(): if result.matches: print(f\"{file_path}: {len(result.matches)} components detected\") # TLSH fuzzy matching for modified components result = sniffer.analyze_file( \"modified_binary.exe\", use_tlsh=True, # Enable TLSH fuzzy matching (default) tlsh_threshold=50 # Lower threshold = more similar required ) for match in result.matches: if match.match_type == 'tlsh_fuzzy': print(f\"Fuzzy match: {match.component} (similarity: {match.confidence:.0%})\")","title":"Python Library Usage"},{"location":"binarysniffer/README_ORIGINAL/#sbom-export-v186","text":"Generate Software Bill of Materials in CycloneDX format for integration with security and compliance tools: # Export single file analysis as SBOM binarysniffer analyze app.apk --format cyclonedx -o app-sbom.json # Export directory analysis as aggregated SBOM binarysniffer analyze project/ -r --format cdx -o project-sbom.json # Include extracted features for signature recreation binarysniffer analyze binary.exe --format cyclonedx --show-features -o sbom-with-features.json The SBOM includes: - Component names, versions, and licenses - Confidence scores for each detection - File paths showing where components were found - Evidence details including matched patterns - Optional extracted features for signature recreation","title":"SBOM Export (v1.8.6+)"},{"location":"binarysniffer/README_ORIGINAL/#package-inventory-extraction-v186","text":"Extract comprehensive file inventories from packages with metadata, hashes, and component detection: # Basic inventory summary binarysniffer inventory app.apk # Export full inventory with auto-format detection binarysniffer inventory app.apk -o inventory.json binarysniffer inventory app.jar -o files.csv # Include file hashes (MD5, SHA1, SHA256, TLSH, ssdeep) binarysniffer inventory app.jar --analyze --with-hashes -o files.csv # Full analysis with component detection binarysniffer inventory app.ipa \\ --analyze \\ --with-hashes \\ --with-components \\ -o full_inventory.json # Export as directory tree visualization binarysniffer inventory archive.zip --format tree -o structure.txt","title":"Package Inventory Extraction (v1.8.6+)"},{"location":"binarysniffer/README_ORIGINAL/#python-api-for-inventory-extraction","text":"from binarysniffer import EnhancedBinarySniffer sniffer = EnhancedBinarySniffer() # Basic inventory extraction inventory = sniffer.extract_package_inventory(\"app.apk\") print(f\"Total files: {inventory['summary']['total_files']}\") print(f\"Package size: {inventory['package_size']:,} bytes\") # Full analysis with all features inventory = sniffer.extract_package_inventory( \"app.apk\", analyze_contents=True, # Extract and analyze file contents include_hashes=True, # Calculate MD5, SHA1, SHA256 include_fuzzy_hashes=True, # Calculate TLSH and ssdeep detect_components=True # Run OSS component detection ) # Access comprehensive file metadata for file_entry in inventory['files']: if not file_entry['is_directory']: print(f\"File: {file_entry['path']}\") print(f\" MIME: {file_entry['mime_type']}\") print(f\" Size: {file_entry['size']:,} bytes\") print(f\" Compression ratio: {file_entry['compression_ratio']:.1%}\") if 'hashes' in file_entry: print(f\" SHA256: {file_entry['hashes']['sha256']}\") if 'components' in file_entry: for comp in file_entry['components']: print(f\" Component: {comp['name']} ({comp['confidence']:.0%})\")","title":"Python API for Inventory Extraction"},{"location":"binarysniffer/README_ORIGINAL/#inventory-export-formats","text":"JSON : Complete structured data with all metadata CSV : Tabular format for data analysis (includes hashes, MIME types, components) Tree : Visual directory structure representation Summary : Quick overview with file type statistics","title":"Inventory Export Formats"},{"location":"binarysniffer/README_ORIGINAL/#license-detection-v189","text":"Detect and analyze software licenses using pattern matching and SPDX identifier recognition: # Analyze licenses in a file or directory binarysniffer license /path/to/project # Check license compatibility binarysniffer license . --check-compatibility # Show which files contain each license binarysniffer license src/ --show-files # Export license report binarysniffer license app.apk -o licenses.json binarysniffer license project/ -o report.md --format markdown","title":"License Detection (v1.8.9+)"},{"location":"binarysniffer/README_ORIGINAL/#integrated-license-detection-with-analysis","text":"Combine component and license detection in a single analysis: # Add license detection to regular analysis binarysniffer analyze app.jar --license-focus # Perform only license detection (skip component analysis) binarysniffer analyze source/ --license-only","title":"Integrated License Detection with Analysis"},{"location":"binarysniffer/README_ORIGINAL/#python-api-for-license-detection","text":"from binarysniffer import EnhancedBinarySniffer sniffer = EnhancedBinarySniffer() # Analyze licenses in a project license_result = sniffer.analyze_licenses(\"/path/to/project\") print(f\"Detected licenses: {', '.join(license_result['licenses_detected'])}\") # Check compatibility compatibility = license_result['compatibility'] if not compatibility['compatible']: for warning in compatibility['warnings']: print(f\"Warning: {warning}\")","title":"Python API for License Detection"},{"location":"binarysniffer/README_ORIGINAL/#features_1","text":"Pattern-based detection for common licenses (MIT, Apache-2.0, GPL, BSD, LGPL, ISC) SPDX identifier support with 100% confidence License compatibility checking to identify conflicts Multiple output formats : Table, JSON, CSV, Markdown Works on : License files, source code with embedded licenses, archives","title":"Features"},{"location":"binarysniffer/README_ORIGINAL/#creating-and-contributing-signatures","text":"","title":"Creating and Contributing Signatures"},{"location":"binarysniffer/README_ORIGINAL/#generate-signatures-from-binaries-or-source-code","text":"Create custom signatures for components you want to detect: # From binary files (recommended for compiled components) binarysniffer signatures create /usr/bin/ffmpeg --name FFmpeg --version 4.4.1 # From source code directories binarysniffer signatures create /path/to/source --name MyLibrary --license MIT # With complete metadata for better attribution binarysniffer signatures create binary.so \\ --name \"My Component\" \\ --version 2.0.0 \\ --license Apache-2.0 \\ --publisher \"My Company\" \\ --description \"Component description\" \\ --output signatures/my-component.json # Specify minimum signature requirements binarysniffer signatures create /path/to/library \\ --name \"LibraryName\" \\ --min-signatures 10 # Require at least 10 unique patterns","title":"Generate Signatures from Binaries or Source Code"},{"location":"binarysniffer/README_ORIGINAL/#collision-detection-for-signature-quality","text":"The signature generator includes automatic collision detection to identify patterns that appear in multiple existing components: # Check for collisions with existing signatures binarysniffer signatures create /usr/bin/myapp \\ --name \"MyApp\" \\ --check-collisions # Interactive review - decide on each collision binarysniffer signatures create /usr/bin/myapp \\ --name \"MyApp\" \\ --interactive # Auto-remove patterns with high collision severity binarysniffer signatures create /usr/bin/myapp \\ --name \"MyApp\" \\ --check-collisions \\ --collision-threshold high # Remove patterns in 3+ components Collision Severity Levels: - Critical : Pattern appears in 5+ unrelated components (likely generic) - High : Pattern appears in 3-4 components - Medium : Pattern appears in 2 unrelated components - Low : Pattern appears in 2 related components (e.g., ffmpeg/libav) Features: - Automatic generic word filtering (100+ common programming terms) - Smart deduplication - all signatures are unique - Cross-signature collision detection - Interactive and automatic filtering modes - Preserves library-specific prefixes (av_, curl_, SSL_, etc.)","title":"Collision Detection for Signature Quality"},{"location":"binarysniffer/README_ORIGINAL/#contributing-signatures-to-the-community","text":"Help improve detection by contributing your signatures: Generate the signature file : bash binarysniffer signatures create /path/to/component \\ --name \"Component Name\" \\ --version \"1.0.0\" \\ --license \"MIT\" \\ --publisher \"Publisher Name\" \\ --output signatures/component-name.json Test your signature : ```bash # Import locally for testing binarysniffer signatures import signatures/component-name.json # Verify detection works binarysniffer analyze /path/to/test/binary ``` Submit via GitHub Pull Request : ```bash # Fork the repository on GitHub, then: git clone https://github.com/YOUR_USERNAME/binarysniffer cd binarysniffer # Add your signature file cp /path/to/component-name.json signatures/ # Commit and push git add signatures/component-name.json git commit -m \"Add signatures for Component Name v1.0.0\" git push origin main # Create a Pull Request on GitHub ``` For detailed contribution guidelines, see CONTRIBUTING.md .","title":"Contributing Signatures to the Community"},{"location":"binarysniffer/README_ORIGINAL/#architecture","text":"The tool uses a multi-tiered approach for efficient matching: Pattern Matching : Direct string/symbol matching against signature database MinHash LSH : Fast similarity search for near-duplicate detection (milliseconds) TLSH Fuzzy Matching : Locality-sensitive hashing to detect modified/recompiled components Detailed Verification : Precise signature verification with confidence scoring","title":"Architecture"},{"location":"binarysniffer/README_ORIGINAL/#tlsh-fuzzy-matching-v180","text":"TLSH (Trend Micro Locality Sensitive Hash) enables detection of: - Modified Components : Components with patches or custom modifications - Recompiled Binaries : Same source code compiled with different options - Version Variants : Different versions of the same library - Obfuscated Code : Components with mild obfuscation or optimization The TLSH algorithm generates a compact hash that remains similar even when files are modified, making it ideal for detecting OSS components that have been customized or rebuilt.","title":"TLSH Fuzzy Matching (v1.8.0+)"},{"location":"binarysniffer/README_ORIGINAL/#performance","text":"Analysis Speed : ~1 second per binary file (5x faster in v1.6.3) Archive Processing : ~100-500ms for APK/IPA files (depends on contents) Signature Storage : ~3.5MB database with 5,136 signatures from 131 components Memory Usage : <100MB during analysis, <200MB for large archives Deterministic Results : Consistent detection across runs (NEW in v1.6.3)","title":"Performance"},{"location":"binarysniffer/README_ORIGINAL/#configuration","text":"Configuration file location: ~/.binarysniffer/config.json { \"signature_sources\": [ \"https://signatures.binarysniffer.io/core.xmdb\" ], \"cache_size_mb\": 100, \"parallel_workers\": 4, \"min_confidence\": 0.5, \"auto_update\": true, \"update_check_interval_days\": 7 }","title":"Configuration"},{"location":"binarysniffer/README_ORIGINAL/#signature-database_1","text":"The tool includes a pre-built signature database with 131 OSS components including: - Mobile SDKs : Facebook Android SDK, Google Firebase, Google Ads - Java Libraries : Jackson, Apache Commons, Google Guava, Netty - Media Libraries : FFmpeg, x264, x265, Vorbis, Opus - Crypto Libraries : Bounty Castle, mbedTLS variants - Development Tools : Lombok, Dagger, RxJava, OkHttp","title":"Signature Database"},{"location":"binarysniffer/README_ORIGINAL/#signature-management","text":"Maintaining an up-to-date signature database is critical for accurate detection. BinarySniffer provides comprehensive signature management commands:","title":"Signature Management"},{"location":"binarysniffer/README_ORIGINAL/#viewing-signature-status","text":"# Check current signature database status binarysniffer signatures status # Shows: total signatures, components, last update, database location # View detailed statistics binarysniffer signatures stats # Shows: signatures per component, database size, index status","title":"Viewing Signature Status"},{"location":"binarysniffer/README_ORIGINAL/#updating-signatures","text":"# Update signatures from GitHub repository (recommended) binarysniffer signatures update # Pulls latest community-contributed signatures # Alternative update command (backward compatible) binarysniffer update # Force update even if current binarysniffer signatures update --force","title":"Updating Signatures"},{"location":"binarysniffer/README_ORIGINAL/#rebuilding-database","text":"# Rebuild database from packaged signatures binarysniffer signatures rebuild # Useful when database is corrupted or needs fresh start # Import specific signature files binarysniffer signatures import signatures/*.json # Import from custom directory binarysniffer signatures import /path/to/signatures --recursive","title":"Rebuilding Database"},{"location":"binarysniffer/README_ORIGINAL/#creating-custom-signatures","text":"# Create signature from binary binarysniffer signatures create /usr/bin/curl \\ --name \"curl\" \\ --version 7.81.0 \\ --license \"MIT\" \\ --output signatures/curl.json # Create from source code directory binarysniffer signatures create /path/to/source \\ --name \"MyLibrary\" \\ --version 1.0.0 \\ --license \"Apache-2.0\" \\ --min-length 8 # Minimum pattern length # Create with metadata binarysniffer signatures create binary.so \\ --name \"Custom Component\" \\ --publisher \"My Company\" \\ --description \"Custom implementation\" \\ --url \"https://github.com/mycompany/component\"","title":"Creating Custom Signatures"},{"location":"binarysniffer/README_ORIGINAL/#signature-validation","text":"# Validate signature quality before adding binarysniffer signatures validate signatures/new-component.json # Checks for: generic patterns, minimum length, uniqueness # Test signature against known files binarysniffer signatures test signatures/component.json /path/to/test/files","title":"Signature Validation"},{"location":"binarysniffer/README_ORIGINAL/#database-management","text":"# Export signatures to JSON (for backup or sharing) binarysniffer signatures export --output my-signatures/ # Creates one JSON file per component # Clear database (use with caution) binarysniffer signatures clear --confirm # Removes all signatures from database # Optimize database binarysniffer signatures optimize # Rebuilds indexes and vacuums database for better performance","title":"Database Management"},{"location":"binarysniffer/README_ORIGINAL/#automated-updates","text":"Configure automatic signature updates in ~/.binarysniffer/config.json : { \"auto_update\": true, \"update_check_interval_days\": 7, \"signature_sources\": [ \"https://github.com/oscarvalenzuelab/binarysniffer-signatures\" ] }","title":"Automated Updates"},{"location":"binarysniffer/README_ORIGINAL/#best-practices","text":"Regular Updates : Run binarysniffer signatures update weekly for latest detections Custom Signatures : Create signatures for proprietary components you want to track Validation : Always validate new signatures to avoid false positives Backup : Export signatures before major updates using signatures export Performance : Run signatures optimize monthly for best performance For detailed signature creation and management documentation, see docs/SIGNATURE_MANAGEMENT.md .","title":"Best Practices"},{"location":"binarysniffer/README_ORIGINAL/#license","text":"Apache License 2.0 - See LICENSE file for details.","title":"License"},{"location":"binarysniffer/README_ORIGINAL/#contributing","text":"Contributions are welcome! Please read our Contributing Guide for details on our code of conduct and the process for submitting pull requests.","title":"Contributing"},{"location":"binarysniffer/SECURITY/","text":"Security Policy for BinarySniffer Supported Versions We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release Reporting a Vulnerability Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. Preferred Languages We prefer all communications to be in English. Policy We follow the principle of Coordinated Vulnerability Disclosure.","title":"Security Policy for BinarySniffer"},{"location":"binarysniffer/SECURITY/#security-policy-for-binarysniffer","text":"","title":"Security Policy for BinarySniffer"},{"location":"binarysniffer/SECURITY/#supported-versions","text":"We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release","title":"Supported Versions"},{"location":"binarysniffer/SECURITY/#reporting-a-vulnerability","text":"Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly.","title":"Reporting a Vulnerability"},{"location":"binarysniffer/SECURITY/#preferred-languages","text":"We prefer all communications to be in English.","title":"Preferred Languages"},{"location":"binarysniffer/SECURITY/#policy","text":"We follow the principle of Coordinated Vulnerability Disclosure.","title":"Policy"},{"location":"binarysniffer/SUPPORT/","text":"Support How to Get Help Thank you for using this project! Here are the best ways to get help: Documentation Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available) Getting Answers Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly Reporting Issues If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue Feature Requests We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project Security Issues For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines. Community Guidelines Please review our Code of Conduct before participating in discussions. Response Times This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours Additional Resources Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Support"},{"location":"binarysniffer/SUPPORT/#support","text":"","title":"Support"},{"location":"binarysniffer/SUPPORT/#how-to-get-help","text":"Thank you for using this project! Here are the best ways to get help:","title":"How to Get Help"},{"location":"binarysniffer/SUPPORT/#documentation","text":"Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available)","title":"Documentation"},{"location":"binarysniffer/SUPPORT/#getting-answers","text":"Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly","title":"Getting Answers"},{"location":"binarysniffer/SUPPORT/#reporting-issues","text":"If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue","title":"Reporting Issues"},{"location":"binarysniffer/SUPPORT/#feature-requests","text":"We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project","title":"Feature Requests"},{"location":"binarysniffer/SUPPORT/#security-issues","text":"For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines.","title":"Security Issues"},{"location":"binarysniffer/SUPPORT/#community-guidelines","text":"Please review our Code of Conduct before participating in discussions.","title":"Community Guidelines"},{"location":"binarysniffer/SUPPORT/#response-times","text":"This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours","title":"Response Times"},{"location":"binarysniffer/SUPPORT/#additional-resources","text":"Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Additional Resources"},{"location":"src2purl/","text":"SRC2PURL - Source Code to Package URL Discovery A Python tool that identifies package coordinates (name, version, license, PURL) from source code directories using a hybrid discovery strategy with manifest parsing, code fingerprinting, repository search, and Software Heritage archive integration. Features 2-Phase Discovery Strategy : Hash-based identification enhanced by manifest parsing Multi-Ecosystem Support : PyPI, NPM, Maven, Go, Ruby Gems, PHP, .NET, and more Fast Performance : 5-15 seconds for typical projects (vs 90+ seconds with SWH) SEMCL.ONE Integration : Works seamlessly with upmex, osslili, and other ecosystem tools Installation pip install src2purl For development: git clone https://github.com/SemClone/src2purl.git cd src2purl pip install -e . Quick Start # Identify package from source code src2purl /path/to/source/code # With Software Heritage archive (comprehensive but slower) src2purl /path/to/source --use-swh Usage CLI Usage # Fast discovery (default) - Uses manifest parsing + SCANOSS + GitHub (5-15 seconds) src2purl /path/to/source/code # Comprehensive discovery - Includes Software Heritage archive (90+ seconds) src2purl /path/to/source --use-swh # High confidence matches only src2purl /path/to/source --confidence-threshold 0.85 # JSON output format for integration src2purl /path/to/source --output-format json # Detect subcomponents in monorepos src2purl /path/to/source --detect-subcomponents Python API from src2purl import identify_package # Basic identification result = identify_package(\"/path/to/source\") print(f\"Package: {result.name}@{result.version}\") print(f\"PURL: {result.purl}\") # With options result = identify_package( path=\"/path/to/source\", use_swh=True, confidence_threshold=0.85 ) Discovery Strategy Examples # Default: 2-Phase hybrid approach (5-15 seconds) # Phase 1: Hash-based discovery + Phase 2: UPMEX manifest parsing # Good for: Most use cases, balanced speed and accuracy src2purl /path/to/project # Comprehensive: Include Software Heritage archive (90+ seconds) # Phase 1 includes deep provenance discovery + Phase 2: UPMEX enhancement # Good for: Security audits, research, historical analysis export SWH_API_TOKEN=your_token # Optional but recommended src2purl /path/to/project --use-swh # High confidence: Only report confident matches # Filters results to highest confidence findings from both phases src2purl /path/to/project --confidence-threshold 0.85 API Authentication No API keys required! The tool works with the free public APIs. API keys only provide enhanced rate limits and additional features. Recommended API Keys (Optional) 1. GitHub API - Most Valuable (Free, 2 minutes to setup) export GITHUB_TOKEN=your_github_personal_access_token Get token : https://github.com/settings/tokens (no special permissions needed) Benefits : Rate limit : 10 \u2192 5000 requests/hour Better search : More accurate repository identification No cost : Completely free Impact : Significant improvement for repository discovery 2. SCANOSS API - Nice to Have (Free, optional) export SCANOSS_API_KEY=your_scanoss_key Get token : Register at https://www.scanoss.com Benefits : No cost : Free tier available Enhanced rate limits : Premium API endpoint Additional features : Possible extra metadata Impact : Minor improvement (SCANOSS works great without key) 3. Software Heritage API - For Heavy Usage (Free, only if using --use-swh ) export SWH_API_TOKEN=your_swh_token Get token : Register at https://archive.softwareheritage.org/api/ Benefits : Bypass rate limits : No 60-second waits Faster comprehensive scans : When using --use-swh Impact : Essential for --use-swh flag, not needed for default fast mode Performance Comparison Configuration Typical Time API Calls Best For No API keys 5-15 seconds Minimal Most users + GitHub token 5-15 seconds Enhanced Recommended setup + All tokens 5-15 seconds Premium Production use + SWH mode 90+ seconds Heavy Security audits Recommendation : Start with GitHub token only - it's free, fast to setup, and provides the biggest improvement. SWHID Validation # Generate and validate SWHID for a directory src2purl-validate /path/to/directory # Compare against expected SWHID src2purl-validate /path/to/directory --expected-swhid swh:1:dir:abc123... # Use fallback implementation src2purl-validate /path/to/directory --use-fallback --verbose Command Line Options Core Options path : Directory path to analyze (required) --confidence-threshold : Minimum confidence to report matches (default: 0.3) --output-format : Output format: 'json' or 'table' (default: table) --verbose : Verbose output for debugging Discovery Control --use-swh : Include Software Heritage archive checking (optional, adds 90+ seconds) --no-license-detection : Skip automatic license detection from local source (faster) --detect-subcomponents : Detect and identify subcomponents in monorepos --max-depth : Maximum directory depth to scan (default: 2) Performance & Caching --no-cache : Disable API response caching --clear-cache : Clear all cached API responses and exit Authentication --api-token : Software Heritage API token (only used with --use-swh) Environment variables: GITHUB_TOKEN , SCANOSS_API_KEY , SWH_API_TOKEN Discovery Method Breakdown # Default: 2-Phase Discovery (Hash-based + UPMEX manifest parsing) src2purl /path/to/project # Phase 1: SWHID generation \u2192 GitHub/SCANOSS search # Phase 2: UPMEX manifest extraction \u2192 Cross-validation & enhancement # Add Software Heritage for comprehensive provenance discovery src2purl /path/to/project --use-swh # Phase 1: SWHID generation \u2192 Software Heritage archive \u2192 Fallback search # Phase 2: UPMEX manifest extraction \u2192 Cross-validation & enhancement # Performance optimization options src2purl /path/to/project --no-license-detection # Skip license enhancement src2purl /path/to/project --use-swh --verbose # Full discovery with details Integration with SEMCL.ONE SRC2PURL is a core component of the SEMCL.ONE ecosystem: Uses upmex for manifest parsing and package metadata extraction Integrates with osslili for enhanced license detection Provides PURLs for purl2src to download source packages Supports purl2notices for generating attribution documentation Enables ospac policy evaluation with identified packages Configuration Configuration via environment variables: # API tokens (optional but recommended) export GITHUB_TOKEN=your_github_token export SCANOSS_API_KEY=your_scanoss_key export SWH_API_TOKEN=your_swh_token # Performance settings export SRC2PURL_CACHE_DIR=~/.cache/src2purl export SRC2PURL_MAX_DEPTH=2 Documentation User Guide - Comprehensive usage examples API Reference - Python API documentation Discovery Methods - Detailed explanation of identification strategies Examples - Common use cases and workflows Contributing We welcome contributions! Please see CONTRIBUTING.md for details on: - Code of conduct - Development setup - Submitting pull requests - Reporting issues Support For support and questions: - GitHub Issues - Bug reports and feature requests - Documentation - Complete project documentation - SEMCL.ONE Community - Ecosystem support and discussions License GNU Affero General Public License v3.0 (AGPL-3.0) - see LICENSE file for details. Authors See AUTHORS.md for a list of contributors. Part of the SEMCL.ONE ecosystem for comprehensive OSS compliance and code analysis.","title":"src2purl"},{"location":"src2purl/#src2purl-source-code-to-package-url-discovery","text":"A Python tool that identifies package coordinates (name, version, license, PURL) from source code directories using a hybrid discovery strategy with manifest parsing, code fingerprinting, repository search, and Software Heritage archive integration.","title":"SRC2PURL - Source Code to Package URL Discovery"},{"location":"src2purl/#features","text":"2-Phase Discovery Strategy : Hash-based identification enhanced by manifest parsing Multi-Ecosystem Support : PyPI, NPM, Maven, Go, Ruby Gems, PHP, .NET, and more Fast Performance : 5-15 seconds for typical projects (vs 90+ seconds with SWH) SEMCL.ONE Integration : Works seamlessly with upmex, osslili, and other ecosystem tools","title":"Features"},{"location":"src2purl/#installation","text":"pip install src2purl For development: git clone https://github.com/SemClone/src2purl.git cd src2purl pip install -e .","title":"Installation"},{"location":"src2purl/#quick-start","text":"# Identify package from source code src2purl /path/to/source/code # With Software Heritage archive (comprehensive but slower) src2purl /path/to/source --use-swh","title":"Quick Start"},{"location":"src2purl/#usage","text":"","title":"Usage"},{"location":"src2purl/#cli-usage","text":"# Fast discovery (default) - Uses manifest parsing + SCANOSS + GitHub (5-15 seconds) src2purl /path/to/source/code # Comprehensive discovery - Includes Software Heritage archive (90+ seconds) src2purl /path/to/source --use-swh # High confidence matches only src2purl /path/to/source --confidence-threshold 0.85 # JSON output format for integration src2purl /path/to/source --output-format json # Detect subcomponents in monorepos src2purl /path/to/source --detect-subcomponents","title":"CLI Usage"},{"location":"src2purl/#python-api","text":"from src2purl import identify_package # Basic identification result = identify_package(\"/path/to/source\") print(f\"Package: {result.name}@{result.version}\") print(f\"PURL: {result.purl}\") # With options result = identify_package( path=\"/path/to/source\", use_swh=True, confidence_threshold=0.85 )","title":"Python API"},{"location":"src2purl/#discovery-strategy-examples","text":"# Default: 2-Phase hybrid approach (5-15 seconds) # Phase 1: Hash-based discovery + Phase 2: UPMEX manifest parsing # Good for: Most use cases, balanced speed and accuracy src2purl /path/to/project # Comprehensive: Include Software Heritage archive (90+ seconds) # Phase 1 includes deep provenance discovery + Phase 2: UPMEX enhancement # Good for: Security audits, research, historical analysis export SWH_API_TOKEN=your_token # Optional but recommended src2purl /path/to/project --use-swh # High confidence: Only report confident matches # Filters results to highest confidence findings from both phases src2purl /path/to/project --confidence-threshold 0.85","title":"Discovery Strategy Examples"},{"location":"src2purl/#api-authentication","text":"No API keys required! The tool works with the free public APIs. API keys only provide enhanced rate limits and additional features.","title":"API Authentication"},{"location":"src2purl/#recommended-api-keys-optional","text":"1. GitHub API - Most Valuable (Free, 2 minutes to setup) export GITHUB_TOKEN=your_github_personal_access_token Get token : https://github.com/settings/tokens (no special permissions needed) Benefits : Rate limit : 10 \u2192 5000 requests/hour Better search : More accurate repository identification No cost : Completely free Impact : Significant improvement for repository discovery 2. SCANOSS API - Nice to Have (Free, optional) export SCANOSS_API_KEY=your_scanoss_key Get token : Register at https://www.scanoss.com Benefits : No cost : Free tier available Enhanced rate limits : Premium API endpoint Additional features : Possible extra metadata Impact : Minor improvement (SCANOSS works great without key) 3. Software Heritage API - For Heavy Usage (Free, only if using --use-swh ) export SWH_API_TOKEN=your_swh_token Get token : Register at https://archive.softwareheritage.org/api/ Benefits : Bypass rate limits : No 60-second waits Faster comprehensive scans : When using --use-swh Impact : Essential for --use-swh flag, not needed for default fast mode","title":"Recommended API Keys (Optional)"},{"location":"src2purl/#performance-comparison","text":"Configuration Typical Time API Calls Best For No API keys 5-15 seconds Minimal Most users + GitHub token 5-15 seconds Enhanced Recommended setup + All tokens 5-15 seconds Premium Production use + SWH mode 90+ seconds Heavy Security audits Recommendation : Start with GitHub token only - it's free, fast to setup, and provides the biggest improvement.","title":"Performance Comparison"},{"location":"src2purl/#swhid-validation","text":"# Generate and validate SWHID for a directory src2purl-validate /path/to/directory # Compare against expected SWHID src2purl-validate /path/to/directory --expected-swhid swh:1:dir:abc123... # Use fallback implementation src2purl-validate /path/to/directory --use-fallback --verbose","title":"SWHID Validation"},{"location":"src2purl/#command-line-options","text":"","title":"Command Line Options"},{"location":"src2purl/#core-options","text":"path : Directory path to analyze (required) --confidence-threshold : Minimum confidence to report matches (default: 0.3) --output-format : Output format: 'json' or 'table' (default: table) --verbose : Verbose output for debugging","title":"Core Options"},{"location":"src2purl/#discovery-control","text":"--use-swh : Include Software Heritage archive checking (optional, adds 90+ seconds) --no-license-detection : Skip automatic license detection from local source (faster) --detect-subcomponents : Detect and identify subcomponents in monorepos --max-depth : Maximum directory depth to scan (default: 2)","title":"Discovery Control"},{"location":"src2purl/#performance-caching","text":"--no-cache : Disable API response caching --clear-cache : Clear all cached API responses and exit","title":"Performance &amp; Caching"},{"location":"src2purl/#authentication","text":"--api-token : Software Heritage API token (only used with --use-swh) Environment variables: GITHUB_TOKEN , SCANOSS_API_KEY , SWH_API_TOKEN","title":"Authentication"},{"location":"src2purl/#discovery-method-breakdown","text":"# Default: 2-Phase Discovery (Hash-based + UPMEX manifest parsing) src2purl /path/to/project # Phase 1: SWHID generation \u2192 GitHub/SCANOSS search # Phase 2: UPMEX manifest extraction \u2192 Cross-validation & enhancement # Add Software Heritage for comprehensive provenance discovery src2purl /path/to/project --use-swh # Phase 1: SWHID generation \u2192 Software Heritage archive \u2192 Fallback search # Phase 2: UPMEX manifest extraction \u2192 Cross-validation & enhancement # Performance optimization options src2purl /path/to/project --no-license-detection # Skip license enhancement src2purl /path/to/project --use-swh --verbose # Full discovery with details","title":"Discovery Method Breakdown"},{"location":"src2purl/#integration-with-semclone","text":"SRC2PURL is a core component of the SEMCL.ONE ecosystem: Uses upmex for manifest parsing and package metadata extraction Integrates with osslili for enhanced license detection Provides PURLs for purl2src to download source packages Supports purl2notices for generating attribution documentation Enables ospac policy evaluation with identified packages","title":"Integration with SEMCL.ONE"},{"location":"src2purl/#configuration","text":"Configuration via environment variables: # API tokens (optional but recommended) export GITHUB_TOKEN=your_github_token export SCANOSS_API_KEY=your_scanoss_key export SWH_API_TOKEN=your_swh_token # Performance settings export SRC2PURL_CACHE_DIR=~/.cache/src2purl export SRC2PURL_MAX_DEPTH=2","title":"Configuration"},{"location":"src2purl/#documentation","text":"User Guide - Comprehensive usage examples API Reference - Python API documentation Discovery Methods - Detailed explanation of identification strategies Examples - Common use cases and workflows","title":"Documentation"},{"location":"src2purl/#contributing","text":"We welcome contributions! Please see CONTRIBUTING.md for details on: - Code of conduct - Development setup - Submitting pull requests - Reporting issues","title":"Contributing"},{"location":"src2purl/#support","text":"For support and questions: - GitHub Issues - Bug reports and feature requests - Documentation - Complete project documentation - SEMCL.ONE Community - Ecosystem support and discussions","title":"Support"},{"location":"src2purl/#license","text":"GNU Affero General Public License v3.0 (AGPL-3.0) - see LICENSE file for details.","title":"License"},{"location":"src2purl/#authors","text":"See AUTHORS.md for a list of contributors. Part of the SEMCL.ONE ecosystem for comprehensive OSS compliance and code analysis.","title":"Authors"},{"location":"src2purl/AUTHORS/","text":"Authors Project Lead Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Authors"},{"location":"src2purl/AUTHORS/#authors","text":"","title":"Authors"},{"location":"src2purl/AUTHORS/#project-lead","text":"Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Project Lead"},{"location":"src2purl/CHANGELOG/","text":"Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [1.3.4] - 2025-10-27 Fixed Updated GitHub repository URLs : Changed project URLs in pyproject.toml from oscarvalenzuelab/src2purl to official SemClone/src2purl repository Homepage URL updated to https://github.com/SemClone/src2purl Bug Tracker URL updated to https://github.com/SemClone/src2purl/issues Source Code URL updated to https://github.com/SemClone/src2purl [1.3.3] - 2025-10-27 Fixed Updated oslili package dependency : Changed from semantic-copycat-oslili to osslili to reflect upstream package rebranding Updated oslili import statements : Changed import from semantic_copycat_oslili to osslili in integration module Maintained backward compatibility : License enhancement functionality preserved with graceful fallback handling Technical All existing functionality remains unchanged Integration properly handles ImportError when osslili package not available No breaking changes to API or core package identification workflow [1.3.2] - 2025-10-27 Changed (Project Rebranding) Renamed project from semantic-copycat-src2id to src2purl : Better reflects the tool's focus on Package URL (PURL) generation Updated CLI commands : Changed from src2id to src2purl and src2id-validate to src2purl-validate Updated project metadata : Package name: semantic-copycat-src2id \u2192 src2purl Repository URLs updated to point to new src2purl repository Project description updated to emphasize PURL generation capabilities Updated documentation : README, CHANGELOG, and all references updated to reflect new branding Updated CLI display : Version string now shows src2purl v{version} instead of src2id v{version} Technical All package imports and module structure remain unchanged (src2id.*) Backward compatibility maintained for existing integrations No breaking changes to API or functionality [1.3.1] - 2025-10-19 Added Hybrid Discovery Strategy : Comprehensive package identification using multiple methods Primary: Hash-based discovery (SWHIDs + Software Heritage) for comprehensive source inventory Secondary: Manifest parsing (UPMEX integration) to validate findings and add missing packages Tertiary: GitHub API and SCANOSS fingerprinting for additional coverage Individual testing capabilities for each discovery method Comprehensive Manifest Parsing : Direct manifest file analysis supporting 15+ ecosystems Python: setup.py, pyproject.toml, setup.cfg, requirements.txt, Pipfile JavaScript/Node.js: package.json, yarn.lock, package-lock.json Java/Maven: pom.xml, gradle.build Go: go.mod, go.sum Rust: Cargo.toml, Cargo.lock Ruby: Gemfile, gemspec files PHP: composer.json, composer.lock .NET: .csproj, packages.config, .nuspec Enhanced Package Metadata Extraction : License detection with confidence scoring Version extraction from multiple sources (tags, releases, manifest files) PURL (Package URL) generation across ecosystems Official organization detection and prioritization Security Fixed URL Substring Sanitization Vulnerabilities : Comprehensive security improvements Replaced vulnerable substring-based URL validation with proper URL parsing Enhanced hostname validation using urlparse() for accurate domain matching Prevents URL validation bypass attacks (e.g., evil.com/github.com/fake ) Addresses CodeQL security alerts #1-#25 for incomplete URL substring sanitization Applied across all modules: extractor.py, orchestrator.py, purl.py, providers.py Improved Performance Optimization : Software Heritage made optional by default Use --use-swh flag to enable Software Heritage integration Prevents timeout issues on large codebases Faster execution for most common use cases Enhanced Documentation : Comprehensive README updates 4-tier discovery strategy explanation API key setup instructions for GitHub, SCANOSS, SerpAPI Emphasis on \"no API keys required\" approach for basic functionality Updated usage examples and configuration options Code Quality : Repository cleanup and maintenance Removed temporary test files and development artifacts Improved error handling and logging Enhanced type safety and validation Fixed Python Version Compatibility : Added fallback support for Python < 3.11 Graceful handling of tomllib import (Python 3.11+ only) Fallback to tomli library for older Python versions Maintains backward compatibility with Python 3.9+ UPMEX Integration Issues : Resolved import and dependency conflicts Created direct manifest parser instead of UPMEX archive-based tool Handles raw manifest files in source directories Supports recursive manifest discovery with depth control Changed Discovery Method Prioritization : Implemented proper hybrid approach Hash-based discovery prioritized over manifest parsing Manifest parsing used for validation and enhancement of hash-based results Software Heritage integration now optional (disabled by default) Intelligent result merging and deduplication [1.1.2] - 2025-08-20 Testing Added comprehensive unit test suite : 83 unit tests with 30% code coverage Tests for all core modules (config, models, scanner, scorer, SWHID, PURL) Removed async integration tests due to pytest-asyncio compatibility issues All tests passing with Python 3.13 and swh.model v8.3.0 Fixed test infrastructure issues : Converted async tests to synchronous to avoid pytest-asyncio dependency Updated scanner tests to match actual implementation behavior Fixed client test assumptions about available methods Dependencies SWHID Generation : Using swh.model v8.3.0 (official Software Heritage library) Considered miniswhid but requires Python 3.10+ (incompatible with current environment) swh.model provides accurate, official SWHID generation Cleaned up test dependencies : Removed asyncio configuration from pytest Changed (Project Rename) Renamed project from SWHPI to src2purl : Better reflects the tool's PURL-focused approach Changed CLI command from swhpi to src2purl Updated all package imports from swhpi.* to src2purl.* Repository moved to src2purl Added Multiple Identification Strategies : Not just Software Heritage anymore Hash-based web search (GitHub, Google) SCANOSS fingerprinting for code similarity Web search across multiple sources Software Heritage now optional with --use-swh flag Subcomponent Detection : New --detect-subcomponents flag Detects multiple packages in monorepos Supports Lerna, Nx, Turborepo, and standard package structures Identifies nested packages in complex projects 30x Performance Improvement : Optimized strategy order Local methods (hash search) run first Web search before expensive API calls SCANOSS as third option to preserve API quotas Software Heritage only when explicitly requested Fixed Removed misleading SWH client messages : Fixed lazy initialization SoftwareHeritageClient only created when actually needed No more \"Using official Software Heritage WebAPIClient\" when not using SWH urllib3 OpenSSL warnings : Added warning filter Unclosed client sessions : Proper cleanup in finally blocks SCANOSS division errors : Fixed type handling for matched values Pre-commit hooks : Added checks to prevent AI assistant mentions in commits Previous Features (from earlier 1.1.2 work on 2025-08-19) Added API Authentication Support : Added --api-token option and SWH_API_TOKEN environment variable for authentication Bypasses rate limits when using Software Heritage API tokens Supports both command-line option and environment variable Works with both official WebAPIClient and fallback HTTP client Batch API Processing : Implemented efficient batch checking using /known/ endpoint Checks multiple SWHIDs in a single API call Significantly improves performance for multi-directory scans Falls back to individual requests when official client unavailable Fixed Fixed oslili integration to properly import osslili library Corrected license detection using LegalAttributionGenerator API Removed duplicate and obsolete methods from oslili integration Fixed directory scanning to traverse subdirectories correctly (not parent directories) Fixed SWHID generation to match official Software Heritage method using model_of_dir() Improved Hide 404 errors in non-verbose mode for cleaner output Removed \"Version\" column from results table since versions are rarely matched Enhanced keyword search to skip common subdirectory names (packaging, src, lib, etc.) Better similarity scoring for official organization repositories License detection now properly shows GPL-3.0 and other SPDX identifiers Enhanced verbose output showing paths, SWHIDs, and API results Improved session management for async HTTP requests Changed Table output now shows: Name, Confidence, License, PURL, Method, URL (Version column removed) Exact matching is now default; fuzzy matching requires --enable-fuzzy flag License detection is now enabled by default; use --no-license-detection to disable More accurate package identification for complex directory structures [1.1.1] - 2025-08-19 Added Initial oslili integration for enhanced license detection Keyword search fallback when exact SWHID matches fail Improved confidence scoring system Cache support for API responses Features Software Heritage archive integration PURL (Package URL) generation Multiple output formats (table, json) Configurable confidence thresholds Directory traversal with depth limits","title":"Changelog"},{"location":"src2purl/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"src2purl/CHANGELOG/#134-2025-10-27","text":"","title":"[1.3.4] - 2025-10-27"},{"location":"src2purl/CHANGELOG/#fixed","text":"Updated GitHub repository URLs : Changed project URLs in pyproject.toml from oscarvalenzuelab/src2purl to official SemClone/src2purl repository Homepage URL updated to https://github.com/SemClone/src2purl Bug Tracker URL updated to https://github.com/SemClone/src2purl/issues Source Code URL updated to https://github.com/SemClone/src2purl","title":"Fixed"},{"location":"src2purl/CHANGELOG/#133-2025-10-27","text":"","title":"[1.3.3] - 2025-10-27"},{"location":"src2purl/CHANGELOG/#fixed_1","text":"Updated oslili package dependency : Changed from semantic-copycat-oslili to osslili to reflect upstream package rebranding Updated oslili import statements : Changed import from semantic_copycat_oslili to osslili in integration module Maintained backward compatibility : License enhancement functionality preserved with graceful fallback handling","title":"Fixed"},{"location":"src2purl/CHANGELOG/#technical","text":"All existing functionality remains unchanged Integration properly handles ImportError when osslili package not available No breaking changes to API or core package identification workflow","title":"Technical"},{"location":"src2purl/CHANGELOG/#132-2025-10-27","text":"","title":"[1.3.2] - 2025-10-27"},{"location":"src2purl/CHANGELOG/#changed-project-rebranding","text":"Renamed project from semantic-copycat-src2id to src2purl : Better reflects the tool's focus on Package URL (PURL) generation Updated CLI commands : Changed from src2id to src2purl and src2id-validate to src2purl-validate Updated project metadata : Package name: semantic-copycat-src2id \u2192 src2purl Repository URLs updated to point to new src2purl repository Project description updated to emphasize PURL generation capabilities Updated documentation : README, CHANGELOG, and all references updated to reflect new branding Updated CLI display : Version string now shows src2purl v{version} instead of src2id v{version}","title":"Changed (Project Rebranding)"},{"location":"src2purl/CHANGELOG/#technical_1","text":"All package imports and module structure remain unchanged (src2id.*) Backward compatibility maintained for existing integrations No breaking changes to API or functionality","title":"Technical"},{"location":"src2purl/CHANGELOG/#131-2025-10-19","text":"","title":"[1.3.1] - 2025-10-19"},{"location":"src2purl/CHANGELOG/#added","text":"Hybrid Discovery Strategy : Comprehensive package identification using multiple methods Primary: Hash-based discovery (SWHIDs + Software Heritage) for comprehensive source inventory Secondary: Manifest parsing (UPMEX integration) to validate findings and add missing packages Tertiary: GitHub API and SCANOSS fingerprinting for additional coverage Individual testing capabilities for each discovery method Comprehensive Manifest Parsing : Direct manifest file analysis supporting 15+ ecosystems Python: setup.py, pyproject.toml, setup.cfg, requirements.txt, Pipfile JavaScript/Node.js: package.json, yarn.lock, package-lock.json Java/Maven: pom.xml, gradle.build Go: go.mod, go.sum Rust: Cargo.toml, Cargo.lock Ruby: Gemfile, gemspec files PHP: composer.json, composer.lock .NET: .csproj, packages.config, .nuspec Enhanced Package Metadata Extraction : License detection with confidence scoring Version extraction from multiple sources (tags, releases, manifest files) PURL (Package URL) generation across ecosystems Official organization detection and prioritization","title":"Added"},{"location":"src2purl/CHANGELOG/#security","text":"Fixed URL Substring Sanitization Vulnerabilities : Comprehensive security improvements Replaced vulnerable substring-based URL validation with proper URL parsing Enhanced hostname validation using urlparse() for accurate domain matching Prevents URL validation bypass attacks (e.g., evil.com/github.com/fake ) Addresses CodeQL security alerts #1-#25 for incomplete URL substring sanitization Applied across all modules: extractor.py, orchestrator.py, purl.py, providers.py","title":"Security"},{"location":"src2purl/CHANGELOG/#improved","text":"Performance Optimization : Software Heritage made optional by default Use --use-swh flag to enable Software Heritage integration Prevents timeout issues on large codebases Faster execution for most common use cases Enhanced Documentation : Comprehensive README updates 4-tier discovery strategy explanation API key setup instructions for GitHub, SCANOSS, SerpAPI Emphasis on \"no API keys required\" approach for basic functionality Updated usage examples and configuration options Code Quality : Repository cleanup and maintenance Removed temporary test files and development artifacts Improved error handling and logging Enhanced type safety and validation","title":"Improved"},{"location":"src2purl/CHANGELOG/#fixed_2","text":"Python Version Compatibility : Added fallback support for Python < 3.11 Graceful handling of tomllib import (Python 3.11+ only) Fallback to tomli library for older Python versions Maintains backward compatibility with Python 3.9+ UPMEX Integration Issues : Resolved import and dependency conflicts Created direct manifest parser instead of UPMEX archive-based tool Handles raw manifest files in source directories Supports recursive manifest discovery with depth control","title":"Fixed"},{"location":"src2purl/CHANGELOG/#changed","text":"Discovery Method Prioritization : Implemented proper hybrid approach Hash-based discovery prioritized over manifest parsing Manifest parsing used for validation and enhancement of hash-based results Software Heritage integration now optional (disabled by default) Intelligent result merging and deduplication","title":"Changed"},{"location":"src2purl/CHANGELOG/#112-2025-08-20","text":"","title":"[1.1.2] - 2025-08-20"},{"location":"src2purl/CHANGELOG/#testing","text":"Added comprehensive unit test suite : 83 unit tests with 30% code coverage Tests for all core modules (config, models, scanner, scorer, SWHID, PURL) Removed async integration tests due to pytest-asyncio compatibility issues All tests passing with Python 3.13 and swh.model v8.3.0 Fixed test infrastructure issues : Converted async tests to synchronous to avoid pytest-asyncio dependency Updated scanner tests to match actual implementation behavior Fixed client test assumptions about available methods","title":"Testing"},{"location":"src2purl/CHANGELOG/#dependencies","text":"SWHID Generation : Using swh.model v8.3.0 (official Software Heritage library) Considered miniswhid but requires Python 3.10+ (incompatible with current environment) swh.model provides accurate, official SWHID generation Cleaned up test dependencies : Removed asyncio configuration from pytest","title":"Dependencies"},{"location":"src2purl/CHANGELOG/#changed-project-rename","text":"Renamed project from SWHPI to src2purl : Better reflects the tool's PURL-focused approach Changed CLI command from swhpi to src2purl Updated all package imports from swhpi.* to src2purl.* Repository moved to src2purl","title":"Changed (Project Rename)"},{"location":"src2purl/CHANGELOG/#added_1","text":"Multiple Identification Strategies : Not just Software Heritage anymore Hash-based web search (GitHub, Google) SCANOSS fingerprinting for code similarity Web search across multiple sources Software Heritage now optional with --use-swh flag Subcomponent Detection : New --detect-subcomponents flag Detects multiple packages in monorepos Supports Lerna, Nx, Turborepo, and standard package structures Identifies nested packages in complex projects 30x Performance Improvement : Optimized strategy order Local methods (hash search) run first Web search before expensive API calls SCANOSS as third option to preserve API quotas Software Heritage only when explicitly requested","title":"Added"},{"location":"src2purl/CHANGELOG/#fixed_3","text":"Removed misleading SWH client messages : Fixed lazy initialization SoftwareHeritageClient only created when actually needed No more \"Using official Software Heritage WebAPIClient\" when not using SWH urllib3 OpenSSL warnings : Added warning filter Unclosed client sessions : Proper cleanup in finally blocks SCANOSS division errors : Fixed type handling for matched values Pre-commit hooks : Added checks to prevent AI assistant mentions in commits","title":"Fixed"},{"location":"src2purl/CHANGELOG/#previous-features-from-earlier-112-work-on-2025-08-19","text":"","title":"Previous Features (from earlier 1.1.2 work on 2025-08-19)"},{"location":"src2purl/CHANGELOG/#added_2","text":"API Authentication Support : Added --api-token option and SWH_API_TOKEN environment variable for authentication Bypasses rate limits when using Software Heritage API tokens Supports both command-line option and environment variable Works with both official WebAPIClient and fallback HTTP client Batch API Processing : Implemented efficient batch checking using /known/ endpoint Checks multiple SWHIDs in a single API call Significantly improves performance for multi-directory scans Falls back to individual requests when official client unavailable","title":"Added"},{"location":"src2purl/CHANGELOG/#fixed_4","text":"Fixed oslili integration to properly import osslili library Corrected license detection using LegalAttributionGenerator API Removed duplicate and obsolete methods from oslili integration Fixed directory scanning to traverse subdirectories correctly (not parent directories) Fixed SWHID generation to match official Software Heritage method using model_of_dir()","title":"Fixed"},{"location":"src2purl/CHANGELOG/#improved_1","text":"Hide 404 errors in non-verbose mode for cleaner output Removed \"Version\" column from results table since versions are rarely matched Enhanced keyword search to skip common subdirectory names (packaging, src, lib, etc.) Better similarity scoring for official organization repositories License detection now properly shows GPL-3.0 and other SPDX identifiers Enhanced verbose output showing paths, SWHIDs, and API results Improved session management for async HTTP requests","title":"Improved"},{"location":"src2purl/CHANGELOG/#changed_1","text":"Table output now shows: Name, Confidence, License, PURL, Method, URL (Version column removed) Exact matching is now default; fuzzy matching requires --enable-fuzzy flag License detection is now enabled by default; use --no-license-detection to disable More accurate package identification for complex directory structures","title":"Changed"},{"location":"src2purl/CHANGELOG/#111-2025-08-19","text":"","title":"[1.1.1] - 2025-08-19"},{"location":"src2purl/CHANGELOG/#added_3","text":"Initial oslili integration for enhanced license detection Keyword search fallback when exact SWHID matches fail Improved confidence scoring system Cache support for API responses","title":"Added"},{"location":"src2purl/CHANGELOG/#features","text":"Software Heritage archive integration PURL (Package URL) generation Multiple output formats (table, json) Configurable confidence thresholds Directory traversal with depth limits","title":"Features"},{"location":"src2purl/CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Contributor Covenant Code of Conduct"},{"location":"src2purl/CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"src2purl/CODE_OF_CONDUCT/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"src2purl/CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"src2purl/CODE_OF_CONDUCT/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"src2purl/CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"src2purl/CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"src2purl/CODE_OF_CONDUCT/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"src2purl/CODE_OF_CONDUCT/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"src2purl/CODE_OF_CONDUCT/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"src2purl/CODE_OF_CONDUCT/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"src2purl/CODE_OF_CONDUCT/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"src2purl/CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Attribution"},{"location":"src2purl/CONTRIBUTING/","text":"Contributing to src2purl First off, thank you for considering contributing to src2purl! It's people like you that make src2purl such a great tool. Code of Conduct This project and everyone participating in it is governed by the Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to conduct@semcl.one . How Can I Contribute? Reporting Bugs Before creating bug reports, please check existing issues as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one. How Do I Submit A Good Bug Report? Bugs are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem. If the problem wasn't triggered by a specific action , describe what you were doing before the problem happened and share more information using the guidelines below. Suggesting Enhancements Enhancement suggestions are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps . Include copy/pasteable snippets which you use in those examples. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users. List some other projects where this enhancement exists. Your First Code Contribution Unsure where to begin contributing? You can start by looking through these beginner and help-wanted issues: [Beginner issues][beginner] - issues which should only require a few lines of code, and a test or two. [Help wanted issues][help-wanted] - issues which should be a bit more involved than beginner issues. Pull Requests The process described here has several goals: Maintain code quality Fix problems that are important to users Engage the community in working toward the best possible product Enable a sustainable system for maintainers to review contributions Please follow these steps to have your contribution considered by the maintainers: Follow all instructions in the template Follow the styleguides After you submit your pull request, verify that all status checks are passing While the prerequisites above must be satisfied prior to having your pull request reviewed, the reviewer(s) may ask you to complete additional design work, tests, or other changes before your pull request can be ultimately accepted. Styleguides Git Commit Messages Use the present tense (\"Add feature\" not \"Added feature\") Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit the first line to 72 characters or less Reference issues and pull requests liberally after the first line When only changing documentation, include [ci skip] in the commit title Python Styleguide All Python code must adhere to PEP 8 . Use type hints where appropriate Include docstrings for all public functions, classes, and modules Prefer explicit over implicit Write tests for new functionality Documentation Styleguide Use Markdown . Reference functions and classes in backticks: `function_name()`. Include code examples where appropriate. Development Process Fork the repo and create your branch from main . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request! Development Setup # Clone your fork git clone https://github.com/your-username/src2purl.git cd src2purl # Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # Install dependencies pip install -e .[dev] # Run tests pytest # Run linting ruff check . black --check . Running Tests # Run all tests pytest # Run with coverage pytest --cov=src2purl # Run specific test file pytest tests/test_specific.py Community You can chat with the community on: - GitHub Discussions - Issues Recognition Contributors who have made significant contributions will be recognized in our AUTHORS file. Thank you for contributing!","title":"Contributing to src2purl"},{"location":"src2purl/CONTRIBUTING/#contributing-to-src2purl","text":"First off, thank you for considering contributing to src2purl! It's people like you that make src2purl such a great tool.","title":"Contributing to src2purl"},{"location":"src2purl/CONTRIBUTING/#code-of-conduct","text":"This project and everyone participating in it is governed by the Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to conduct@semcl.one .","title":"Code of Conduct"},{"location":"src2purl/CONTRIBUTING/#how-can-i-contribute","text":"","title":"How Can I Contribute?"},{"location":"src2purl/CONTRIBUTING/#reporting-bugs","text":"Before creating bug reports, please check existing issues as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one.","title":"Reporting Bugs"},{"location":"src2purl/CONTRIBUTING/#how-do-i-submit-a-good-bug-report","text":"Bugs are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem. If the problem wasn't triggered by a specific action , describe what you were doing before the problem happened and share more information using the guidelines below.","title":"How Do I Submit A Good Bug Report?"},{"location":"src2purl/CONTRIBUTING/#suggesting-enhancements","text":"Enhancement suggestions are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps . Include copy/pasteable snippets which you use in those examples. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users. List some other projects where this enhancement exists.","title":"Suggesting Enhancements"},{"location":"src2purl/CONTRIBUTING/#your-first-code-contribution","text":"Unsure where to begin contributing? You can start by looking through these beginner and help-wanted issues: [Beginner issues][beginner] - issues which should only require a few lines of code, and a test or two. [Help wanted issues][help-wanted] - issues which should be a bit more involved than beginner issues.","title":"Your First Code Contribution"},{"location":"src2purl/CONTRIBUTING/#pull-requests","text":"The process described here has several goals: Maintain code quality Fix problems that are important to users Engage the community in working toward the best possible product Enable a sustainable system for maintainers to review contributions Please follow these steps to have your contribution considered by the maintainers: Follow all instructions in the template Follow the styleguides After you submit your pull request, verify that all status checks are passing While the prerequisites above must be satisfied prior to having your pull request reviewed, the reviewer(s) may ask you to complete additional design work, tests, or other changes before your pull request can be ultimately accepted.","title":"Pull Requests"},{"location":"src2purl/CONTRIBUTING/#styleguides","text":"","title":"Styleguides"},{"location":"src2purl/CONTRIBUTING/#git-commit-messages","text":"Use the present tense (\"Add feature\" not \"Added feature\") Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit the first line to 72 characters or less Reference issues and pull requests liberally after the first line When only changing documentation, include [ci skip] in the commit title","title":"Git Commit Messages"},{"location":"src2purl/CONTRIBUTING/#python-styleguide","text":"All Python code must adhere to PEP 8 . Use type hints where appropriate Include docstrings for all public functions, classes, and modules Prefer explicit over implicit Write tests for new functionality","title":"Python Styleguide"},{"location":"src2purl/CONTRIBUTING/#documentation-styleguide","text":"Use Markdown . Reference functions and classes in backticks: `function_name()`. Include code examples where appropriate.","title":"Documentation Styleguide"},{"location":"src2purl/CONTRIBUTING/#development-process","text":"Fork the repo and create your branch from main . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request!","title":"Development Process"},{"location":"src2purl/CONTRIBUTING/#development-setup","text":"# Clone your fork git clone https://github.com/your-username/src2purl.git cd src2purl # Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # Install dependencies pip install -e .[dev] # Run tests pytest # Run linting ruff check . black --check .","title":"Development Setup"},{"location":"src2purl/CONTRIBUTING/#running-tests","text":"# Run all tests pytest # Run with coverage pytest --cov=src2purl # Run specific test file pytest tests/test_specific.py","title":"Running Tests"},{"location":"src2purl/CONTRIBUTING/#community","text":"You can chat with the community on: - GitHub Discussions - Issues","title":"Community"},{"location":"src2purl/CONTRIBUTING/#recognition","text":"Contributors who have made significant contributions will be recognized in our AUTHORS file. Thank you for contributing!","title":"Recognition"},{"location":"src2purl/SECURITY/","text":"Security Policy Supported Versions We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release Reporting a Vulnerability Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. Preferred Languages We prefer all communications to be in English. Policy We follow the principle of Coordinated Vulnerability Disclosure.","title":"Security Policy"},{"location":"src2purl/SECURITY/#security-policy","text":"","title":"Security Policy"},{"location":"src2purl/SECURITY/#supported-versions","text":"We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release","title":"Supported Versions"},{"location":"src2purl/SECURITY/#reporting-a-vulnerability","text":"Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly.","title":"Reporting a Vulnerability"},{"location":"src2purl/SECURITY/#preferred-languages","text":"We prefer all communications to be in English.","title":"Preferred Languages"},{"location":"src2purl/SECURITY/#policy","text":"We follow the principle of Coordinated Vulnerability Disclosure.","title":"Policy"},{"location":"src2purl/SUPPORT/","text":"Support How to Get Help Thank you for using this project! Here are the best ways to get help: Documentation Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available) Getting Answers Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly Reporting Issues If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue Feature Requests We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project Security Issues For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines. Community Guidelines Please review our Code of Conduct before participating in discussions. Response Times This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours Additional Resources Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Support"},{"location":"src2purl/SUPPORT/#support","text":"","title":"Support"},{"location":"src2purl/SUPPORT/#how-to-get-help","text":"Thank you for using this project! Here are the best ways to get help:","title":"How to Get Help"},{"location":"src2purl/SUPPORT/#documentation","text":"Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available)","title":"Documentation"},{"location":"src2purl/SUPPORT/#getting-answers","text":"Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly","title":"Getting Answers"},{"location":"src2purl/SUPPORT/#reporting-issues","text":"If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue","title":"Reporting Issues"},{"location":"src2purl/SUPPORT/#feature-requests","text":"We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project","title":"Feature Requests"},{"location":"src2purl/SUPPORT/#security-issues","text":"For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines.","title":"Security Issues"},{"location":"src2purl/SUPPORT/#community-guidelines","text":"Please review our Code of Conduct before participating in discussions.","title":"Community Guidelines"},{"location":"src2purl/SUPPORT/#response-times","text":"This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours","title":"Response Times"},{"location":"src2purl/SUPPORT/#additional-resources","text":"Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Additional Resources"},{"location":"purl2notices/","text":"PURL2NOTICES - Package URL to Legal Notices Generator Generate comprehensive legal notices and attribution documentation from Package URLs (PURLs). Automatically extracts copyright and license information from packages across 12+ ecosystems, producing customizable text and HTML output for compliance documentation. Features Multi-Format Input : Process PURLs, archives (JAR/WAR/WHL), directories, and cache files 12+ Ecosystem Support : NPM, PyPI, Maven, Cargo, Go, NuGet, Conda, and more Smart License Detection : Multiple engines (purl2src, upmex, osslili) for accurate extraction SEMCL.ONE Integration : Works seamlessly with src2purl, osslili, and ecosystem tools Installation pip install purl2notices For development: git clone https://github.com/SemClone/purl2notices.git cd purl2notices pip install -e . Quick Start # Generate notices for a single package purl2notices -i pkg:npm/express@4.0.0 # Process multiple packages from file purl2notices -i packages.txt -o NOTICE.txt # Scan directory recursively purl2notices -i ./src --recursive -o NOTICE.html -f html Usage CLI Usage # Basic notice generation purl2notices -i pkg:npm/express@4.0.0 -o NOTICE.txt # Process JAR/WAR archives purl2notices -i library.jar -o NOTICE.txt # Scan directory with caching purl2notices -i ./project --recursive --cache project.cache.json -o NOTICE.txt # Merge multiple cache files purl2notices -i cache1.json --merge-cache cache2.json -o combined-NOTICE.txt # HTML output with custom template purl2notices -i packages.txt -o NOTICE.html -f html --template custom.jinja2 # Apply license overrides purl2notices -i packages.txt --overrides custom.json -o NOTICE.txt Python API from purl2notices import Purl2Notices import asyncio # Initialize processor processor = Purl2Notices() # Process single package package = asyncio.run(processor.process_single_purl(\"pkg:npm/express@4.0.0\")) # Generate notices notices = processor.generate_notices([package]) print(notices) # Custom configuration processor = Purl2Notices( output_format=\"html\", template_path=\"custom_template.jinja2\" ) Supported Input Types Package URLs (PURLs) # NPM packages purl2notices -i pkg:npm/express@4.0.0 # Python packages purl2notices -i pkg:pypi/django@4.2.0 # Maven artifacts purl2notices -i pkg:maven/org.apache.commons/commons-lang3@3.12.0 # Multiple PURLs from file echo \"pkg:npm/express@4.0.0\" > packages.txt echo \"pkg:pypi/django@4.2.0\" >> packages.txt purl2notices -i packages.txt Archive Files # Java archives purl2notices -i application.jar purl2notices -i webapp.war # Python wheels purl2notices -i package-1.0.0-py3-none-any.whl # Process multiple archives purl2notices -i libs/*.jar -o NOTICE.txt Directories # Scan current directory purl2notices -i . -o NOTICE.txt # Recursive scan with specific patterns purl2notices -i ./src --recursive --include \"*.py\" -o NOTICE.txt # Exclude patterns purl2notices -i ./project --recursive --exclude \"test/*\" -o NOTICE.txt Cache Files # Use CycloneDX cache purl2notices -i project.cache.json -o NOTICE.txt # Merge multiple caches purl2notices -i cache1.json --merge-cache cache2.json --merge-cache cache3.json Output Formats Text Format (Default) ================================================================================ express 4.0.0 -------------------------------------------------------------------------------- Copyright (c) 2009-2014 TJ Holowaychuk <tj@vision-media.ca> Copyright (c) 2013-2014 Roman Shtylman <shtylman+expressjs@gmail.com> Copyright (c) 2014-2015 Douglas Christopher Wilson <doug@somethingdoug.com> MIT License [Full license text...] ================================================================================ HTML Format # Generate HTML with default template purl2notices -i packages.txt -o NOTICE.html -f html # Use custom Jinja2 template purl2notices -i packages.txt -o NOTICE.html -f html --template custom.jinja2 Configuration License Overrides Create a JSON file to override detected licenses: { \"pkg:npm/express@4.0.0\": { \"license\": \"MIT\", \"copyright\": \"Copyright (c) Express Authors\" } } Apply overrides: purl2notices -i packages.txt --overrides overrides.json -o NOTICE.txt Custom Templates Create custom Jinja2 templates for HTML output: <!DOCTYPE html> <html> <head><title>Legal Notices</title></head> <body> {% for package in packages %} <h2>{{ package.name }} {{ package.version }}</h2> <p>{{ package.copyright }}</p> <pre>{{ package.license_text }}</pre> {% endfor %} </body> </html> Environment Variables # Set default output format export PURL2NOTICES_FORMAT=html # Set default template path export PURL2NOTICES_TEMPLATE=/path/to/template.jinja2 # Enable debug logging export PURL2NOTICES_DEBUG=true Integration with SEMCL.ONE PURL2NOTICES is a core component of the SEMCL.ONE ecosystem: Works with src2purl for package identification from source Uses osslili for enhanced license detection Integrates with upmex for package metadata extraction Complements ospac for policy compliance evaluation Supports purl2src for source code retrieval Complete Workflow Example # 1. Identify package from source src2purl ./project > project.purl # 2. Generate legal notices purl2notices -i project.purl -o NOTICE.txt # 3. Validate compliance ospac evaluate NOTICE.txt --policy compliance.yaml Advanced Features Batch Processing # Process large lists efficiently purl2notices -i packages.txt --batch-size 20 --workers 4 -o NOTICE.txt Filtering and Exclusions # Exclude specific packages purl2notices -i packages.txt --exclude-purl \"pkg:npm/test-*\" -o NOTICE.txt # Include only specific licenses purl2notices -i packages.txt --include-license MIT --include-license Apache-2.0 Cache Management # Generate cache for later use purl2notices -i ./project --recursive --cache-only -o project.cache.json # Update existing cache purl2notices -i new-packages.txt --update-cache project.cache.json # Clear cache purl2notices --clear-cache Documentation User Guide - Comprehensive usage documentation Examples - Detailed examples and use cases Configuration - Configuration options and customization Contributing We welcome contributions! Please see CONTRIBUTING.md for details on: - Code of conduct - Development setup - Submitting pull requests - Reporting issues Support For support and questions: - GitHub Issues - Bug reports and feature requests - Documentation - Complete project documentation - SEMCL.ONE Community - Ecosystem support and discussions License Apache License 2.0 - see LICENSE file for details. Authors See AUTHORS.md for a list of contributors. Part of the SEMCL.ONE ecosystem for comprehensive OSS compliance and code analysis.","title":"purl2notices"},{"location":"purl2notices/#purl2notices-package-url-to-legal-notices-generator","text":"Generate comprehensive legal notices and attribution documentation from Package URLs (PURLs). Automatically extracts copyright and license information from packages across 12+ ecosystems, producing customizable text and HTML output for compliance documentation.","title":"PURL2NOTICES - Package URL to Legal Notices Generator"},{"location":"purl2notices/#features","text":"Multi-Format Input : Process PURLs, archives (JAR/WAR/WHL), directories, and cache files 12+ Ecosystem Support : NPM, PyPI, Maven, Cargo, Go, NuGet, Conda, and more Smart License Detection : Multiple engines (purl2src, upmex, osslili) for accurate extraction SEMCL.ONE Integration : Works seamlessly with src2purl, osslili, and ecosystem tools","title":"Features"},{"location":"purl2notices/#installation","text":"pip install purl2notices For development: git clone https://github.com/SemClone/purl2notices.git cd purl2notices pip install -e .","title":"Installation"},{"location":"purl2notices/#quick-start","text":"# Generate notices for a single package purl2notices -i pkg:npm/express@4.0.0 # Process multiple packages from file purl2notices -i packages.txt -o NOTICE.txt # Scan directory recursively purl2notices -i ./src --recursive -o NOTICE.html -f html","title":"Quick Start"},{"location":"purl2notices/#usage","text":"","title":"Usage"},{"location":"purl2notices/#cli-usage","text":"# Basic notice generation purl2notices -i pkg:npm/express@4.0.0 -o NOTICE.txt # Process JAR/WAR archives purl2notices -i library.jar -o NOTICE.txt # Scan directory with caching purl2notices -i ./project --recursive --cache project.cache.json -o NOTICE.txt # Merge multiple cache files purl2notices -i cache1.json --merge-cache cache2.json -o combined-NOTICE.txt # HTML output with custom template purl2notices -i packages.txt -o NOTICE.html -f html --template custom.jinja2 # Apply license overrides purl2notices -i packages.txt --overrides custom.json -o NOTICE.txt","title":"CLI Usage"},{"location":"purl2notices/#python-api","text":"from purl2notices import Purl2Notices import asyncio # Initialize processor processor = Purl2Notices() # Process single package package = asyncio.run(processor.process_single_purl(\"pkg:npm/express@4.0.0\")) # Generate notices notices = processor.generate_notices([package]) print(notices) # Custom configuration processor = Purl2Notices( output_format=\"html\", template_path=\"custom_template.jinja2\" )","title":"Python API"},{"location":"purl2notices/#supported-input-types","text":"","title":"Supported Input Types"},{"location":"purl2notices/#package-urls-purls","text":"# NPM packages purl2notices -i pkg:npm/express@4.0.0 # Python packages purl2notices -i pkg:pypi/django@4.2.0 # Maven artifacts purl2notices -i pkg:maven/org.apache.commons/commons-lang3@3.12.0 # Multiple PURLs from file echo \"pkg:npm/express@4.0.0\" > packages.txt echo \"pkg:pypi/django@4.2.0\" >> packages.txt purl2notices -i packages.txt","title":"Package URLs (PURLs)"},{"location":"purl2notices/#archive-files","text":"# Java archives purl2notices -i application.jar purl2notices -i webapp.war # Python wheels purl2notices -i package-1.0.0-py3-none-any.whl # Process multiple archives purl2notices -i libs/*.jar -o NOTICE.txt","title":"Archive Files"},{"location":"purl2notices/#directories","text":"# Scan current directory purl2notices -i . -o NOTICE.txt # Recursive scan with specific patterns purl2notices -i ./src --recursive --include \"*.py\" -o NOTICE.txt # Exclude patterns purl2notices -i ./project --recursive --exclude \"test/*\" -o NOTICE.txt","title":"Directories"},{"location":"purl2notices/#cache-files","text":"# Use CycloneDX cache purl2notices -i project.cache.json -o NOTICE.txt # Merge multiple caches purl2notices -i cache1.json --merge-cache cache2.json --merge-cache cache3.json","title":"Cache Files"},{"location":"purl2notices/#output-formats","text":"","title":"Output Formats"},{"location":"purl2notices/#text-format-default","text":"================================================================================ express 4.0.0 -------------------------------------------------------------------------------- Copyright (c) 2009-2014 TJ Holowaychuk <tj@vision-media.ca> Copyright (c) 2013-2014 Roman Shtylman <shtylman+expressjs@gmail.com> Copyright (c) 2014-2015 Douglas Christopher Wilson <doug@somethingdoug.com> MIT License [Full license text...] ================================================================================","title":"Text Format (Default)"},{"location":"purl2notices/#html-format","text":"# Generate HTML with default template purl2notices -i packages.txt -o NOTICE.html -f html # Use custom Jinja2 template purl2notices -i packages.txt -o NOTICE.html -f html --template custom.jinja2","title":"HTML Format"},{"location":"purl2notices/#configuration","text":"","title":"Configuration"},{"location":"purl2notices/#license-overrides","text":"Create a JSON file to override detected licenses: { \"pkg:npm/express@4.0.0\": { \"license\": \"MIT\", \"copyright\": \"Copyright (c) Express Authors\" } } Apply overrides: purl2notices -i packages.txt --overrides overrides.json -o NOTICE.txt","title":"License Overrides"},{"location":"purl2notices/#custom-templates","text":"Create custom Jinja2 templates for HTML output: <!DOCTYPE html> <html> <head><title>Legal Notices</title></head> <body> {% for package in packages %} <h2>{{ package.name }} {{ package.version }}</h2> <p>{{ package.copyright }}</p> <pre>{{ package.license_text }}</pre> {% endfor %} </body> </html>","title":"Custom Templates"},{"location":"purl2notices/#environment-variables","text":"# Set default output format export PURL2NOTICES_FORMAT=html # Set default template path export PURL2NOTICES_TEMPLATE=/path/to/template.jinja2 # Enable debug logging export PURL2NOTICES_DEBUG=true","title":"Environment Variables"},{"location":"purl2notices/#integration-with-semclone","text":"PURL2NOTICES is a core component of the SEMCL.ONE ecosystem: Works with src2purl for package identification from source Uses osslili for enhanced license detection Integrates with upmex for package metadata extraction Complements ospac for policy compliance evaluation Supports purl2src for source code retrieval","title":"Integration with SEMCL.ONE"},{"location":"purl2notices/#complete-workflow-example","text":"# 1. Identify package from source src2purl ./project > project.purl # 2. Generate legal notices purl2notices -i project.purl -o NOTICE.txt # 3. Validate compliance ospac evaluate NOTICE.txt --policy compliance.yaml","title":"Complete Workflow Example"},{"location":"purl2notices/#advanced-features","text":"","title":"Advanced Features"},{"location":"purl2notices/#batch-processing","text":"# Process large lists efficiently purl2notices -i packages.txt --batch-size 20 --workers 4 -o NOTICE.txt","title":"Batch Processing"},{"location":"purl2notices/#filtering-and-exclusions","text":"# Exclude specific packages purl2notices -i packages.txt --exclude-purl \"pkg:npm/test-*\" -o NOTICE.txt # Include only specific licenses purl2notices -i packages.txt --include-license MIT --include-license Apache-2.0","title":"Filtering and Exclusions"},{"location":"purl2notices/#cache-management","text":"# Generate cache for later use purl2notices -i ./project --recursive --cache-only -o project.cache.json # Update existing cache purl2notices -i new-packages.txt --update-cache project.cache.json # Clear cache purl2notices --clear-cache","title":"Cache Management"},{"location":"purl2notices/#documentation","text":"User Guide - Comprehensive usage documentation Examples - Detailed examples and use cases Configuration - Configuration options and customization","title":"Documentation"},{"location":"purl2notices/#contributing","text":"We welcome contributions! Please see CONTRIBUTING.md for details on: - Code of conduct - Development setup - Submitting pull requests - Reporting issues","title":"Contributing"},{"location":"purl2notices/#support","text":"For support and questions: - GitHub Issues - Bug reports and feature requests - Documentation - Complete project documentation - SEMCL.ONE Community - Ecosystem support and discussions","title":"Support"},{"location":"purl2notices/#license","text":"Apache License 2.0 - see LICENSE file for details.","title":"License"},{"location":"purl2notices/#authors","text":"See AUTHORS.md for a list of contributors. Part of the SEMCL.ONE ecosystem for comprehensive OSS compliance and code analysis.","title":"Authors"},{"location":"purl2notices/AUTHORS/","text":"Authors Project Lead Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Authors"},{"location":"purl2notices/AUTHORS/#authors","text":"","title":"Authors"},{"location":"purl2notices/AUTHORS/#project-lead","text":"Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Project Lead"},{"location":"purl2notices/CHANGELOG/","text":"Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [1.2.6] - 2025-10-30 Fixed Updated dependency from semantic-copycat-purl2src to purl2src [1.2.5] - 2025-10-28 Changed BREAKING : Renamed oslili extractor to osslili for consistent naming convention Renamed file: purl2notices/extractors/oslili_extractor.py \u2192 osslili_extractor.py Renamed class: OsliliExtractor \u2192 OssliliExtractor Updated enum: ExtractionSource.OSLILI \u2192 ExtractionSource.OSSLILI Updated all import statements and references throughout codebase Updated package naming to remove semantic-copycat prefix in documentation Updated installation commands in README and docs to use pip install purl2notices Updated repository URLs to point to SemClone/purl2notices instead of oscarvalenzuelab/semantic-copycat-purl2notices Updated GitHub Actions examples to use new package name Updated dependency from semantic-copycat-oslili>=1.3.0 to osslili>=1.3.0 Updated dependency from semantic-copycat-upmex>=1.5.0 to upmex>=1.5.0 Fixed Fixed import statements to use renamed dependency packages ( upmex , osslili ) Updated all documentation references to reflect new project and repository names Corrected logger references for renamed extractors Technical Details Updated purl2notices/__init__.py version from 1.1.8 to 1.2.5 Modified all extractor imports in __init__.py and combined_extractor.py Updated extraction source enum in base extractor class Fixed all variable references in combined extractor workflow Updated documentation in README.md , docs/user-guide.md , and docs/examples.md All tests pass with renamed components and dependencies Verified end-to-end functionality with both PURL processing and source code scanning Migration Notes If upgrading from versions < 1.2.5, existing code using OsliliExtractor will need to be updated to OssliliExtractor Cache files created with previous versions remain compatible Installation package name changes from semantic-copycat-purl2notices to purl2notices [1.2.0] - 2025-10-16 Fixed Fix KissBOM CLI parameter order mismatch that was causing validation failures Update JSON format test expectations to match actual output structure Enhance CombinedExtractor metadata merging to preserve upmex package identification fields Ensure metadata from upmex takes precedence over oslili during merge operations Remove cache file from repository to prevent accidental commits Changed Improved metadata handling in CombinedExtractor to preserve package identification data Better error handling and test coverage for CLI functionality Enhanced test suite reliability for JSON output format validation [1.1.9] - 2025-09-16 Added Full implementation of Ruby Gem and Chef cookbook detector Support for Chef cookbooks with metadata.rb and metadata.json files Support for Ruby gems with .gemspec files Support for .gem archive detection Comprehensive test coverage for Ruby/Chef detection Special handling for Chef cookbooks to process entire cookbook directory Metadata preservation for packages detected with PURLs Fixed Chef cookbooks in subdirectories are now detected as separate packages instead of being merged License information from Chef metadata.rb is properly extracted and converted to License objects Detection metadata is preserved when processing packages through PURL pipeline Homepage property access in formatter now safely retrieves from metadata dictionary (fixes #8) Changed GemDetector is no longer a stub - fully functional implementation Chef cookbooks detected locally do not generate PURLs since they cannot be downloaded from registries Improved core processor to handle Chef cookbooks specially by processing cookbook directories [1.1.8] - 2025-09-15 Added Table of Contents index for HTML notice files with navigation links Package-based anchor IDs for direct navigation to specific packages License information displayed next to each package in the index Smooth scrolling CSS for better navigation experience \"Back to Top\" link for easy return to the index Changed HTML template now lists all packages individually in the Table of Contents Anchor IDs are placed on package elements rather than license headers Improved support for package names with special characters (colons, slashes) [1.1.7] - 2025-09-10 Fixed NPM detector now properly handles node_modules as input directory Correctly detects packages when scanning node_modules directly Added Filed issue #4 for future --offline mode feature [1.1.6] - 2025-09-10 Added Explicit offline-only mode configuration for upmex extractor Changed upmex extractor now operates strictly in offline mode to prevent network lookups Improved JAR file processing reliability with fallback to oslili [1.1.5] - 2025-09-10 Fixed License text display in HTML output for grouped licenses with multiple IDs Updated minimum dependency versions for better compatibility Added python-Levenshtein for optimal fuzzy matching performance [1.1.4] - 2025-09-10 Fixed UnboundLocalError in CLI caused by duplicate sys import inside main() function [1.1.3] - 2025-09-06 Added Shell completion support for bash, zsh, and fish JSON output format ( --format json ) for programmatic processing Test suite with unit and integration tests Utility functions module to reduce code duplication Exclusion pattern support for archive file scanning Changed Archive scanner now includes hidden directories (e.g., .mvn/ ) CLI always sets recursive and max_depth configuration values Refactored to eliminate code duplication across modules Fixed CLI depth parameter ( -d ) now correctly passes to directory scanner Hidden directories are no longer skipped during archive scanning Config key mismatch for max_depth (was scan.max_depth , now scanning.max_depth ) License model missing @dataclass decorator Test data files in test directories can now be excluded with -e test [1.1.0] - 2024-01-06 Added Archive file mode for processing individual archive files (JAR, WAR, WHL, etc.) Separate package attribution for archive files during directory scans Support for merging multiple cache files with --merge-cache option Dynamic license recognition for common OSS patterns Centralized constants module for better maintainability User override system for filtering packages and modifying metadata Improved cache merging that preserves existing data Changed Directory scanning now processes archive files as separate packages with proper attribution Cache saving now merges with existing cache instead of replacing it Override system now properly applies to both new and cached packages Improved Apache license variant recognition Fixed Cache merging now properly combines packages instead of replacing User overrides are now correctly applied when loading from cache Package exclusion via exclude_purls now works correctly Archive files in deep directory structures are now properly detected Removed Dead code: unused save_cache() and validate_cache() methods from core module Unused validate() method from cache manager Various unused imports across modules [0.1.0] - 2024-01-01 Added Initial release Support for processing Package URLs (PURLs) KissBOM file processing Directory scanning for packages Cache support using CycloneDX format Multiple output formats (text, HTML) Integration with semantic-copycat ecosystem (purl2src, upmex, oslili) License and copyright extraction Configurable parallel processing Template-based output generation","title":"Changelog"},{"location":"purl2notices/CHANGELOG/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"purl2notices/CHANGELOG/#126-2025-10-30","text":"","title":"[1.2.6] - 2025-10-30"},{"location":"purl2notices/CHANGELOG/#fixed","text":"Updated dependency from semantic-copycat-purl2src to purl2src","title":"Fixed"},{"location":"purl2notices/CHANGELOG/#125-2025-10-28","text":"","title":"[1.2.5] - 2025-10-28"},{"location":"purl2notices/CHANGELOG/#changed","text":"BREAKING : Renamed oslili extractor to osslili for consistent naming convention Renamed file: purl2notices/extractors/oslili_extractor.py \u2192 osslili_extractor.py Renamed class: OsliliExtractor \u2192 OssliliExtractor Updated enum: ExtractionSource.OSLILI \u2192 ExtractionSource.OSSLILI Updated all import statements and references throughout codebase Updated package naming to remove semantic-copycat prefix in documentation Updated installation commands in README and docs to use pip install purl2notices Updated repository URLs to point to SemClone/purl2notices instead of oscarvalenzuelab/semantic-copycat-purl2notices Updated GitHub Actions examples to use new package name Updated dependency from semantic-copycat-oslili>=1.3.0 to osslili>=1.3.0 Updated dependency from semantic-copycat-upmex>=1.5.0 to upmex>=1.5.0","title":"Changed"},{"location":"purl2notices/CHANGELOG/#fixed_1","text":"Fixed import statements to use renamed dependency packages ( upmex , osslili ) Updated all documentation references to reflect new project and repository names Corrected logger references for renamed extractors","title":"Fixed"},{"location":"purl2notices/CHANGELOG/#technical-details","text":"Updated purl2notices/__init__.py version from 1.1.8 to 1.2.5 Modified all extractor imports in __init__.py and combined_extractor.py Updated extraction source enum in base extractor class Fixed all variable references in combined extractor workflow Updated documentation in README.md , docs/user-guide.md , and docs/examples.md All tests pass with renamed components and dependencies Verified end-to-end functionality with both PURL processing and source code scanning","title":"Technical Details"},{"location":"purl2notices/CHANGELOG/#migration-notes","text":"If upgrading from versions < 1.2.5, existing code using OsliliExtractor will need to be updated to OssliliExtractor Cache files created with previous versions remain compatible Installation package name changes from semantic-copycat-purl2notices to purl2notices","title":"Migration Notes"},{"location":"purl2notices/CHANGELOG/#120-2025-10-16","text":"","title":"[1.2.0] - 2025-10-16"},{"location":"purl2notices/CHANGELOG/#fixed_2","text":"Fix KissBOM CLI parameter order mismatch that was causing validation failures Update JSON format test expectations to match actual output structure Enhance CombinedExtractor metadata merging to preserve upmex package identification fields Ensure metadata from upmex takes precedence over oslili during merge operations Remove cache file from repository to prevent accidental commits","title":"Fixed"},{"location":"purl2notices/CHANGELOG/#changed_1","text":"Improved metadata handling in CombinedExtractor to preserve package identification data Better error handling and test coverage for CLI functionality Enhanced test suite reliability for JSON output format validation","title":"Changed"},{"location":"purl2notices/CHANGELOG/#119-2025-09-16","text":"","title":"[1.1.9] - 2025-09-16"},{"location":"purl2notices/CHANGELOG/#added","text":"Full implementation of Ruby Gem and Chef cookbook detector Support for Chef cookbooks with metadata.rb and metadata.json files Support for Ruby gems with .gemspec files Support for .gem archive detection Comprehensive test coverage for Ruby/Chef detection Special handling for Chef cookbooks to process entire cookbook directory Metadata preservation for packages detected with PURLs","title":"Added"},{"location":"purl2notices/CHANGELOG/#fixed_3","text":"Chef cookbooks in subdirectories are now detected as separate packages instead of being merged License information from Chef metadata.rb is properly extracted and converted to License objects Detection metadata is preserved when processing packages through PURL pipeline Homepage property access in formatter now safely retrieves from metadata dictionary (fixes #8)","title":"Fixed"},{"location":"purl2notices/CHANGELOG/#changed_2","text":"GemDetector is no longer a stub - fully functional implementation Chef cookbooks detected locally do not generate PURLs since they cannot be downloaded from registries Improved core processor to handle Chef cookbooks specially by processing cookbook directories","title":"Changed"},{"location":"purl2notices/CHANGELOG/#118-2025-09-15","text":"","title":"[1.1.8] - 2025-09-15"},{"location":"purl2notices/CHANGELOG/#added_1","text":"Table of Contents index for HTML notice files with navigation links Package-based anchor IDs for direct navigation to specific packages License information displayed next to each package in the index Smooth scrolling CSS for better navigation experience \"Back to Top\" link for easy return to the index","title":"Added"},{"location":"purl2notices/CHANGELOG/#changed_3","text":"HTML template now lists all packages individually in the Table of Contents Anchor IDs are placed on package elements rather than license headers Improved support for package names with special characters (colons, slashes)","title":"Changed"},{"location":"purl2notices/CHANGELOG/#117-2025-09-10","text":"","title":"[1.1.7] - 2025-09-10"},{"location":"purl2notices/CHANGELOG/#fixed_4","text":"NPM detector now properly handles node_modules as input directory Correctly detects packages when scanning node_modules directly","title":"Fixed"},{"location":"purl2notices/CHANGELOG/#added_2","text":"Filed issue #4 for future --offline mode feature","title":"Added"},{"location":"purl2notices/CHANGELOG/#116-2025-09-10","text":"","title":"[1.1.6] - 2025-09-10"},{"location":"purl2notices/CHANGELOG/#added_3","text":"Explicit offline-only mode configuration for upmex extractor","title":"Added"},{"location":"purl2notices/CHANGELOG/#changed_4","text":"upmex extractor now operates strictly in offline mode to prevent network lookups Improved JAR file processing reliability with fallback to oslili","title":"Changed"},{"location":"purl2notices/CHANGELOG/#115-2025-09-10","text":"","title":"[1.1.5] - 2025-09-10"},{"location":"purl2notices/CHANGELOG/#fixed_5","text":"License text display in HTML output for grouped licenses with multiple IDs Updated minimum dependency versions for better compatibility Added python-Levenshtein for optimal fuzzy matching performance","title":"Fixed"},{"location":"purl2notices/CHANGELOG/#114-2025-09-10","text":"","title":"[1.1.4] - 2025-09-10"},{"location":"purl2notices/CHANGELOG/#fixed_6","text":"UnboundLocalError in CLI caused by duplicate sys import inside main() function","title":"Fixed"},{"location":"purl2notices/CHANGELOG/#113-2025-09-06","text":"","title":"[1.1.3] - 2025-09-06"},{"location":"purl2notices/CHANGELOG/#added_4","text":"Shell completion support for bash, zsh, and fish JSON output format ( --format json ) for programmatic processing Test suite with unit and integration tests Utility functions module to reduce code duplication Exclusion pattern support for archive file scanning","title":"Added"},{"location":"purl2notices/CHANGELOG/#changed_5","text":"Archive scanner now includes hidden directories (e.g., .mvn/ ) CLI always sets recursive and max_depth configuration values Refactored to eliminate code duplication across modules","title":"Changed"},{"location":"purl2notices/CHANGELOG/#fixed_7","text":"CLI depth parameter ( -d ) now correctly passes to directory scanner Hidden directories are no longer skipped during archive scanning Config key mismatch for max_depth (was scan.max_depth , now scanning.max_depth ) License model missing @dataclass decorator Test data files in test directories can now be excluded with -e test","title":"Fixed"},{"location":"purl2notices/CHANGELOG/#110-2024-01-06","text":"","title":"[1.1.0] - 2024-01-06"},{"location":"purl2notices/CHANGELOG/#added_5","text":"Archive file mode for processing individual archive files (JAR, WAR, WHL, etc.) Separate package attribution for archive files during directory scans Support for merging multiple cache files with --merge-cache option Dynamic license recognition for common OSS patterns Centralized constants module for better maintainability User override system for filtering packages and modifying metadata Improved cache merging that preserves existing data","title":"Added"},{"location":"purl2notices/CHANGELOG/#changed_6","text":"Directory scanning now processes archive files as separate packages with proper attribution Cache saving now merges with existing cache instead of replacing it Override system now properly applies to both new and cached packages Improved Apache license variant recognition","title":"Changed"},{"location":"purl2notices/CHANGELOG/#fixed_8","text":"Cache merging now properly combines packages instead of replacing User overrides are now correctly applied when loading from cache Package exclusion via exclude_purls now works correctly Archive files in deep directory structures are now properly detected","title":"Fixed"},{"location":"purl2notices/CHANGELOG/#removed","text":"Dead code: unused save_cache() and validate_cache() methods from core module Unused validate() method from cache manager Various unused imports across modules","title":"Removed"},{"location":"purl2notices/CHANGELOG/#010-2024-01-01","text":"","title":"[0.1.0] - 2024-01-01"},{"location":"purl2notices/CHANGELOG/#added_6","text":"Initial release Support for processing Package URLs (PURLs) KissBOM file processing Directory scanning for packages Cache support using CycloneDX format Multiple output formats (text, HTML) Integration with semantic-copycat ecosystem (purl2src, upmex, oslili) License and copyright extraction Configurable parallel processing Template-based output generation","title":"Added"},{"location":"purl2notices/CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Contributor Covenant Code of Conduct"},{"location":"purl2notices/CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"purl2notices/CODE_OF_CONDUCT/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"purl2notices/CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"purl2notices/CODE_OF_CONDUCT/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"purl2notices/CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"purl2notices/CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"purl2notices/CODE_OF_CONDUCT/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"purl2notices/CODE_OF_CONDUCT/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"purl2notices/CODE_OF_CONDUCT/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"purl2notices/CODE_OF_CONDUCT/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"purl2notices/CODE_OF_CONDUCT/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"purl2notices/CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Attribution"},{"location":"purl2notices/CONTRIBUTING/","text":"Contributing to purl2notices First off, thank you for considering contributing to purl2notices! It's people like you that make purl2notices such a great tool. Code of Conduct This project and everyone participating in it is governed by the Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to conduct@semcl.one . How Can I Contribute? Reporting Bugs Before creating bug reports, please check existing issues as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one. How Do I Submit A Good Bug Report? Bugs are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem. If the problem wasn't triggered by a specific action , describe what you were doing before the problem happened and share more information using the guidelines below. Suggesting Enhancements Enhancement suggestions are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps . Include copy/pasteable snippets which you use in those examples. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users. List some other projects where this enhancement exists. Your First Code Contribution Unsure where to begin contributing? You can start by looking through these beginner and help-wanted issues: [Beginner issues][beginner] - issues which should only require a few lines of code, and a test or two. [Help wanted issues][help-wanted] - issues which should be a bit more involved than beginner issues. Pull Requests The process described here has several goals: Maintain code quality Fix problems that are important to users Engage the community in working toward the best possible product Enable a sustainable system for maintainers to review contributions Please follow these steps to have your contribution considered by the maintainers: Follow all instructions in the template Follow the styleguides After you submit your pull request, verify that all status checks are passing While the prerequisites above must be satisfied prior to having your pull request reviewed, the reviewer(s) may ask you to complete additional design work, tests, or other changes before your pull request can be ultimately accepted. Styleguides Git Commit Messages Use the present tense (\"Add feature\" not \"Added feature\") Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit the first line to 72 characters or less Reference issues and pull requests liberally after the first line When only changing documentation, include [ci skip] in the commit title Python Styleguide All Python code must adhere to PEP 8 . Use type hints where appropriate Include docstrings for all public functions, classes, and modules Prefer explicit over implicit Write tests for new functionality Documentation Styleguide Use Markdown . Reference functions and classes in backticks: `function_name()`. Include code examples where appropriate. Development Process Fork the repo and create your branch from main . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request! Development Setup # Clone your fork git clone https://github.com/your-username/purl2notices.git cd purl2notices # Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # Install dependencies pip install -e .[dev] # Run tests pytest # Run linting ruff check . black --check . Running Tests # Run all tests pytest # Run with coverage pytest --cov=purl2notices # Run specific test file pytest tests/test_specific.py Community You can chat with the community on: - GitHub Discussions - Issues Recognition Contributors who have made significant contributions will be recognized in our AUTHORS file. Thank you for contributing!","title":"Contributing to purl2notices"},{"location":"purl2notices/CONTRIBUTING/#contributing-to-purl2notices","text":"First off, thank you for considering contributing to purl2notices! It's people like you that make purl2notices such a great tool.","title":"Contributing to purl2notices"},{"location":"purl2notices/CONTRIBUTING/#code-of-conduct","text":"This project and everyone participating in it is governed by the Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to conduct@semcl.one .","title":"Code of Conduct"},{"location":"purl2notices/CONTRIBUTING/#how-can-i-contribute","text":"","title":"How Can I Contribute?"},{"location":"purl2notices/CONTRIBUTING/#reporting-bugs","text":"Before creating bug reports, please check existing issues as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one.","title":"Reporting Bugs"},{"location":"purl2notices/CONTRIBUTING/#how-do-i-submit-a-good-bug-report","text":"Bugs are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem. If the problem wasn't triggered by a specific action , describe what you were doing before the problem happened and share more information using the guidelines below.","title":"How Do I Submit A Good Bug Report?"},{"location":"purl2notices/CONTRIBUTING/#suggesting-enhancements","text":"Enhancement suggestions are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps . Include copy/pasteable snippets which you use in those examples. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users. List some other projects where this enhancement exists.","title":"Suggesting Enhancements"},{"location":"purl2notices/CONTRIBUTING/#your-first-code-contribution","text":"Unsure where to begin contributing? You can start by looking through these beginner and help-wanted issues: [Beginner issues][beginner] - issues which should only require a few lines of code, and a test or two. [Help wanted issues][help-wanted] - issues which should be a bit more involved than beginner issues.","title":"Your First Code Contribution"},{"location":"purl2notices/CONTRIBUTING/#pull-requests","text":"The process described here has several goals: Maintain code quality Fix problems that are important to users Engage the community in working toward the best possible product Enable a sustainable system for maintainers to review contributions Please follow these steps to have your contribution considered by the maintainers: Follow all instructions in the template Follow the styleguides After you submit your pull request, verify that all status checks are passing While the prerequisites above must be satisfied prior to having your pull request reviewed, the reviewer(s) may ask you to complete additional design work, tests, or other changes before your pull request can be ultimately accepted.","title":"Pull Requests"},{"location":"purl2notices/CONTRIBUTING/#styleguides","text":"","title":"Styleguides"},{"location":"purl2notices/CONTRIBUTING/#git-commit-messages","text":"Use the present tense (\"Add feature\" not \"Added feature\") Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit the first line to 72 characters or less Reference issues and pull requests liberally after the first line When only changing documentation, include [ci skip] in the commit title","title":"Git Commit Messages"},{"location":"purl2notices/CONTRIBUTING/#python-styleguide","text":"All Python code must adhere to PEP 8 . Use type hints where appropriate Include docstrings for all public functions, classes, and modules Prefer explicit over implicit Write tests for new functionality","title":"Python Styleguide"},{"location":"purl2notices/CONTRIBUTING/#documentation-styleguide","text":"Use Markdown . Reference functions and classes in backticks: `function_name()`. Include code examples where appropriate.","title":"Documentation Styleguide"},{"location":"purl2notices/CONTRIBUTING/#development-process","text":"Fork the repo and create your branch from main . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request!","title":"Development Process"},{"location":"purl2notices/CONTRIBUTING/#development-setup","text":"# Clone your fork git clone https://github.com/your-username/purl2notices.git cd purl2notices # Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # Install dependencies pip install -e .[dev] # Run tests pytest # Run linting ruff check . black --check .","title":"Development Setup"},{"location":"purl2notices/CONTRIBUTING/#running-tests","text":"# Run all tests pytest # Run with coverage pytest --cov=purl2notices # Run specific test file pytest tests/test_specific.py","title":"Running Tests"},{"location":"purl2notices/CONTRIBUTING/#community","text":"You can chat with the community on: - GitHub Discussions - Issues","title":"Community"},{"location":"purl2notices/CONTRIBUTING/#recognition","text":"Contributors who have made significant contributions will be recognized in our AUTHORS file. Thank you for contributing!","title":"Recognition"},{"location":"purl2notices/SECURITY/","text":"Security Policy Supported Versions We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release Reporting a Vulnerability Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. Preferred Languages We prefer all communications to be in English. Policy We follow the principle of Coordinated Vulnerability Disclosure.","title":"Security Policy"},{"location":"purl2notices/SECURITY/#security-policy","text":"","title":"Security Policy"},{"location":"purl2notices/SECURITY/#supported-versions","text":"We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release","title":"Supported Versions"},{"location":"purl2notices/SECURITY/#reporting-a-vulnerability","text":"Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly.","title":"Reporting a Vulnerability"},{"location":"purl2notices/SECURITY/#preferred-languages","text":"We prefer all communications to be in English.","title":"Preferred Languages"},{"location":"purl2notices/SECURITY/#policy","text":"We follow the principle of Coordinated Vulnerability Disclosure.","title":"Policy"},{"location":"purl2notices/SUPPORT/","text":"Support How to Get Help Thank you for using this project! Here are the best ways to get help: Documentation Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available) Getting Answers Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly Reporting Issues If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue Feature Requests We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project Security Issues For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines. Community Guidelines Please review our Code of Conduct before participating in discussions. Response Times This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours Additional Resources Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Support"},{"location":"purl2notices/SUPPORT/#support","text":"","title":"Support"},{"location":"purl2notices/SUPPORT/#how-to-get-help","text":"Thank you for using this project! Here are the best ways to get help:","title":"How to Get Help"},{"location":"purl2notices/SUPPORT/#documentation","text":"Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available)","title":"Documentation"},{"location":"purl2notices/SUPPORT/#getting-answers","text":"Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly","title":"Getting Answers"},{"location":"purl2notices/SUPPORT/#reporting-issues","text":"If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue","title":"Reporting Issues"},{"location":"purl2notices/SUPPORT/#feature-requests","text":"We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project","title":"Feature Requests"},{"location":"purl2notices/SUPPORT/#security-issues","text":"For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines.","title":"Security Issues"},{"location":"purl2notices/SUPPORT/#community-guidelines","text":"Please review our Code of Conduct before participating in discussions.","title":"Community Guidelines"},{"location":"purl2notices/SUPPORT/#response-times","text":"This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours","title":"Response Times"},{"location":"purl2notices/SUPPORT/#additional-resources","text":"Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Additional Resources"},{"location":"vulnq/","text":"vulnq - Vulnerability Query Tool vulnq is a lightweight, multi-source vulnerability query tool that consolidates security data from multiple vulnerability databases. It accepts various software identifiers (PURLs, CPEs, hashes) and returns comprehensive vulnerability information including CVEs, severity scores, and available fixes. Key Features Multiple ID Formats - Accepts PURLs, CPE strings, and file hashes Multi-Source Aggregation - Queries OSV.dev, GitHub Advisory, NIST NVD, and more Smart Format Detection - Auto-detects input format or accepts explicit flags Upgrade Path Suggestions - Identifies fixed versions when available Lightweight - API-only design, no local vulnerability databases Flexible Output - JSON, table, and markdown formats Installation pip install vulnq For development: git clone https://github.com/scanoss/vulnq.git cd vulnq pip install -e . Quick Start Command Line # Query using Package URL (auto-detected) vulnq pkg:npm/express@4.17.1 # Query using CPE string (example: Apache Log4j) vulnq --cpe \"cpe:2.3:a:apache:log4j:2.14.0:*:*:*:*:*:*:*\" # Note: Hash-based queries are not currently supported by vulnerability databases # Query multiple identifiers from file vulnq --input packages.txt # Filter by severity vulnq pkg:pypi/django@3.2.1 --min-severity high # Output as JSON vulnq pkg:gem/rails@6.0.0 --format json # Include fixed versions only vulnq pkg:maven/org.apache.logging.log4j/log4j-core@2.14.1 --show-fixes Python API from vulnq import VulnerabilityQuery # Initialize the query engine vq = VulnerabilityQuery() # Query by PURL results = vq.query(\"pkg:npm/express@4.17.1\") # Query by CPE results = vq.query_cpe(\"cpe:2.3:a:apache:log4j:2.14.0:*:*:*:*:*:*:*\") # Note: Hash queries are not currently supported by vulnerability databases # Future versions may support this through file-to-package mapping services # Process results for vuln in results.vulnerabilities: print(f\"{vuln.id}: {vuln.severity} - {vuln.summary}\") if vuln.fixed_versions: print(f\" Fixed in: {', '.join(vuln.fixed_versions)}\") Supported Vulnerability Sources OSV.dev - Google's Open Source Vulnerability database GitHub Advisory Database - GitHub Security Advisories NIST NVD - National Vulnerability Database FIRST.org - Forum of Incident Response and Security Teams (planned) Sonatype OSS Index - Component vulnerability data (planned) Supported Identifier Formats Package URLs (PURLs) pkg:npm/package@version pkg:pypi/package@version pkg:maven/group/artifact@version pkg:gem/package@version pkg:cargo/package@version pkg:nuget/package@version pkg:golang/module@version CPE (Common Platform Enumeration) cpe:2.3:a:vendor:product:version:*:*:*:*:*:*:* cpe:/a:vendor:product:version (legacy format) File Hashes SHA256 SHA1 MD5 Configuration vulnq can be configured via environment variables or config file: # API Keys (optional, for higher rate limits) export GITHUB_TOKEN=\"your_github_token\" export NVD_API_KEY=\"your_nvd_api_key\" # Cache settings export VULNQ_CACHE_DIR=\"~/.vulnq/cache\" export VULNQ_CACHE_TTL=\"3600\" # seconds # Rate limiting export VULNQ_MAX_CONCURRENT=\"5\" Integration with SEMCL.ONE vulnq is designed to work seamlessly with other SEMCL.ONE tools: # Pipe PURLs from src2purl to vulnq src2purl /path/to/project | vulnq --format json # Check vulnerabilities for detected packages upmex /path/to/package.json | vulnq --min-severity critical # Generate vulnerability report from SBOM cat sbom.json | vulnq --input - --format markdown > vulns.md Output Formats Table (default) \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 CVE \u2502 Severity \u2502 CVSS \u2502 Package \u2502 Fixed In \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 CVE-2021-1234\u2502 HIGH \u2502 7.5 \u2502 express@4.17.1 \u2502 4.17.2 \u2502 \u2502 CVE-2021-5678\u2502 CRITICAL \u2502 9.8 \u2502 express@4.17.1 \u2502 4.18.0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 JSON { \"query\": \"pkg:npm/express@4.17.1\", \"vulnerabilities\": [ { \"id\": \"CVE-2021-1234\", \"severity\": \"HIGH\", \"cvss_score\": 7.5, \"summary\": \"Remote Code Execution...\", \"fixed_versions\": [\"4.17.2\", \"4.18.0\"], \"references\": [...] } ], \"metadata\": { \"sources\": [\"osv\", \"github\", \"nvd\"], \"query_time\": \"2024-11-04T10:30:00Z\" } } Development Running Tests # Run all tests pytest # Run with coverage pytest --cov=vulnq tests/ # Run specific test pytest tests/test_osv_client.py -v Building # Build package python -m build # Install locally for testing pip install -e . Contributing We welcome contributions! Please see CONTRIBUTING.md for details. License vulnq is released under the Apache License 2.0. See LICENSE for details. Support Issues : GitHub Issues Discussions : GitHub Discussions Security : Report vulnerabilities to security@scanoss.com Part of the SEMCL.ONE Software Composition Analysis toolchain","title":"vulnq"},{"location":"vulnq/#vulnq-vulnerability-query-tool","text":"vulnq is a lightweight, multi-source vulnerability query tool that consolidates security data from multiple vulnerability databases. It accepts various software identifiers (PURLs, CPEs, hashes) and returns comprehensive vulnerability information including CVEs, severity scores, and available fixes.","title":"vulnq - Vulnerability Query Tool"},{"location":"vulnq/#key-features","text":"Multiple ID Formats - Accepts PURLs, CPE strings, and file hashes Multi-Source Aggregation - Queries OSV.dev, GitHub Advisory, NIST NVD, and more Smart Format Detection - Auto-detects input format or accepts explicit flags Upgrade Path Suggestions - Identifies fixed versions when available Lightweight - API-only design, no local vulnerability databases Flexible Output - JSON, table, and markdown formats","title":"Key Features"},{"location":"vulnq/#installation","text":"pip install vulnq For development: git clone https://github.com/scanoss/vulnq.git cd vulnq pip install -e .","title":"Installation"},{"location":"vulnq/#quick-start","text":"","title":"Quick Start"},{"location":"vulnq/#command-line","text":"# Query using Package URL (auto-detected) vulnq pkg:npm/express@4.17.1 # Query using CPE string (example: Apache Log4j) vulnq --cpe \"cpe:2.3:a:apache:log4j:2.14.0:*:*:*:*:*:*:*\" # Note: Hash-based queries are not currently supported by vulnerability databases # Query multiple identifiers from file vulnq --input packages.txt # Filter by severity vulnq pkg:pypi/django@3.2.1 --min-severity high # Output as JSON vulnq pkg:gem/rails@6.0.0 --format json # Include fixed versions only vulnq pkg:maven/org.apache.logging.log4j/log4j-core@2.14.1 --show-fixes","title":"Command Line"},{"location":"vulnq/#python-api","text":"from vulnq import VulnerabilityQuery # Initialize the query engine vq = VulnerabilityQuery() # Query by PURL results = vq.query(\"pkg:npm/express@4.17.1\") # Query by CPE results = vq.query_cpe(\"cpe:2.3:a:apache:log4j:2.14.0:*:*:*:*:*:*:*\") # Note: Hash queries are not currently supported by vulnerability databases # Future versions may support this through file-to-package mapping services # Process results for vuln in results.vulnerabilities: print(f\"{vuln.id}: {vuln.severity} - {vuln.summary}\") if vuln.fixed_versions: print(f\" Fixed in: {', '.join(vuln.fixed_versions)}\")","title":"Python API"},{"location":"vulnq/#supported-vulnerability-sources","text":"OSV.dev - Google's Open Source Vulnerability database GitHub Advisory Database - GitHub Security Advisories NIST NVD - National Vulnerability Database FIRST.org - Forum of Incident Response and Security Teams (planned) Sonatype OSS Index - Component vulnerability data (planned)","title":"Supported Vulnerability Sources"},{"location":"vulnq/#supported-identifier-formats","text":"","title":"Supported Identifier Formats"},{"location":"vulnq/#package-urls-purls","text":"pkg:npm/package@version pkg:pypi/package@version pkg:maven/group/artifact@version pkg:gem/package@version pkg:cargo/package@version pkg:nuget/package@version pkg:golang/module@version","title":"Package URLs (PURLs)"},{"location":"vulnq/#cpe-common-platform-enumeration","text":"cpe:2.3:a:vendor:product:version:*:*:*:*:*:*:* cpe:/a:vendor:product:version (legacy format)","title":"CPE (Common Platform Enumeration)"},{"location":"vulnq/#file-hashes","text":"SHA256 SHA1 MD5","title":"File Hashes"},{"location":"vulnq/#configuration","text":"vulnq can be configured via environment variables or config file: # API Keys (optional, for higher rate limits) export GITHUB_TOKEN=\"your_github_token\" export NVD_API_KEY=\"your_nvd_api_key\" # Cache settings export VULNQ_CACHE_DIR=\"~/.vulnq/cache\" export VULNQ_CACHE_TTL=\"3600\" # seconds # Rate limiting export VULNQ_MAX_CONCURRENT=\"5\"","title":"Configuration"},{"location":"vulnq/#integration-with-semclone","text":"vulnq is designed to work seamlessly with other SEMCL.ONE tools: # Pipe PURLs from src2purl to vulnq src2purl /path/to/project | vulnq --format json # Check vulnerabilities for detected packages upmex /path/to/package.json | vulnq --min-severity critical # Generate vulnerability report from SBOM cat sbom.json | vulnq --input - --format markdown > vulns.md","title":"Integration with SEMCL.ONE"},{"location":"vulnq/#output-formats","text":"","title":"Output Formats"},{"location":"vulnq/#table-default","text":"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 CVE \u2502 Severity \u2502 CVSS \u2502 Package \u2502 Fixed In \u2502 \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 \u2502 CVE-2021-1234\u2502 HIGH \u2502 7.5 \u2502 express@4.17.1 \u2502 4.17.2 \u2502 \u2502 CVE-2021-5678\u2502 CRITICAL \u2502 9.8 \u2502 express@4.17.1 \u2502 4.18.0 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518","title":"Table (default)"},{"location":"vulnq/#json","text":"{ \"query\": \"pkg:npm/express@4.17.1\", \"vulnerabilities\": [ { \"id\": \"CVE-2021-1234\", \"severity\": \"HIGH\", \"cvss_score\": 7.5, \"summary\": \"Remote Code Execution...\", \"fixed_versions\": [\"4.17.2\", \"4.18.0\"], \"references\": [...] } ], \"metadata\": { \"sources\": [\"osv\", \"github\", \"nvd\"], \"query_time\": \"2024-11-04T10:30:00Z\" } }","title":"JSON"},{"location":"vulnq/#development","text":"","title":"Development"},{"location":"vulnq/#running-tests","text":"# Run all tests pytest # Run with coverage pytest --cov=vulnq tests/ # Run specific test pytest tests/test_osv_client.py -v","title":"Running Tests"},{"location":"vulnq/#building","text":"# Build package python -m build # Install locally for testing pip install -e .","title":"Building"},{"location":"vulnq/#contributing","text":"We welcome contributions! Please see CONTRIBUTING.md for details.","title":"Contributing"},{"location":"vulnq/#license","text":"vulnq is released under the Apache License 2.0. See LICENSE for details.","title":"License"},{"location":"vulnq/#support","text":"Issues : GitHub Issues Discussions : GitHub Discussions Security : Report vulnerabilities to security@scanoss.com Part of the SEMCL.ONE Software Composition Analysis toolchain","title":"Support"},{"location":"vulnq/AUTHORS/","text":"Authors Project Lead Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Authors"},{"location":"vulnq/AUTHORS/#authors","text":"","title":"Authors"},{"location":"vulnq/AUTHORS/#project-lead","text":"Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Project Lead"},{"location":"vulnq/CHANGELOG/","text":"Changelog All notable changes to vulnq will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . 1.0.1 - 2025-01-05 Fixed Replace broken pip-licenses with osslili-based license checking workflow Update deprecated GitHub Actions (upload-artifact v3 \u2192 v4, CodeQL v2 \u2192 v3) Fix PyPI publishing to use GitHub OIDC trusted publishing instead of API tokens Add explicit permissions to all workflow jobs for security best practices Remove unnecessary files (Makefile, .pre-commit-config.yaml) for consistency Remove Related Projects section from README Changed Standardize Python version to 3.13 across all workflows Align workflow structure with other SEMCL.ONE projects 1.0.0 - 2025-01-05 Added Full implementation of vulnerability querying from multiple sources Real API client implementations for OSV.dev, GitHub Advisory, and NIST NVD Support for VulnerableCode as an optional aggregated source Parallel asynchronous queries for improved performance Advanced deduplication and data normalization across sources CVSS score parsing from vector strings No API keys required for OSV.dev and VulnerableCode Optional API keys for enhanced rate limits (GitHub, NVD) Proper session management to prevent resource leaks Changed Upgraded from mock implementations to production-ready API clients Improved error handling and retry logic with exponential backoff Enhanced vulnerability merging logic with source prioritization Better CVSS score extraction from various formats Fixed Session cleanup warnings in async operations CVSS vector string parsing for OSV.dev responses CPE string normalization and parsing Deduplication using CVE as primary identifier 0.1.0 - 2024-11-04 Added Initial release of vulnq Support for multiple identifier formats (PURL, CPE, hashes) Integration with OSV.dev API Integration with GitHub Advisory Database Integration with NIST NVD Command-line interface with multiple output formats (table, JSON, markdown) Python API for programmatic access Caching support for API responses Severity filtering capabilities Batch processing from input files Security Secure API key handling via environment variables Rate limiting for API calls","title":"Changelog"},{"location":"vulnq/CHANGELOG/#changelog","text":"All notable changes to vulnq will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"vulnq/CHANGELOG/#101-2025-01-05","text":"","title":"1.0.1 - 2025-01-05"},{"location":"vulnq/CHANGELOG/#fixed","text":"Replace broken pip-licenses with osslili-based license checking workflow Update deprecated GitHub Actions (upload-artifact v3 \u2192 v4, CodeQL v2 \u2192 v3) Fix PyPI publishing to use GitHub OIDC trusted publishing instead of API tokens Add explicit permissions to all workflow jobs for security best practices Remove unnecessary files (Makefile, .pre-commit-config.yaml) for consistency Remove Related Projects section from README","title":"Fixed"},{"location":"vulnq/CHANGELOG/#changed","text":"Standardize Python version to 3.13 across all workflows Align workflow structure with other SEMCL.ONE projects","title":"Changed"},{"location":"vulnq/CHANGELOG/#100-2025-01-05","text":"","title":"1.0.0 - 2025-01-05"},{"location":"vulnq/CHANGELOG/#added","text":"Full implementation of vulnerability querying from multiple sources Real API client implementations for OSV.dev, GitHub Advisory, and NIST NVD Support for VulnerableCode as an optional aggregated source Parallel asynchronous queries for improved performance Advanced deduplication and data normalization across sources CVSS score parsing from vector strings No API keys required for OSV.dev and VulnerableCode Optional API keys for enhanced rate limits (GitHub, NVD) Proper session management to prevent resource leaks","title":"Added"},{"location":"vulnq/CHANGELOG/#changed_1","text":"Upgraded from mock implementations to production-ready API clients Improved error handling and retry logic with exponential backoff Enhanced vulnerability merging logic with source prioritization Better CVSS score extraction from various formats","title":"Changed"},{"location":"vulnq/CHANGELOG/#fixed_1","text":"Session cleanup warnings in async operations CVSS vector string parsing for OSV.dev responses CPE string normalization and parsing Deduplication using CVE as primary identifier","title":"Fixed"},{"location":"vulnq/CHANGELOG/#010-2024-11-04","text":"","title":"0.1.0 - 2024-11-04"},{"location":"vulnq/CHANGELOG/#added_1","text":"Initial release of vulnq Support for multiple identifier formats (PURL, CPE, hashes) Integration with OSV.dev API Integration with GitHub Advisory Database Integration with NIST NVD Command-line interface with multiple output formats (table, JSON, markdown) Python API for programmatic access Caching support for API responses Severity filtering capabilities Batch processing from input files","title":"Added"},{"location":"vulnq/CHANGELOG/#security","text":"Secure API key handling via environment variables Rate limiting for API calls","title":"Security"},{"location":"vulnq/CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Contributor Covenant Code of Conduct"},{"location":"vulnq/CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"vulnq/CODE_OF_CONDUCT/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"vulnq/CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"vulnq/CODE_OF_CONDUCT/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"vulnq/CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"vulnq/CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"vulnq/CODE_OF_CONDUCT/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"vulnq/CODE_OF_CONDUCT/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"vulnq/CODE_OF_CONDUCT/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"vulnq/CODE_OF_CONDUCT/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"vulnq/CODE_OF_CONDUCT/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"vulnq/CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Attribution"},{"location":"vulnq/CONTRIBUTING/","text":"Contributing to vulnq We welcome contributions to vulnq! This document provides guidelines and instructions for contributing. Code of Conduct By participating in this project, you agree to abide by our Code of Conduct, which promotes a respectful and inclusive environment for all contributors. How to Contribute Reporting Issues Check if the issue already exists in the issue tracker Provide a clear description of the problem Include steps to reproduce the issue Specify your environment (OS, Python version, vulnq version) Suggesting Enhancements Open an issue describing the enhancement Explain the use case and benefits Provide examples if possible Pull Requests Fork the repository Create a feature branch ( git checkout -b feature/amazing-feature ) Make your changes Add or update tests as needed Ensure all tests pass ( pytest ) Update documentation if needed Commit your changes ( git commit -m 'Add amazing feature' ) Push to your branch ( git push origin feature/amazing-feature ) Open a Pull Request Development Setup Clone the repository: bash git clone https://github.com/scanoss/vulnq.git cd vulnq Create a virtual environment: bash python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate Install in development mode: bash pip install -e .[dev] Install pre-commit hooks: bash pre-commit install Testing Run the test suite: pytest Run with coverage: pytest --cov=vulnq tests/ Run specific tests: pytest tests/test_utils.py -v Code Style We use the following tools to maintain code quality: Black for code formatting isort for import sorting flake8 for linting mypy for type checking Run all checks: black vulnq/ isort vulnq/ flake8 vulnq/ mypy vulnq/ Or use pre-commit: pre-commit run --all-files Documentation Update the README.md if you change functionality Add docstrings to all public functions and classes Update CHANGELOG.md following Keep a Changelog format Adding New Vulnerability Sources To add support for a new vulnerability database: Create a new client module in vulnq/clients/ Implement the client following the existing pattern Add the source to VulnerabilitySource enum Update the core query logic to use your client Add tests for the new functionality Update documentation Example structure: # vulnq/clients/new_source.py class NewSourceClient: async def query(self, identifier: str) -> List[Vulnerability]: # Implementation here pass Commit Messages Follow these guidelines for commit messages: Use present tense (\"Add feature\" not \"Added feature\") Use imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit first line to 72 characters Reference issues and pull requests when relevant Release Process Update version in pyproject.toml Update CHANGELOG.md Create a git tag: git tag v0.1.0 Push tag: git push origin v0.1.0 GitHub Actions will automatically publish to PyPI Questions? Feel free to open an issue or discussion on GitHub if you have questions about contributing. Thank you for contributing to vulnq!","title":"Contributing to vulnq"},{"location":"vulnq/CONTRIBUTING/#contributing-to-vulnq","text":"We welcome contributions to vulnq! This document provides guidelines and instructions for contributing.","title":"Contributing to vulnq"},{"location":"vulnq/CONTRIBUTING/#code-of-conduct","text":"By participating in this project, you agree to abide by our Code of Conduct, which promotes a respectful and inclusive environment for all contributors.","title":"Code of Conduct"},{"location":"vulnq/CONTRIBUTING/#how-to-contribute","text":"","title":"How to Contribute"},{"location":"vulnq/CONTRIBUTING/#reporting-issues","text":"Check if the issue already exists in the issue tracker Provide a clear description of the problem Include steps to reproduce the issue Specify your environment (OS, Python version, vulnq version)","title":"Reporting Issues"},{"location":"vulnq/CONTRIBUTING/#suggesting-enhancements","text":"Open an issue describing the enhancement Explain the use case and benefits Provide examples if possible","title":"Suggesting Enhancements"},{"location":"vulnq/CONTRIBUTING/#pull-requests","text":"Fork the repository Create a feature branch ( git checkout -b feature/amazing-feature ) Make your changes Add or update tests as needed Ensure all tests pass ( pytest ) Update documentation if needed Commit your changes ( git commit -m 'Add amazing feature' ) Push to your branch ( git push origin feature/amazing-feature ) Open a Pull Request","title":"Pull Requests"},{"location":"vulnq/CONTRIBUTING/#development-setup","text":"Clone the repository: bash git clone https://github.com/scanoss/vulnq.git cd vulnq Create a virtual environment: bash python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate Install in development mode: bash pip install -e .[dev] Install pre-commit hooks: bash pre-commit install","title":"Development Setup"},{"location":"vulnq/CONTRIBUTING/#testing","text":"Run the test suite: pytest Run with coverage: pytest --cov=vulnq tests/ Run specific tests: pytest tests/test_utils.py -v","title":"Testing"},{"location":"vulnq/CONTRIBUTING/#code-style","text":"We use the following tools to maintain code quality: Black for code formatting isort for import sorting flake8 for linting mypy for type checking Run all checks: black vulnq/ isort vulnq/ flake8 vulnq/ mypy vulnq/ Or use pre-commit: pre-commit run --all-files","title":"Code Style"},{"location":"vulnq/CONTRIBUTING/#documentation","text":"Update the README.md if you change functionality Add docstrings to all public functions and classes Update CHANGELOG.md following Keep a Changelog format","title":"Documentation"},{"location":"vulnq/CONTRIBUTING/#adding-new-vulnerability-sources","text":"To add support for a new vulnerability database: Create a new client module in vulnq/clients/ Implement the client following the existing pattern Add the source to VulnerabilitySource enum Update the core query logic to use your client Add tests for the new functionality Update documentation Example structure: # vulnq/clients/new_source.py class NewSourceClient: async def query(self, identifier: str) -> List[Vulnerability]: # Implementation here pass","title":"Adding New Vulnerability Sources"},{"location":"vulnq/CONTRIBUTING/#commit-messages","text":"Follow these guidelines for commit messages: Use present tense (\"Add feature\" not \"Added feature\") Use imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit first line to 72 characters Reference issues and pull requests when relevant","title":"Commit Messages"},{"location":"vulnq/CONTRIBUTING/#release-process","text":"Update version in pyproject.toml Update CHANGELOG.md Create a git tag: git tag v0.1.0 Push tag: git push origin v0.1.0 GitHub Actions will automatically publish to PyPI","title":"Release Process"},{"location":"vulnq/CONTRIBUTING/#questions","text":"Feel free to open an issue or discussion on GitHub if you have questions about contributing. Thank you for contributing to vulnq!","title":"Questions?"},{"location":"vulnq/SECURITY/","text":"Security Policy Supported Versions We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release Reporting a Vulnerability Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. Preferred Languages We prefer all communications to be in English. Policy We follow the principle of Coordinated Vulnerability Disclosure.","title":"Security Policy"},{"location":"vulnq/SECURITY/#security-policy","text":"","title":"Security Policy"},{"location":"vulnq/SECURITY/#supported-versions","text":"We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release","title":"Supported Versions"},{"location":"vulnq/SECURITY/#reporting-a-vulnerability","text":"Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly.","title":"Reporting a Vulnerability"},{"location":"vulnq/SECURITY/#preferred-languages","text":"We prefer all communications to be in English.","title":"Preferred Languages"},{"location":"vulnq/SECURITY/#policy","text":"We follow the principle of Coordinated Vulnerability Disclosure.","title":"Policy"},{"location":"vulnq/SUPPORT/","text":"Support How to Get Help Thank you for using this project! Here are the best ways to get help: Documentation Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available) Getting Answers Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly Reporting Issues If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue Feature Requests We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project Security Issues For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines. Community Guidelines Please review our Code of Conduct before participating in discussions. Response Times This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours Additional Resources Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Support"},{"location":"vulnq/SUPPORT/#support","text":"","title":"Support"},{"location":"vulnq/SUPPORT/#how-to-get-help","text":"Thank you for using this project! Here are the best ways to get help:","title":"How to Get Help"},{"location":"vulnq/SUPPORT/#documentation","text":"Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available)","title":"Documentation"},{"location":"vulnq/SUPPORT/#getting-answers","text":"Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly","title":"Getting Answers"},{"location":"vulnq/SUPPORT/#reporting-issues","text":"If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue","title":"Reporting Issues"},{"location":"vulnq/SUPPORT/#feature-requests","text":"We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project","title":"Feature Requests"},{"location":"vulnq/SUPPORT/#security-issues","text":"For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines.","title":"Security Issues"},{"location":"vulnq/SUPPORT/#community-guidelines","text":"Please review our Code of Conduct before participating in discussions.","title":"Community Guidelines"},{"location":"vulnq/SUPPORT/#response-times","text":"This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours","title":"Response Times"},{"location":"vulnq/SUPPORT/#additional-resources","text":"Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Additional Resources"},{"location":"ospac/","text":"OSPAC - Open Source Policy as Code OSPAC (Open Source Policy as Code) is a comprehensive policy engine for automated OSS license compliance. It provides a declarative, data-driven approach where all compliance logic, rules, and decisions are defined in versionable policy files rather than hardcoded in application logic. Key Features Policy as Code - All compliance logic is defined in YAML/JSON policy files SPDX Integration - Built-in support for SPDX license identifiers Compatibility Engine - Complex license compatibility evaluation Obligation Tracking - Automated compliance checklist generation Extensible - Easy to add new licenses, rules, and regulations CLI & API - Both command-line and programmatic interfaces Core Philosophy Everything in OSPAC is policy-defined, not code-defined: No hardcoded business logic - All rules are data-driven Versionable - Policies in Git, reviewable via PR Testable - Unit test your policies Composable - Build complex policies from simple rules Auditable - Clear lineage of decisions Installation pip install ospac For development with SEMCL.ONE integration: pip install \"ospac[semcl]\" How It Works OSPAC provides both: 1. Data Generation Pipeline - Downloads SPDX licenses and generates comprehensive policy datasets 2. Runtime Engine - Evaluates licenses against policies using the generated data Data Generation OSPAC includes a pipeline that: - Downloads the complete SPDX license dataset (700+ licenses) - Optionally uses LLM (Ollama + llama3) for enhanced analysis via StrandsAgents SDK - Generates comprehensive policy files with: - License categorizations (permissive, copyleft, etc.) - Compatibility matrices - Obligation databases - Regulatory requirements Quick Start Policy Evaluation # Evaluate licenses against policies ospac evaluate --licenses GPL-3.0,MIT --context static_linking # Check license compatibility ospac check GPL-3.0 MIT --context static_linking # Get license obligations ospac obligations --licenses Apache-2.0,MIT --format checklist # Initialize a new policy from template ospac init --template enterprise --output my_policy.yaml # Validate policy syntax ospac validate ./my_policy.yaml Python API from ospac import PolicyRuntime # Initialize runtime with policies runtime = PolicyRuntime.from_path(\"policies/\") # Evaluate licenses result = runtime.evaluate({ \"licenses_found\": [\"GPL-3.0\", \"MIT\"], \"context\": \"static_linking\", \"distribution\": \"commercial\" }) # Check compatibility compat = runtime.check_compatibility(\"GPL-3.0\", \"MIT\", \"static_linking\") # Get obligations obligations = runtime.get_obligations([\"Apache-2.0\", \"MIT\"]) Data Generation (First Time Setup) # Download SPDX dataset and generate basic policy data ospac data download-spdx # Generate complete policy dataset (basic analysis) ospac data generate --output-dir ./data # Generate with LLM-enhanced analysis (requires Ollama with llama3) ospac data generate --use-llm --output-dir ./data # Validate generated data ospac data validate --data-dir ./data # Query specific license from database ospac data show MIT --format yaml Policy Files OSPAC uses declarative policy files to define all compliance logic: License Definition # policies/licenses/spdx/MIT.yaml license: id: MIT type: permissive requirements: include_license: true include_copyright: true compatibility: static_linking: compatible_with: [category: any] Organizational Policy # policies/organizations/my_company.yaml version: \"1.0\" rules: - id: no_copyleft when: license_type: copyleft_strong then: action: deny message: \"Strong copyleft licenses not allowed\" Integration with SEMCL.ONE OSPAC integrates seamlessly with the SEMCL.ONE ecosystem: # Use with osslili for license detection from osslili import scan_directory from ospac import PolicyRuntime # Detect licenses licenses = scan_directory(\"/path/to/project\") # Validate against policy runtime = PolicyRuntime.from_path(\"policies/\") result = runtime.evaluate({\"licenses_found\": licenses}) Project Structure ospac/ \u251c\u2500\u2500 runtime/ # Policy execution engine \u251c\u2500\u2500 policies/ # Policy definitions (Policy as Code) \u2502 \u251c\u2500\u2500 licenses/ # License definitions \u2502 \u251c\u2500\u2500 compatibility/ # Compatibility rules \u2502 \u251c\u2500\u2500 obligations/ # License obligations \u2502 \u2514\u2500\u2500 organizations/ # Org-specific policies \u251c\u2500\u2500 models/ # Data models \u251c\u2500\u2500 cli/ # CLI interface \u2514\u2500\u2500 utils/ # Utilities Contributing We welcome contributions! Please see CONTRIBUTING.md for details. Support For support, please: - Check the documentation - File an issue on GitHub - See SUPPORT.md for more options License Apache-2.0 - See LICENSE for details. Authors See AUTHORS.md for a list of contributors. Acknowledgments SPDX Project for license standardization SEMCL.ONE ecosystem for integration capabilities Open Chain Project for compliance best practices","title":"ospac"},{"location":"ospac/#ospac-open-source-policy-as-code","text":"OSPAC (Open Source Policy as Code) is a comprehensive policy engine for automated OSS license compliance. It provides a declarative, data-driven approach where all compliance logic, rules, and decisions are defined in versionable policy files rather than hardcoded in application logic.","title":"OSPAC - Open Source Policy as Code"},{"location":"ospac/#key-features","text":"Policy as Code - All compliance logic is defined in YAML/JSON policy files SPDX Integration - Built-in support for SPDX license identifiers Compatibility Engine - Complex license compatibility evaluation Obligation Tracking - Automated compliance checklist generation Extensible - Easy to add new licenses, rules, and regulations CLI & API - Both command-line and programmatic interfaces","title":"Key Features"},{"location":"ospac/#core-philosophy","text":"Everything in OSPAC is policy-defined, not code-defined: No hardcoded business logic - All rules are data-driven Versionable - Policies in Git, reviewable via PR Testable - Unit test your policies Composable - Build complex policies from simple rules Auditable - Clear lineage of decisions","title":"Core Philosophy"},{"location":"ospac/#installation","text":"pip install ospac For development with SEMCL.ONE integration: pip install \"ospac[semcl]\"","title":"Installation"},{"location":"ospac/#how-it-works","text":"OSPAC provides both: 1. Data Generation Pipeline - Downloads SPDX licenses and generates comprehensive policy datasets 2. Runtime Engine - Evaluates licenses against policies using the generated data","title":"How It Works"},{"location":"ospac/#data-generation","text":"OSPAC includes a pipeline that: - Downloads the complete SPDX license dataset (700+ licenses) - Optionally uses LLM (Ollama + llama3) for enhanced analysis via StrandsAgents SDK - Generates comprehensive policy files with: - License categorizations (permissive, copyleft, etc.) - Compatibility matrices - Obligation databases - Regulatory requirements","title":"Data Generation"},{"location":"ospac/#quick-start","text":"","title":"Quick Start"},{"location":"ospac/#policy-evaluation","text":"# Evaluate licenses against policies ospac evaluate --licenses GPL-3.0,MIT --context static_linking # Check license compatibility ospac check GPL-3.0 MIT --context static_linking # Get license obligations ospac obligations --licenses Apache-2.0,MIT --format checklist # Initialize a new policy from template ospac init --template enterprise --output my_policy.yaml # Validate policy syntax ospac validate ./my_policy.yaml","title":"Policy Evaluation"},{"location":"ospac/#python-api","text":"from ospac import PolicyRuntime # Initialize runtime with policies runtime = PolicyRuntime.from_path(\"policies/\") # Evaluate licenses result = runtime.evaluate({ \"licenses_found\": [\"GPL-3.0\", \"MIT\"], \"context\": \"static_linking\", \"distribution\": \"commercial\" }) # Check compatibility compat = runtime.check_compatibility(\"GPL-3.0\", \"MIT\", \"static_linking\") # Get obligations obligations = runtime.get_obligations([\"Apache-2.0\", \"MIT\"])","title":"Python API"},{"location":"ospac/#data-generation-first-time-setup","text":"# Download SPDX dataset and generate basic policy data ospac data download-spdx # Generate complete policy dataset (basic analysis) ospac data generate --output-dir ./data # Generate with LLM-enhanced analysis (requires Ollama with llama3) ospac data generate --use-llm --output-dir ./data # Validate generated data ospac data validate --data-dir ./data # Query specific license from database ospac data show MIT --format yaml","title":"Data Generation (First Time Setup)"},{"location":"ospac/#policy-files","text":"OSPAC uses declarative policy files to define all compliance logic:","title":"Policy Files"},{"location":"ospac/#license-definition","text":"# policies/licenses/spdx/MIT.yaml license: id: MIT type: permissive requirements: include_license: true include_copyright: true compatibility: static_linking: compatible_with: [category: any]","title":"License Definition"},{"location":"ospac/#organizational-policy","text":"# policies/organizations/my_company.yaml version: \"1.0\" rules: - id: no_copyleft when: license_type: copyleft_strong then: action: deny message: \"Strong copyleft licenses not allowed\"","title":"Organizational Policy"},{"location":"ospac/#integration-with-semclone","text":"OSPAC integrates seamlessly with the SEMCL.ONE ecosystem: # Use with osslili for license detection from osslili import scan_directory from ospac import PolicyRuntime # Detect licenses licenses = scan_directory(\"/path/to/project\") # Validate against policy runtime = PolicyRuntime.from_path(\"policies/\") result = runtime.evaluate({\"licenses_found\": licenses})","title":"Integration with SEMCL.ONE"},{"location":"ospac/#project-structure","text":"ospac/ \u251c\u2500\u2500 runtime/ # Policy execution engine \u251c\u2500\u2500 policies/ # Policy definitions (Policy as Code) \u2502 \u251c\u2500\u2500 licenses/ # License definitions \u2502 \u251c\u2500\u2500 compatibility/ # Compatibility rules \u2502 \u251c\u2500\u2500 obligations/ # License obligations \u2502 \u2514\u2500\u2500 organizations/ # Org-specific policies \u251c\u2500\u2500 models/ # Data models \u251c\u2500\u2500 cli/ # CLI interface \u2514\u2500\u2500 utils/ # Utilities","title":"Project Structure"},{"location":"ospac/#contributing","text":"We welcome contributions! Please see CONTRIBUTING.md for details.","title":"Contributing"},{"location":"ospac/#support","text":"For support, please: - Check the documentation - File an issue on GitHub - See SUPPORT.md for more options","title":"Support"},{"location":"ospac/#license","text":"Apache-2.0 - See LICENSE for details.","title":"License"},{"location":"ospac/#authors","text":"See AUTHORS.md for a list of contributors.","title":"Authors"},{"location":"ospac/#acknowledgments","text":"SPDX Project for license standardization SEMCL.ONE ecosystem for integration capabilities Open Chain Project for compliance best practices","title":"Acknowledgments"},{"location":"ospac/AUTHORS/","text":"Authors Project Lead Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Authors"},{"location":"ospac/AUTHORS/#authors","text":"","title":"Authors"},{"location":"ospac/AUTHORS/#project-lead","text":"Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Project Lead"},{"location":"ospac/CHANGELOG/","text":"Changelog All notable changes to OSPAC (Open Source Policy as Code) will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [1.0.4] - 2025-11-04 Fixed CLI Command Improvements - Fixed ospac obligations command returning no output - Corrected policy loader integration for obligation data retrieval - Updated get_obligations method to properly traverse nested policy structure - Resolved obligation policy path resolution for CLI commands GitHub Actions Workflow - Removed duplicate release workflow causing PyPI publishing conflicts - Consolidated to standard python-publish.yml workflow - Fixed action errors during release process Changed Internal Architecture - Improved PolicyRuntime obligation handling for nested policy files - Enhanced policy loader to correctly map obligation policies - Standardized workflow configuration to prevent CI/CD conflicts 1.0.3 - 2025-11-04 Fixed Critical Data Quality Corrections - Fixed systematic license limitation value errors across all 712 SPDX licenses - Corrected liability and warranty limitation semantics (false = license disclaims, not provides) - Fixed Apache-2.0 license classification as permissive (removed incorrect copyleft requirements) - Corrected MIT license patent grant status (false, as MIT provides no explicit patent grant) - Fixed Apache-2.0 patent grant status (true, as Apache-2.0 provides explicit patent grants) Data Generation Pipeline Improvements - Fixed fallback analysis methods in LLM analyzer and provider modules - Improved LLM prompt clarity for limitation field semantics - Enhanced license-specific handling for Apache, MIT, GPL, LGPL, and AGPL families - Standardized copyleft vs permissive license requirement patterns AGPL License Data Corrections - Fixed inconsistent license compatibility data across all AGPL license variants - Corrected AGPL-3.0.yaml incompatible licenses list (MIT-LICENSED \u2192 MIT) - Fixed AGPL-3.0-or-later.yaml limitation values and same_license requirements - Updated contamination_effect values for strong copyleft licenses (module \u2192 full) - Standardized incompatible license naming (Proprietary \u2192 proprietary) Database Integrity - Regenerated complete license database with corrected pipeline logic - Ensured consistent data structure and semantics across all license definitions - Maintained compatibility with existing CLI functionality and policy evaluation - Verified all 712 SPDX licenses have accurate legal metadata Technical Details Root cause identified in fallback analysis methods with incorrect default values Fixed semantic interpretation of limitation fields in license analysis Improved license categorization logic for permissive vs copyleft licenses Enhanced compatibility matrix generation with corrected license relationships 1.0.2 - 2025-11-04 Added Complete SPDX license database coverage (712/712 licenses) All Apache family licenses now included (Apache-1.0, Apache-1.1, Apache-2.0) Enhanced data generation process for comprehensive license coverage Fixed Critical issue where Apache-2.0 and other licenses were missing from the main database Data generation process bug that excluded previously processed licenses from master database YAML format conversion issues between individual license files and database generation Database completeness ensuring all 712 SPDX licenses are accessible via CLI Changed Updated data generation flow to include all processed licenses instead of incremental updates only Improved license database structure to support complete SPDX license set Enhanced compatibility checking to work with full license catalog Technical Details Fixed ospac/pipeline/data_generator.py to use all analyzed licenses in master database generation Added _convert_yaml_format() function to transform YAML license data to expected database format Updated database from 638 to 712 licenses with complete metadata and compatibility rules 1.0.1 - 2025-11-05 Added Package now includes all default data files in distribution 700+ SPDX license files Compatibility matrices and relationships Pre-generated obligation database MANIFEST.in for proper source distribution packaging Changed Data directory moved to ospac/data/ for wheel distribution compatibility Updated pyproject.toml with comprehensive package-data configuration Fixed Default data now ships with PyPI package installation Users can use the tool immediately without generating data first 0.1.0 - 2025-11-04 Added Initial release of OSPAC - Open Source Policy as Code engine Core features: Policy-as-code framework for OSS license compliance SPDX license database integration (712 licenses) License compatibility checking system Obligation tracking and enforcement CLI tool for policy evaluation Data generation pipeline: SPDX license processor LLM-enhanced analysis support (OpenAI, Ollama) Compatibility matrix generation Split matrix architecture for efficient storage Runtime engine: YAML-based policy definitions Rule evaluation system Context-aware compliance checking Decision tree support CLI commands: ospac evaluate - Evaluate licenses against policies ospac check-compat - Check compatibility between licenses ospac data generate - Generate license database ospac data show - Display license information ospac data download-spdx - Download SPDX dataset Technical Details Python 3.9+ support Async/await architecture for LLM operations Efficient sparse matrix storage for compatibility data Comprehensive test suite (52 tests) GitHub Actions CI/CD pipeline Known Issues 13 SPDX licenses return 404 from API (fallback data provided) LLM analysis optional but recommended for enhanced accuracy","title":"Changelog"},{"location":"ospac/CHANGELOG/#changelog","text":"All notable changes to OSPAC (Open Source Policy as Code) will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"ospac/CHANGELOG/#104-2025-11-04","text":"","title":"[1.0.4] - 2025-11-04"},{"location":"ospac/CHANGELOG/#fixed","text":"CLI Command Improvements - Fixed ospac obligations command returning no output - Corrected policy loader integration for obligation data retrieval - Updated get_obligations method to properly traverse nested policy structure - Resolved obligation policy path resolution for CLI commands GitHub Actions Workflow - Removed duplicate release workflow causing PyPI publishing conflicts - Consolidated to standard python-publish.yml workflow - Fixed action errors during release process","title":"Fixed"},{"location":"ospac/CHANGELOG/#changed","text":"Internal Architecture - Improved PolicyRuntime obligation handling for nested policy files - Enhanced policy loader to correctly map obligation policies - Standardized workflow configuration to prevent CI/CD conflicts","title":"Changed"},{"location":"ospac/CHANGELOG/#103-2025-11-04","text":"","title":"1.0.3 - 2025-11-04"},{"location":"ospac/CHANGELOG/#fixed_1","text":"Critical Data Quality Corrections - Fixed systematic license limitation value errors across all 712 SPDX licenses - Corrected liability and warranty limitation semantics (false = license disclaims, not provides) - Fixed Apache-2.0 license classification as permissive (removed incorrect copyleft requirements) - Corrected MIT license patent grant status (false, as MIT provides no explicit patent grant) - Fixed Apache-2.0 patent grant status (true, as Apache-2.0 provides explicit patent grants) Data Generation Pipeline Improvements - Fixed fallback analysis methods in LLM analyzer and provider modules - Improved LLM prompt clarity for limitation field semantics - Enhanced license-specific handling for Apache, MIT, GPL, LGPL, and AGPL families - Standardized copyleft vs permissive license requirement patterns AGPL License Data Corrections - Fixed inconsistent license compatibility data across all AGPL license variants - Corrected AGPL-3.0.yaml incompatible licenses list (MIT-LICENSED \u2192 MIT) - Fixed AGPL-3.0-or-later.yaml limitation values and same_license requirements - Updated contamination_effect values for strong copyleft licenses (module \u2192 full) - Standardized incompatible license naming (Proprietary \u2192 proprietary) Database Integrity - Regenerated complete license database with corrected pipeline logic - Ensured consistent data structure and semantics across all license definitions - Maintained compatibility with existing CLI functionality and policy evaluation - Verified all 712 SPDX licenses have accurate legal metadata","title":"Fixed"},{"location":"ospac/CHANGELOG/#technical-details","text":"Root cause identified in fallback analysis methods with incorrect default values Fixed semantic interpretation of limitation fields in license analysis Improved license categorization logic for permissive vs copyleft licenses Enhanced compatibility matrix generation with corrected license relationships","title":"Technical Details"},{"location":"ospac/CHANGELOG/#102-2025-11-04","text":"","title":"1.0.2 - 2025-11-04"},{"location":"ospac/CHANGELOG/#added","text":"Complete SPDX license database coverage (712/712 licenses) All Apache family licenses now included (Apache-1.0, Apache-1.1, Apache-2.0) Enhanced data generation process for comprehensive license coverage","title":"Added"},{"location":"ospac/CHANGELOG/#fixed_2","text":"Critical issue where Apache-2.0 and other licenses were missing from the main database Data generation process bug that excluded previously processed licenses from master database YAML format conversion issues between individual license files and database generation Database completeness ensuring all 712 SPDX licenses are accessible via CLI","title":"Fixed"},{"location":"ospac/CHANGELOG/#changed_1","text":"Updated data generation flow to include all processed licenses instead of incremental updates only Improved license database structure to support complete SPDX license set Enhanced compatibility checking to work with full license catalog","title":"Changed"},{"location":"ospac/CHANGELOG/#technical-details_1","text":"Fixed ospac/pipeline/data_generator.py to use all analyzed licenses in master database generation Added _convert_yaml_format() function to transform YAML license data to expected database format Updated database from 638 to 712 licenses with complete metadata and compatibility rules","title":"Technical Details"},{"location":"ospac/CHANGELOG/#101-2025-11-05","text":"","title":"1.0.1 - 2025-11-05"},{"location":"ospac/CHANGELOG/#added_1","text":"Package now includes all default data files in distribution 700+ SPDX license files Compatibility matrices and relationships Pre-generated obligation database MANIFEST.in for proper source distribution packaging","title":"Added"},{"location":"ospac/CHANGELOG/#changed_2","text":"Data directory moved to ospac/data/ for wheel distribution compatibility Updated pyproject.toml with comprehensive package-data configuration","title":"Changed"},{"location":"ospac/CHANGELOG/#fixed_3","text":"Default data now ships with PyPI package installation Users can use the tool immediately without generating data first","title":"Fixed"},{"location":"ospac/CHANGELOG/#010-2025-11-04","text":"","title":"0.1.0 - 2025-11-04"},{"location":"ospac/CHANGELOG/#added_2","text":"Initial release of OSPAC - Open Source Policy as Code engine Core features: Policy-as-code framework for OSS license compliance SPDX license database integration (712 licenses) License compatibility checking system Obligation tracking and enforcement CLI tool for policy evaluation Data generation pipeline: SPDX license processor LLM-enhanced analysis support (OpenAI, Ollama) Compatibility matrix generation Split matrix architecture for efficient storage Runtime engine: YAML-based policy definitions Rule evaluation system Context-aware compliance checking Decision tree support CLI commands: ospac evaluate - Evaluate licenses against policies ospac check-compat - Check compatibility between licenses ospac data generate - Generate license database ospac data show - Display license information ospac data download-spdx - Download SPDX dataset","title":"Added"},{"location":"ospac/CHANGELOG/#technical-details_2","text":"Python 3.9+ support Async/await architecture for LLM operations Efficient sparse matrix storage for compatibility data Comprehensive test suite (52 tests) GitHub Actions CI/CD pipeline","title":"Technical Details"},{"location":"ospac/CHANGELOG/#known-issues","text":"13 SPDX licenses return 404 from API (fallback data provided) LLM analysis optional but recommended for enhanced accuracy","title":"Known Issues"},{"location":"ospac/CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Contributor Covenant Code of Conduct"},{"location":"ospac/CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"ospac/CODE_OF_CONDUCT/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"ospac/CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"ospac/CODE_OF_CONDUCT/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"ospac/CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"ospac/CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"ospac/CODE_OF_CONDUCT/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"ospac/CODE_OF_CONDUCT/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"ospac/CODE_OF_CONDUCT/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"ospac/CODE_OF_CONDUCT/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"ospac/CODE_OF_CONDUCT/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"ospac/CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Attribution"},{"location":"ospac/CONTRIBUTING/","text":"Contributing to osslili First off, thank you for considering contributing to osslili! It's people like you that make osslili such a great tool. Code of Conduct This project and everyone participating in it is governed by the Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to conduct@semcl.one . How Can I Contribute? Reporting Bugs Before creating bug reports, please check existing issues as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one. How Do I Submit A Good Bug Report? Bugs are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem. If the problem wasn't triggered by a specific action , describe what you were doing before the problem happened and share more information using the guidelines below. Suggesting Enhancements Enhancement suggestions are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps . Include copy/pasteable snippets which you use in those examples. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users. List some other projects where this enhancement exists. Your First Code Contribution Unsure where to begin contributing? You can start by looking through these beginner and help-wanted issues: [Beginner issues][beginner] - issues which should only require a few lines of code, and a test or two. [Help wanted issues][help-wanted] - issues which should be a bit more involved than beginner issues. Pull Requests The process described here has several goals: Maintain code quality Fix problems that are important to users Engage the community in working toward the best possible product Enable a sustainable system for maintainers to review contributions Please follow these steps to have your contribution considered by the maintainers: Follow all instructions in the template Follow the styleguides After you submit your pull request, verify that all status checks are passing While the prerequisites above must be satisfied prior to having your pull request reviewed, the reviewer(s) may ask you to complete additional design work, tests, or other changes before your pull request can be ultimately accepted. Styleguides Git Commit Messages Use the present tense (\"Add feature\" not \"Added feature\") Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit the first line to 72 characters or less Reference issues and pull requests liberally after the first line When only changing documentation, include [ci skip] in the commit title Python Styleguide All Python code must adhere to PEP 8 . Use type hints where appropriate Include docstrings for all public functions, classes, and modules Prefer explicit over implicit Write tests for new functionality Documentation Styleguide Use Markdown . Reference functions and classes in backticks: `function_name()`. Include code examples where appropriate. Development Process Fork the repo and create your branch from main . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request! Development Setup # Clone your fork git clone https://github.com/your-username/osslili.git cd osslili # Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # Install dependencies pip install -e .[dev] # Run tests pytest # Run linting ruff check . black --check . Running Tests # Run all tests pytest # Run with coverage pytest --cov=osslili # Run specific test file pytest tests/test_specific.py Community You can chat with the community on: - GitHub Discussions - Issues Recognition Contributors who have made significant contributions will be recognized in our AUTHORS file. Thank you for contributing!","title":"Contributing to osslili"},{"location":"ospac/CONTRIBUTING/#contributing-to-osslili","text":"First off, thank you for considering contributing to osslili! It's people like you that make osslili such a great tool.","title":"Contributing to osslili"},{"location":"ospac/CONTRIBUTING/#code-of-conduct","text":"This project and everyone participating in it is governed by the Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to conduct@semcl.one .","title":"Code of Conduct"},{"location":"ospac/CONTRIBUTING/#how-can-i-contribute","text":"","title":"How Can I Contribute?"},{"location":"ospac/CONTRIBUTING/#reporting-bugs","text":"Before creating bug reports, please check existing issues as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one.","title":"Reporting Bugs"},{"location":"ospac/CONTRIBUTING/#how-do-i-submit-a-good-bug-report","text":"Bugs are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem. If the problem wasn't triggered by a specific action , describe what you were doing before the problem happened and share more information using the guidelines below.","title":"How Do I Submit A Good Bug Report?"},{"location":"ospac/CONTRIBUTING/#suggesting-enhancements","text":"Enhancement suggestions are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps . Include copy/pasteable snippets which you use in those examples. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users. List some other projects where this enhancement exists.","title":"Suggesting Enhancements"},{"location":"ospac/CONTRIBUTING/#your-first-code-contribution","text":"Unsure where to begin contributing? You can start by looking through these beginner and help-wanted issues: [Beginner issues][beginner] - issues which should only require a few lines of code, and a test or two. [Help wanted issues][help-wanted] - issues which should be a bit more involved than beginner issues.","title":"Your First Code Contribution"},{"location":"ospac/CONTRIBUTING/#pull-requests","text":"The process described here has several goals: Maintain code quality Fix problems that are important to users Engage the community in working toward the best possible product Enable a sustainable system for maintainers to review contributions Please follow these steps to have your contribution considered by the maintainers: Follow all instructions in the template Follow the styleguides After you submit your pull request, verify that all status checks are passing While the prerequisites above must be satisfied prior to having your pull request reviewed, the reviewer(s) may ask you to complete additional design work, tests, or other changes before your pull request can be ultimately accepted.","title":"Pull Requests"},{"location":"ospac/CONTRIBUTING/#styleguides","text":"","title":"Styleguides"},{"location":"ospac/CONTRIBUTING/#git-commit-messages","text":"Use the present tense (\"Add feature\" not \"Added feature\") Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit the first line to 72 characters or less Reference issues and pull requests liberally after the first line When only changing documentation, include [ci skip] in the commit title","title":"Git Commit Messages"},{"location":"ospac/CONTRIBUTING/#python-styleguide","text":"All Python code must adhere to PEP 8 . Use type hints where appropriate Include docstrings for all public functions, classes, and modules Prefer explicit over implicit Write tests for new functionality","title":"Python Styleguide"},{"location":"ospac/CONTRIBUTING/#documentation-styleguide","text":"Use Markdown . Reference functions and classes in backticks: `function_name()`. Include code examples where appropriate.","title":"Documentation Styleguide"},{"location":"ospac/CONTRIBUTING/#development-process","text":"Fork the repo and create your branch from main . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request!","title":"Development Process"},{"location":"ospac/CONTRIBUTING/#development-setup","text":"# Clone your fork git clone https://github.com/your-username/osslili.git cd osslili # Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # Install dependencies pip install -e .[dev] # Run tests pytest # Run linting ruff check . black --check .","title":"Development Setup"},{"location":"ospac/CONTRIBUTING/#running-tests","text":"# Run all tests pytest # Run with coverage pytest --cov=osslili # Run specific test file pytest tests/test_specific.py","title":"Running Tests"},{"location":"ospac/CONTRIBUTING/#community","text":"You can chat with the community on: - GitHub Discussions - Issues","title":"Community"},{"location":"ospac/CONTRIBUTING/#recognition","text":"Contributors who have made significant contributions will be recognized in our AUTHORS file. Thank you for contributing!","title":"Recognition"},{"location":"ospac/SECURITY/","text":"Security Policy Supported Versions We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release Reporting a Vulnerability Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. Preferred Languages We prefer all communications to be in English. Policy We follow the principle of Coordinated Vulnerability Disclosure.","title":"Security Policy"},{"location":"ospac/SECURITY/#security-policy","text":"","title":"Security Policy"},{"location":"ospac/SECURITY/#supported-versions","text":"We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release","title":"Supported Versions"},{"location":"ospac/SECURITY/#reporting-a-vulnerability","text":"Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly.","title":"Reporting a Vulnerability"},{"location":"ospac/SECURITY/#preferred-languages","text":"We prefer all communications to be in English.","title":"Preferred Languages"},{"location":"ospac/SECURITY/#policy","text":"We follow the principle of Coordinated Vulnerability Disclosure.","title":"Policy"},{"location":"ospac/SUPPORT/","text":"Support How to Get Help Thank you for using this project! Here are the best ways to get help: Documentation Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available) Getting Answers Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly Reporting Issues If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue Feature Requests We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project Security Issues For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines. Community Guidelines Please review our Code of Conduct before participating in discussions. Response Times This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours Additional Resources Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Support"},{"location":"ospac/SUPPORT/#support","text":"","title":"Support"},{"location":"ospac/SUPPORT/#how-to-get-help","text":"Thank you for using this project! Here are the best ways to get help:","title":"How to Get Help"},{"location":"ospac/SUPPORT/#documentation","text":"Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available)","title":"Documentation"},{"location":"ospac/SUPPORT/#getting-answers","text":"Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly","title":"Getting Answers"},{"location":"ospac/SUPPORT/#reporting-issues","text":"If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue","title":"Reporting Issues"},{"location":"ospac/SUPPORT/#feature-requests","text":"We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project","title":"Feature Requests"},{"location":"ospac/SUPPORT/#security-issues","text":"For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines.","title":"Security Issues"},{"location":"ospac/SUPPORT/#community-guidelines","text":"Please review our Code of Conduct before participating in discussions.","title":"Community Guidelines"},{"location":"ospac/SUPPORT/#response-times","text":"This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours","title":"Response Times"},{"location":"ospac/SUPPORT/#additional-resources","text":"Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Additional Resources"},{"location":"ossnotices/","text":"OSS Notices Generator - Simplified Legal Notices for Open Source Projects A streamlined tool for generating legal notices from open source dependencies. Built on the powerful purl2notices library, ossnotices provides a simple interface for scanning source code and producing attribution documentation required for OSS compliance. Features Simple Interface : Streamlined CLI for scanning local source code and archives Multi-Format Support : Generate notices in text, HTML, or JSON formats Archive Processing : Handle JAR, WAR, WHL, ZIP, and other archive formats SEMCL.ONE Integration : Seamlessly works with other ecosystem tools for comprehensive compliance workflows Installation pip install ossnotices For development: git clone https://github.com/SemClone/ossnotices.git cd ossnotices pip install -e . Quick Start # Scan current directory and generate default NOTICE.txt ossnotices # Process a specific project directory ossnotices ./my-project --recursive -o NOTICE.txt Usage CLI Usage # Basic directory scanning ossnotices ./src --recursive -o NOTICE.txt # Process archive files ossnotices library.jar -o NOTICE.txt # Generate HTML format for documentation ossnotices ./project -f html -o notices.html # JSON output for further processing ossnotices ./project -f json -o notices.json # Quiet mode for CI/CD pipelines ossnotices . -q -o NOTICE.txt Command Line Options Usage: ossnotices [OPTIONS] [PATH] Arguments: PATH Directory or archive file to scan (default: current directory) Options: --version Show version and exit -o, --output PATH Output file path (default: NOTICE.txt) -f, --format TYPE Output format: text, html, json (default: text) -r, --recursive Scan directories recursively --cache/--no-cache Enable/disable caching (default: enabled) -v, --verbose Enable verbose output -q, --quiet Suppress all output except errors --help Show help and exit Configuration Caching is enabled by default and stores package information in .ossnotices.cache.json for faster subsequent runs. # Disable caching ossnotices . --no-cache Integration with SEMCL.ONE OSS Notices Generator is part of the comprehensive SEMCL.ONE compliance ecosystem: Works with src2purl for package identification Integrates with purl2notices for detailed attribution generation Complements osslili for license detection Supports upmex package metadata extraction Supported Input Types Source Directories : Recursively scans for package dependencies Archive Files : JAR, WAR, WHL, ZIP, TAR, GZ, BZ2, EGG formats Supported Package Ecosystems Through purl2notices integration: - Python (PyPI) - JavaScript/Node.js (npm) - Java (Maven) - Ruby (RubyGems) - Go modules - Rust (Cargo) - .NET (NuGet) - PHP (Composer) - And many more... Documentation User Guide - Comprehensive usage examples API Reference - Python API documentation Examples - Common workflows and integration patterns Contributing We welcome contributions! Please see CONTRIBUTING.md for details on: - Code of conduct - Development setup - Submitting pull requests - Reporting issues Support For support and questions: - GitHub Issues - Bug reports and feature requests - Documentation - Complete project documentation - SEMCL.ONE Community - Ecosystem support and discussions License Apache License 2.0 - see LICENSE file for details. Authors See AUTHORS.md for a list of contributors. Part of the SEMCL.ONE ecosystem for comprehensive OSS compliance and code analysis.","title":"ossnotices"},{"location":"ossnotices/#oss-notices-generator-simplified-legal-notices-for-open-source-projects","text":"A streamlined tool for generating legal notices from open source dependencies. Built on the powerful purl2notices library, ossnotices provides a simple interface for scanning source code and producing attribution documentation required for OSS compliance.","title":"OSS Notices Generator - Simplified Legal Notices for Open Source Projects"},{"location":"ossnotices/#features","text":"Simple Interface : Streamlined CLI for scanning local source code and archives Multi-Format Support : Generate notices in text, HTML, or JSON formats Archive Processing : Handle JAR, WAR, WHL, ZIP, and other archive formats SEMCL.ONE Integration : Seamlessly works with other ecosystem tools for comprehensive compliance workflows","title":"Features"},{"location":"ossnotices/#installation","text":"pip install ossnotices For development: git clone https://github.com/SemClone/ossnotices.git cd ossnotices pip install -e .","title":"Installation"},{"location":"ossnotices/#quick-start","text":"# Scan current directory and generate default NOTICE.txt ossnotices # Process a specific project directory ossnotices ./my-project --recursive -o NOTICE.txt","title":"Quick Start"},{"location":"ossnotices/#usage","text":"","title":"Usage"},{"location":"ossnotices/#cli-usage","text":"# Basic directory scanning ossnotices ./src --recursive -o NOTICE.txt # Process archive files ossnotices library.jar -o NOTICE.txt # Generate HTML format for documentation ossnotices ./project -f html -o notices.html # JSON output for further processing ossnotices ./project -f json -o notices.json # Quiet mode for CI/CD pipelines ossnotices . -q -o NOTICE.txt","title":"CLI Usage"},{"location":"ossnotices/#command-line-options","text":"Usage: ossnotices [OPTIONS] [PATH] Arguments: PATH Directory or archive file to scan (default: current directory) Options: --version Show version and exit -o, --output PATH Output file path (default: NOTICE.txt) -f, --format TYPE Output format: text, html, json (default: text) -r, --recursive Scan directories recursively --cache/--no-cache Enable/disable caching (default: enabled) -v, --verbose Enable verbose output -q, --quiet Suppress all output except errors --help Show help and exit","title":"Command Line Options"},{"location":"ossnotices/#configuration","text":"Caching is enabled by default and stores package information in .ossnotices.cache.json for faster subsequent runs. # Disable caching ossnotices . --no-cache","title":"Configuration"},{"location":"ossnotices/#integration-with-semclone","text":"OSS Notices Generator is part of the comprehensive SEMCL.ONE compliance ecosystem: Works with src2purl for package identification Integrates with purl2notices for detailed attribution generation Complements osslili for license detection Supports upmex package metadata extraction","title":"Integration with SEMCL.ONE"},{"location":"ossnotices/#supported-input-types","text":"Source Directories : Recursively scans for package dependencies Archive Files : JAR, WAR, WHL, ZIP, TAR, GZ, BZ2, EGG formats","title":"Supported Input Types"},{"location":"ossnotices/#supported-package-ecosystems","text":"Through purl2notices integration: - Python (PyPI) - JavaScript/Node.js (npm) - Java (Maven) - Ruby (RubyGems) - Go modules - Rust (Cargo) - .NET (NuGet) - PHP (Composer) - And many more...","title":"Supported Package Ecosystems"},{"location":"ossnotices/#documentation","text":"User Guide - Comprehensive usage examples API Reference - Python API documentation Examples - Common workflows and integration patterns","title":"Documentation"},{"location":"ossnotices/#contributing","text":"We welcome contributions! Please see CONTRIBUTING.md for details on: - Code of conduct - Development setup - Submitting pull requests - Reporting issues","title":"Contributing"},{"location":"ossnotices/#support","text":"For support and questions: - GitHub Issues - Bug reports and feature requests - Documentation - Complete project documentation - SEMCL.ONE Community - Ecosystem support and discussions","title":"Support"},{"location":"ossnotices/#license","text":"Apache License 2.0 - see LICENSE file for details.","title":"License"},{"location":"ossnotices/#authors","text":"See AUTHORS.md for a list of contributors. Part of the SEMCL.ONE ecosystem for comprehensive OSS compliance and code analysis.","title":"Authors"},{"location":"ossnotices/AUTHORS/","text":"Authors Project Lead Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Authors"},{"location":"ossnotices/AUTHORS/#authors","text":"","title":"Authors"},{"location":"ossnotices/AUTHORS/#project-lead","text":"Oscar Valenzuela B. - Project creator and maintainer For a complete list of all contributors, please see the GitHub contributors page .","title":"Project Lead"},{"location":"ossnotices/CODE_OF_CONDUCT/","text":"Contributor Covenant Code of Conduct Our Pledge We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community. Our Standards Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Enforcement Responsibilities Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate. Scope This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident. Enforcement Guidelines Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct: 1. Correction Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. 2. Warning Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban. 3. Temporary Ban Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban. 4. Permanent Ban Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community. Attribution This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Contributor Covenant Code of Conduct"},{"location":"ossnotices/CODE_OF_CONDUCT/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"ossnotices/CODE_OF_CONDUCT/#our-pledge","text":"We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.","title":"Our Pledge"},{"location":"ossnotices/CODE_OF_CONDUCT/#our-standards","text":"Examples of behavior that contributes to a positive environment for our community include: Demonstrating empathy and kindness toward other people Being respectful of differing opinions, viewpoints, and experiences Giving and gracefully accepting constructive feedback Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience Focusing on what is best not just for us as individuals, but for the overall community Examples of unacceptable behavior include: The use of sexualized language or imagery, and sexual attention or advances of any kind Trolling, insulting or derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or email address, without their explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"ossnotices/CODE_OF_CONDUCT/#enforcement-responsibilities","text":"Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful. Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.","title":"Enforcement Responsibilities"},{"location":"ossnotices/CODE_OF_CONDUCT/#scope","text":"This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.","title":"Scope"},{"location":"ossnotices/CODE_OF_CONDUCT/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at conduct@semcl.one. All complaints will be reviewed and investigated promptly and fairly. All community leaders are obligated to respect the privacy and security of the reporter of any incident.","title":"Enforcement"},{"location":"ossnotices/CODE_OF_CONDUCT/#enforcement-guidelines","text":"Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:","title":"Enforcement Guidelines"},{"location":"ossnotices/CODE_OF_CONDUCT/#1-correction","text":"Community Impact : Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community. Consequence : A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.","title":"1. Correction"},{"location":"ossnotices/CODE_OF_CONDUCT/#2-warning","text":"Community Impact : A violation through a single incident or series of actions. Consequence : A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.","title":"2. Warning"},{"location":"ossnotices/CODE_OF_CONDUCT/#3-temporary-ban","text":"Community Impact : A serious violation of community standards, including sustained inappropriate behavior. Consequence : A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.","title":"3. Temporary Ban"},{"location":"ossnotices/CODE_OF_CONDUCT/#4-permanent-ban","text":"Community Impact : Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals. Consequence : A permanent ban from any sort of public interaction within the community.","title":"4. Permanent Ban"},{"location":"ossnotices/CODE_OF_CONDUCT/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html . Community Impact Guidelines were inspired by Mozilla's code of conduct enforcement ladder . For answers to common questions about this code of conduct, see the FAQ at https://www.contributor-covenant.org/faq . Translations are available at https://www.contributor-covenant.org/translations .","title":"Attribution"},{"location":"ossnotices/CONTRIBUTING/","text":"Contributing to ossnotices First off, thank you for considering contributing to ossnotices! It's people like you that make ossnotices such a great tool. Code of Conduct This project and everyone participating in it is governed by the Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to conduct@semcl.one . How Can I Contribute? Reporting Bugs Before creating bug reports, please check existing issues as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one. How Do I Submit A Good Bug Report? Bugs are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem. If the problem wasn't triggered by a specific action , describe what you were doing before the problem happened and share more information using the guidelines below. Suggesting Enhancements Enhancement suggestions are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps . Include copy/pasteable snippets which you use in those examples. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users. List some other projects where this enhancement exists. Your First Code Contribution Unsure where to begin contributing? You can start by looking through these beginner and help-wanted issues: [Beginner issues][beginner] - issues which should only require a few lines of code, and a test or two. [Help wanted issues][help-wanted] - issues which should be a bit more involved than beginner issues. Pull Requests The process described here has several goals: Maintain code quality Fix problems that are important to users Engage the community in working toward the best possible product Enable a sustainable system for maintainers to review contributions Please follow these steps to have your contribution considered by the maintainers: Follow all instructions in the template Follow the styleguides After you submit your pull request, verify that all status checks are passing While the prerequisites above must be satisfied prior to having your pull request reviewed, the reviewer(s) may ask you to complete additional design work, tests, or other changes before your pull request can be ultimately accepted. Styleguides Git Commit Messages Use the present tense (\"Add feature\" not \"Added feature\") Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit the first line to 72 characters or less Reference issues and pull requests liberally after the first line When only changing documentation, include [ci skip] in the commit title Python Styleguide All Python code must adhere to PEP 8 . Use type hints where appropriate Include docstrings for all public functions, classes, and modules Prefer explicit over implicit Write tests for new functionality Documentation Styleguide Use Markdown . Reference functions and classes in backticks: `function_name()`. Include code examples where appropriate. Development Process Fork the repo and create your branch from main . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request! Development Setup # Clone your fork git clone https://github.com/your-username/ossnotices.git cd ossnotices # Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # Install dependencies pip install -e .[dev] # Run tests pytest # Run linting ruff check . black --check . Running Tests # Run all tests pytest # Run with coverage pytest --cov=ossnotices # Run specific test file pytest tests/test_specific.py Community You can chat with the community on: - GitHub Discussions - Issues Recognition Contributors who have made significant contributions will be recognized in our AUTHORS file. Thank you for contributing!","title":"Contributing to ossnotices"},{"location":"ossnotices/CONTRIBUTING/#contributing-to-ossnotices","text":"First off, thank you for considering contributing to ossnotices! It's people like you that make ossnotices such a great tool.","title":"Contributing to ossnotices"},{"location":"ossnotices/CONTRIBUTING/#code-of-conduct","text":"This project and everyone participating in it is governed by the Code of Conduct . By participating, you are expected to uphold this code. Please report unacceptable behavior to conduct@semcl.one .","title":"Code of Conduct"},{"location":"ossnotices/CONTRIBUTING/#how-can-i-contribute","text":"","title":"How Can I Contribute?"},{"location":"ossnotices/CONTRIBUTING/#reporting-bugs","text":"Before creating bug reports, please check existing issues as you might find out that you don't need to create one. When you are creating a bug report, please include as many details as possible. Note: If you find a Closed issue that seems like it is the same thing that you're experiencing, open a new issue and include a link to the original issue in the body of your new one.","title":"Reporting Bugs"},{"location":"ossnotices/CONTRIBUTING/#how-do-i-submit-a-good-bug-report","text":"Bugs are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the problem. Describe the exact steps which reproduce the problem in as many details as possible. Provide specific examples to demonstrate the steps . Include links to files or GitHub projects, or copy/pasteable snippets, which you use in those examples. Describe the behavior you observed after following the steps and point out what exactly is the problem with that behavior. Explain which behavior you expected to see instead and why. Include screenshots and animated GIFs which show you following the described steps and clearly demonstrate the problem. If the problem wasn't triggered by a specific action , describe what you were doing before the problem happened and share more information using the guidelines below.","title":"How Do I Submit A Good Bug Report?"},{"location":"ossnotices/CONTRIBUTING/#suggesting-enhancements","text":"Enhancement suggestions are tracked as GitHub issues. Create an issue and provide the following information: Use a clear and descriptive title for the issue to identify the suggestion. Provide a step-by-step description of the suggested enhancement in as many details as possible. Provide specific examples to demonstrate the steps . Include copy/pasteable snippets which you use in those examples. Describe the current behavior and explain which behavior you expected to see instead and why. Explain why this enhancement would be useful to most users. List some other projects where this enhancement exists.","title":"Suggesting Enhancements"},{"location":"ossnotices/CONTRIBUTING/#your-first-code-contribution","text":"Unsure where to begin contributing? You can start by looking through these beginner and help-wanted issues: [Beginner issues][beginner] - issues which should only require a few lines of code, and a test or two. [Help wanted issues][help-wanted] - issues which should be a bit more involved than beginner issues.","title":"Your First Code Contribution"},{"location":"ossnotices/CONTRIBUTING/#pull-requests","text":"The process described here has several goals: Maintain code quality Fix problems that are important to users Engage the community in working toward the best possible product Enable a sustainable system for maintainers to review contributions Please follow these steps to have your contribution considered by the maintainers: Follow all instructions in the template Follow the styleguides After you submit your pull request, verify that all status checks are passing While the prerequisites above must be satisfied prior to having your pull request reviewed, the reviewer(s) may ask you to complete additional design work, tests, or other changes before your pull request can be ultimately accepted.","title":"Pull Requests"},{"location":"ossnotices/CONTRIBUTING/#styleguides","text":"","title":"Styleguides"},{"location":"ossnotices/CONTRIBUTING/#git-commit-messages","text":"Use the present tense (\"Add feature\" not \"Added feature\") Use the imperative mood (\"Move cursor to...\" not \"Moves cursor to...\") Limit the first line to 72 characters or less Reference issues and pull requests liberally after the first line When only changing documentation, include [ci skip] in the commit title","title":"Git Commit Messages"},{"location":"ossnotices/CONTRIBUTING/#python-styleguide","text":"All Python code must adhere to PEP 8 . Use type hints where appropriate Include docstrings for all public functions, classes, and modules Prefer explicit over implicit Write tests for new functionality","title":"Python Styleguide"},{"location":"ossnotices/CONTRIBUTING/#documentation-styleguide","text":"Use Markdown . Reference functions and classes in backticks: `function_name()`. Include code examples where appropriate.","title":"Documentation Styleguide"},{"location":"ossnotices/CONTRIBUTING/#development-process","text":"Fork the repo and create your branch from main . If you've added code that should be tested, add tests. If you've changed APIs, update the documentation. Ensure the test suite passes. Make sure your code lints. Issue that pull request!","title":"Development Process"},{"location":"ossnotices/CONTRIBUTING/#development-setup","text":"# Clone your fork git clone https://github.com/your-username/ossnotices.git cd ossnotices # Create a virtual environment python -m venv venv source venv/bin/activate # On Windows: venv\\Scripts\\activate # Install dependencies pip install -e .[dev] # Run tests pytest # Run linting ruff check . black --check .","title":"Development Setup"},{"location":"ossnotices/CONTRIBUTING/#running-tests","text":"# Run all tests pytest # Run with coverage pytest --cov=ossnotices # Run specific test file pytest tests/test_specific.py","title":"Running Tests"},{"location":"ossnotices/CONTRIBUTING/#community","text":"You can chat with the community on: - GitHub Discussions - Issues","title":"Community"},{"location":"ossnotices/CONTRIBUTING/#recognition","text":"Contributors who have made significant contributions will be recognized in our AUTHORS file. Thank you for contributing!","title":"Recognition"},{"location":"ossnotices/SECURITY/","text":"Security Policy Supported Versions We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release Reporting a Vulnerability Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly. Preferred Languages We prefer all communications to be in English. Policy We follow the principle of Coordinated Vulnerability Disclosure.","title":"Security Policy"},{"location":"ossnotices/SECURITY/#security-policy","text":"","title":"Security Policy"},{"location":"ossnotices/SECURITY/#supported-versions","text":"We release patches for security vulnerabilities. Which versions are eligible for receiving such patches depends on the CVSS v3.0 Rating: CVSS v3.0 Supported Versions 9.0-10.0 Releases within the previous three months 4.0-8.9 Most recent release","title":"Supported Versions"},{"location":"ossnotices/SECURITY/#reporting-a-vulnerability","text":"Please report (suspected) security vulnerabilities to security@semcl.one . You will receive a response from us within 48 hours. If the issue is confirmed, we will release a patch as soon as possible depending on complexity but historically within a few days. Please include the following information in your report: Type of issue (e.g. buffer overflow, SQL injection, cross-site scripting, etc.) Full paths of source file(s) related to the manifestation of the issue The location of the affected source code (tag/branch/commit or direct URL) Any special configuration required to reproduce the issue Step-by-step instructions to reproduce the issue Proof-of-concept or exploit code (if possible) Impact of the issue, including how an attacker might exploit the issue This information will help us triage your report more quickly.","title":"Reporting a Vulnerability"},{"location":"ossnotices/SECURITY/#preferred-languages","text":"We prefer all communications to be in English.","title":"Preferred Languages"},{"location":"ossnotices/SECURITY/#policy","text":"We follow the principle of Coordinated Vulnerability Disclosure.","title":"Policy"},{"location":"ossnotices/SUPPORT/","text":"Support How to Get Help Thank you for using this project! Here are the best ways to get help: Documentation Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available) Getting Answers Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly Reporting Issues If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue Feature Requests We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project Security Issues For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines. Community Guidelines Please review our Code of Conduct before participating in discussions. Response Times This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours Additional Resources Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Support"},{"location":"ossnotices/SUPPORT/#support","text":"","title":"Support"},{"location":"ossnotices/SUPPORT/#how-to-get-help","text":"Thank you for using this project! Here are the best ways to get help:","title":"How to Get Help"},{"location":"ossnotices/SUPPORT/#documentation","text":"Check the README for basic usage and setup instructions Review the CONTRIBUTING guide for development setup Look through existing documentation in the /docs folder (if available)","title":"Documentation"},{"location":"ossnotices/SUPPORT/#getting-answers","text":"Before opening an issue: 1. Search existing GitHub Issues to see if your question has been answered 2. Check closed issues as well - your question might have been resolved 3. Review the project's documentation thoroughly","title":"Getting Answers"},{"location":"ossnotices/SUPPORT/#reporting-issues","text":"If you've found a bug or have a feature request: Search first : Check if someone else has already reported the same issue Create a detailed report : Use our issue templates when available Include context : Provide OS, Python version, and relevant configuration Share reproducible steps : Help us understand how to reproduce the issue","title":"Reporting Issues"},{"location":"ossnotices/SUPPORT/#feature-requests","text":"We welcome feature suggestions! Please: - Check existing issues for similar requests - Clearly describe the feature and its use case - Explain why this feature would be valuable to the project","title":"Feature Requests"},{"location":"ossnotices/SUPPORT/#security-issues","text":"For security vulnerabilities, please refer to our SECURITY policy for responsible disclosure guidelines.","title":"Security Issues"},{"location":"ossnotices/SUPPORT/#community-guidelines","text":"Please review our Code of Conduct before participating in discussions.","title":"Community Guidelines"},{"location":"ossnotices/SUPPORT/#response-times","text":"This project is maintained by a small team. While we strive to respond quickly: - Issues: Initial response within 7 days - Pull requests: Review within 14 days - Security issues: Within 48 hours","title":"Response Times"},{"location":"ossnotices/SUPPORT/#additional-resources","text":"Project Homepage : GitHub Repository License : See LICENSE file Contributing : See CONTRIBUTING guide Note : This is an open-source project maintained by volunteers. Response times may vary based on contributor availability.","title":"Additional Resources"}]}